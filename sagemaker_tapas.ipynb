{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4674f667",
   "metadata": {},
   "source": [
    "# Deploy a pretrained PyTorch BERT model from HuggingFace on Amazon SageMaker with Neuron container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39838",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c454f",
   "metadata": {},
   "source": [
    "In this tutotial we will deploy on SageMaker a pretraine BERT Base model from HuggingFace Transformers, using the [AWS Deep Learning Containers](https://github.com/aws/deep-learning-containers). We will use the same model as shown in the [Neuron Tutorial \"PyTorch - HuggingFace Pretrained BERT Tutorial\"](../../../../frameworks/torch/torch-neuronx/tutorials/training/bert.html#). We will compile the model and build a custom AWS Deep Learning Container, to include the HuggingFace Transformers Library. \n",
    "\n",
    "This Jupyter Notebook should run on a ml.c5.4xlarge SageMaker Notebook instance. You can set up your SageMaker Notebook instance by following the [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html) documentation. \n",
    "\n",
    "> We recommend increasing the size of the base root volume of you SM notebook instance, to accomodate the models and containers built locally. A root volume of 10Gb should suffice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37445ad2",
   "metadata": {},
   "source": [
    "## Install Dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd765f",
   "metadata": {},
   "source": [
    "This tutorial requires the following pip packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3092c",
   "metadata": {},
   "source": [
    "- torch-neuron\n",
    "- neuron-cc[tensorflow]\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c3731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-neuron in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1.2.7.1.0)\n",
      "Requirement already satisfied: neuron-cc[tensorflow] in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.15.0.0+eec0c3604)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: dmlc-nnvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: numpy<2,>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.18.5)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (3.19.6)\n",
      "Requirement already satisfied: dmlc-tvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: inferentia-hwm==1.14.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.14.1.0+a9fb5c73a)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.3.3)\n",
      "Requirement already satisfied: networkx<=2.6.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2.6.3)\n",
      "Requirement already satisfied: dmlc-topi==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: islpy<=2022.1.1,>2021.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2022.1.1)\n",
      "Requirement already satisfied: tensorflow<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.5)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-topi==1.15.0.0->neuron-cc[tensorflow]) (5.1.1)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-tvm==1.15.0.0->neuron-cc[tensorflow]) (22.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pytest>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (7.3.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.54.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.3.0)\n",
      "Requirement already satisfied: h5py<=2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (21.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.1.1)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (4.11.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (3.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers==4.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (4.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.8)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.11.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (1.18.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.10.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (3.9.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.53)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->transformers==4.6.0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2022.12.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.2.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (8.1.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "#!python -m pip install neuronx-cc==2.* torch-neuronx torchvision\n",
    "!pip install --upgrade --no-cache-dir 'transformers==4.6.0'\n",
    "#!pip install --upgrade --no-cache-dir transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4796d3a",
   "metadata": {},
   "source": [
    "## Compile the model into an AWS Neuron optimized TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdefb95c-4f8b-42fa-a639-04efbb4f7f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048d8014-5d64-4c49-868f-9192a88893df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install torch torch-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe85f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incompatible libnrt.so.1 preloaded from /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/lib/libnrt.so.1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27792/2123318223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2707\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__version__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_import_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Add modeling imports here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m from ..albert.modeling_albert import (\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mAlbertForMaskedLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mAlbertForMultipleChoice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 43\u001b[0;31m from ...modeling_utils import (\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepspeed_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_deepspeed_zero3_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/integrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mENV_VARS_TRUE_VALUES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_callback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainerCallback\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPREFIX_CHECKPOINT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBestRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntervalStrategy\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntervalStrategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_dp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Setup Neuron library for AWS EC2 inf/trn instances.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# It needs to be called before _XLAC is loaded so that _XLAC can pick up environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0m_aws_ec2_inf_trn_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# These needs to be called before the _XLAC module is loaded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m_aws_ec2_inf_trn_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Setup Neuron library for AWS EC2 inf/trn instances.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuronx/xla.py\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mlibneuronxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0menable_torch_autocast_cuda_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEURON_INTERNAL_USE_VANILLA_TORCH_XLA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/libneuronxla/__init__.py\u001b[0m in \u001b[0;36mconfigure_environment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XLA_USE_BF16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XLA_DOWNCAST_BF16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0m_maybe_setenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEURON_RT_STOCHASTIC_ROUNDING_EN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_default_rt_stochastic_rounding_enable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0m_libnrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_compatible_libnrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/libneuronxla/libnrt.py\u001b[0m in \u001b[0;36mcheck_compatible_libnrt\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcompatible_libnrt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompatible_libnrt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloaded_libnrt_path\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcompatible_libnrt_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Incompatible {} preloaded from {}!'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIBNRT_SONAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_libnrt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: Incompatible libnrt.so.1 preloaded from /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/lib/libnrt.so.1!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_neuron\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b83ed-7abe-4219-bcc5-f70d38023d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c253a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"google/tapas-mini-finetuned-wtq\"\n",
    "#model_name = \"google/tapas-mini\"\n",
    "model = TapasForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = TapasTokenizer.from_pretrained(model_name, return_dict=False)\n",
    "\n",
    "data = {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]}\n",
    "queries = [\n",
    "    \"What is the name of the first actor?\",\n",
    "    \"How many movies has George Clooney played in?\",\n",
    "    \"What is the total number of movies?\",\n",
    "]\n",
    "\n",
    "\n",
    "# tapas_mini_query = \"[CLS] Sentence [SEP] Flattened table [SEP]\"\n",
    "\n",
    "\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "inputs = tokenizer(table=table, queries=queries, max_length=128, padding=\"max_length\", return_tensors=\"pt\")\n",
    "#max_length=128\n",
    "#inputs = tokenizer(tapas_mini_query, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, outputs.logits.detach(), outputs.logits_aggregation.detach()\n",
    ")\n",
    "\n",
    "example_inputs = inputs['input_ids'], inputs['attention_mask'], inputs['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44255ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_neuron = torch.neuron.trace(model, example_inputs, verbose=1, compiler_workdir='./compilation_artifacts', strict=False)\n",
    "model_neuron = torch.neuron.trace(model, example_inputs, verbose=1, compiler_workdir='./compilation_artifacts', strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4752ac",
   "metadata": {},
   "source": [
    "You may inspect **model_neuron.graph** to see which part is running on CPU versus running on the accelerator. All native **aten** operators in the graph will be running on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00889e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See  which part is running on CPU versus running on the accelerator.\n",
    "print(model_neuron.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fb30d",
   "metadata": {},
   "source": [
    "Save the compiled model, so it can be packaged and sent to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c4f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the TorchScript for later use\n",
    "model_neuron.save('neuron_compiled_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362c579",
   "metadata": {},
   "source": [
    "### Package the pre-trained model and upload it to S3\n",
    "\n",
    "To make the model available for the SageMaker deployment, you will TAR the serialized graph and upload it to the default Amazon S3 bucket for your SageMaker session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7f7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now you'll create a model.tar.gz file to be used by SageMaker endpoint\n",
    "!tar -czvf model.tar.gz neuron_compiled_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beadca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad87d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload model to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "sess=sagemaker.Session()\n",
    "region=sess.boto_region_name\n",
    "bucket=sess.default_bucket()\n",
    "sm_client=boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_key = '{}/model/model.tar.gz'.format('inf1_compiled_model')\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model.tar.gz', model_key)\n",
    "print(\"Uploaded model to S3:\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b425d4",
   "metadata": {},
   "source": [
    "## Build and Push the container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e6ed2",
   "metadata": {},
   "source": [
    "The following shell code shows how to build the container image using docker build and push the container image to ECR using docker push.\n",
    "The Dockerfile in this example is available in the ***container*** folder.\n",
    "Here's an example of the Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuron:1.7.1-neuron-py36-ubuntu18.04\n",
    "\n",
    "# Install packages \n",
    "RUN pip install \"transformers==4.7.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970025d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78b0f",
   "metadata": {},
   "source": [
    "Before running the next cell, make sure your SageMaker IAM role has access to ECR. If not, you can attache the role `AmazonEC2ContainerRegistryPowerUser` to your IAM role ARN, which allows you to upload image layers to ECR.  \n",
    "\n",
    "It takes 5 minutes to build docker images and upload image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd51acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=neuron-py36-inference\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6bbda",
   "metadata": {},
   "source": [
    "## Deploy Container and run inference based on the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65e31",
   "metadata": {},
   "source": [
    "To deploy a pretrained PyTorch model, you'll need to use the PyTorch estimator object to create a PyTorchModel object and set a different entry_point.\n",
    "\n",
    "You'll use the PyTorchModel object to deploy a PyTorchPredictor. This creates a SageMaker Endpoint -- a hosted prediction service that we can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343d3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd73b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"inf1_compiled_model/model\"\n",
    "\n",
    "# Get container name in ECR\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "algorithm_name=\"inference-to-deploy\"\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298f2a7",
   "metadata": {},
   "source": [
    "An implementation of *model_fn* is required for inference script.\n",
    "We are going to implement our own **model_fn** and **predict_fn** for Hugging Face Bert, and use default implementations of **input_fn** and **output_fn** defined in sagemaker-pytorch-containers.\n",
    "\n",
    "In this example, the inference script is put in ***code*** folder. Run the next cell to see it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea75b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31a7b8",
   "metadata": {},
   "source": [
    "Path of compiled pretrained model in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3556e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(pretrained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7557a5f",
   "metadata": {},
   "source": [
    "The model object is defined by using the SageMaker Python SDK's PyTorchModel and pass in the model from the estimator and the entry_point. The endpoint's entry point for inference is defined by model_fn as seen in the previous code block that prints out **inference.py**. The model_fn function will load the model and required tokenizer.\n",
    "\n",
    "Note, **image_uri** must be user's own ECR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd99768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=pretrained_model_data,\n",
    "    role=role,\n",
    "    source_dir=\"entry\",\n",
    "    framework_version=\"1.7.1\",\n",
    "    entry_point=\"inference_cpu.py\",\n",
    "    image_uri=ecr_image\n",
    ")\n",
    "\n",
    "# Let SageMaker know that we've already compiled the model via neuron-cc\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67439fe7",
   "metadata": {},
   "source": [
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint.\n",
    "\n",
    "Here you will deploy the model to a single **ml.inf1.2xlarge** instance.\n",
    "It may take 6-10 min to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771fc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type=\"ml.inf1.2xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6342f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059537d9",
   "metadata": {},
   "source": [
    "Since in the input_fn we declared that the incoming requests are json-encoded, we need to use a json serializer, to encode the incoming data into a json string. Also, we declared the return content type to be json string, we Need to use a json deserializer to parse the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e82f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006ea03",
   "metadata": {},
   "source": [
    "Using a list of sentences, now SageMaker endpoint is invoked to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "example_query = [{\"data\": {\"Actors\": [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \"Number of movies\": [\"87\", \"53\", \"69\"]},\n",
    "\"queries\": [\n",
    "\"What is the name of the first actor?\",\n",
    "\"How many movies has George Clooney played in?\",\n",
    "\"What is the total number of movies?\",\n",
    "]}]\n",
    "result = predictor.predict(example_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12410d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = predictor.predict(\n",
    "    [\n",
    "        \"The company HuggingFace is based in New York City\",\n",
    "        \"HuggingFace's headquarters are situated in Manhattan\",\n",
    "    ]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72dfd16",
   "metadata": {},
   "source": [
    "## Benchmarking your endpoint\n",
    "\n",
    "The following cells create a load test for your endpoint. You first define some helper functions: `inference_latency` runs the endpoint request, collects cliend side latency and any errors, `random_sentence` builds random to be sent to the endpoint.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d0e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import boto3   \n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038d9953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_latency(model,*inputs):\n",
    "    \"\"\"\n",
    "    infetence_time is a simple method to return the latency of a model inference.\n",
    "\n",
    "        Parameters:\n",
    "            model: torch model onbject loaded using torch.jit.load\n",
    "            inputs: model() args\n",
    "\n",
    "        Returns:\n",
    "            latency in seconds\n",
    "    \"\"\"\n",
    "    error = False\n",
    "    start = time.time()\n",
    "    try:\n",
    "        results = model(*inputs)\n",
    "    except:\n",
    "        error = True\n",
    "        results = []\n",
    "    return {'latency':time.time() - start, 'error': error, 'result': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b200ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_sentence():\n",
    "    \n",
    "    s_nouns = [\"A dude\", \"My mom\", \"The king\", \"Some guy\", \"A cat with rabies\", \"A sloth\", \"Your homie\", \"This cool guy my gardener met yesterday\", \"Superman\"]\n",
    "    p_nouns = [\"These dudes\", \"Both of my moms\", \"All the kings of the world\", \"Some guys\", \"All of a cattery's cats\", \"The multitude of sloths living under your bed\", \"Your homies\", \"Like, these, like, all these people\", \"Supermen\"]\n",
    "    s_verbs = [\"eats\", \"kicks\", \"gives\", \"treats\", \"meets with\", \"creates\", \"hacks\", \"configures\", \"spies on\", \"retards\", \"meows on\", \"flees from\", \"tries to automate\", \"explodes\"]\n",
    "    p_verbs = [\"eat\", \"kick\", \"give\", \"treat\", \"meet with\", \"create\", \"hack\", \"configure\", \"spy on\", \"retard\", \"meow on\", \"flee from\", \"try to automate\", \"explode\"]\n",
    "    infinitives = [\"to make a pie.\", \"for no apparent reason.\", \"because the sky is green.\", \"for a disease.\", \"to be able to make toast explode.\", \"to know more about archeology.\"]\n",
    "    \n",
    "    return (random.choice(s_nouns) + ' ' + random.choice(s_verbs) + ' ' + random.choice(s_nouns).lower() or random.choice(p_nouns).lower() + ' ' + random.choice(infinitives))\n",
    "\n",
    "print([random_sentence(), random_sentence()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2945dde",
   "metadata": {},
   "source": [
    "The following cell creates `number_of_clients` concurrent threads to run `number_of_runs` requests. Once completed, a `boto3` CloudWatch client will query for the server side latency metrics for comparison.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c047e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining Auxiliary variables\n",
    "number_of_clients = 2\n",
    "number_of_runs = 1000\n",
    "t = tqdm(range(number_of_runs),position=0, leave=True)\n",
    "\n",
    "# Starting parallel clients\n",
    "cw_start = datetime.datetime.utcnow()\n",
    "\n",
    "results = Parallel(n_jobs=number_of_clients,prefer=\"threads\")(delayed(inference_latency)(predictor.predict,[random_sentence(), random_sentence()]) for mod in t)\n",
    "avg_throughput = t.total/t.format_dict['elapsed']\n",
    "\n",
    "cw_end = datetime.datetime.utcnow() \n",
    "\n",
    "# Computing metrics and print\n",
    "latencies = [res['latency'] for res in results]\n",
    "errors = [res['error'] for res in results]\n",
    "error_p = sum(errors)/len(errors) *100\n",
    "p50 = np.quantile(latencies[-1000:],0.50) * 1000\n",
    "p90 = np.quantile(latencies[-1000:],0.95) * 1000\n",
    "p95 = np.quantile(latencies[-1000:],0.99) * 1000\n",
    "\n",
    "print(f'Avg Throughput: :{avg_throughput:.1f}\\n')\n",
    "print(f'50th Percentile Latency:{p50:.1f} ms')\n",
    "print(f'90th Percentile Latency:{p90:.1f} ms')\n",
    "print(f'95th Percentile Latency:{p95:.1f} ms\\n')\n",
    "print(f'Errors percentage: {error_p:.1f} %\\n')\n",
    "\n",
    "# Querying CloudWatch\n",
    "print('Getting Cloudwatch:')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "statistics=['SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "extended=['p50', 'p90', 'p95', 'p100']\n",
    "\n",
    "# Give 5 minute buffer to end\n",
    "cw_end += datetime.timedelta(minutes=5)\n",
    "\n",
    "# Period must be 1, 5, 10, 30, or multiple of 60\n",
    "# Calculate closest multiple of 60 to the total elapsed time\n",
    "factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "period = factor * 60\n",
    "print('Time elapsed: {} seconds'.format((cw_end - cw_start).total_seconds()))\n",
    "print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "cloudwatch_ready = False\n",
    "# Keep polling CloudWatch metrics until datapoints are available\n",
    "while not cloudwatch_ready:\n",
    "  time.sleep(30)\n",
    "  print('Waiting 30 seconds ...')\n",
    "  # Must use default units of microseconds\n",
    "  model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='ModelLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': predictor.endpoint_name},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  # Should be 1000\n",
    "  if len(model_latency_metrics['Datapoints']) > 0:\n",
    "    print('{} latency datapoints ready'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "    side_avg = model_latency_metrics['Datapoints'][0]['Average'] / number_of_runs\n",
    "    side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / number_of_runs\n",
    "    side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / number_of_runs\n",
    "    side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / number_of_runs\n",
    "    side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / number_of_runs\n",
    "    \n",
    "    print(f'50th Percentile Latency:{side_p50:.1f} ms')\n",
    "    print(f'90th Percentile Latency:{side_p90:.1f} ms')\n",
    "    print(f'95th Percentile Latency:{side_p95:.1f} ms\\n')\n",
    "\n",
    "    cloudwatch_ready = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035e681",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Endpoints should be deleted when no longer in use, to avoid costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284ef3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af53873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
