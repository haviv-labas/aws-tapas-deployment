v0.0.1
%391 = fn (%v1:0: Tensor[(3, 512, 256), float32], %v2:0: Tensor[(3, 512, 256), float32], %v3:0: Tensor[(3, 512, 256), float32], %v4:0: Tensor[(3, 512, 256), float32], %v5:0: Tensor[(3, 512, 256), float32], %v6:0: Tensor[(3, 512, 256), float32], %v7:0: Tensor[(3, 512, 256), float32], %v8:0: Tensor[(3, 512, 256), float32], %v9:0: Tensor[(3, 512, 256), float32], %tensor.1:0: Tensor[(3, 512), int64], %tensor.9:0: Tensor[(3, 512, 7), int64]) -> (Tensor[(3, 256), float32], Tensor[(1,), int64], Tensor[(3, 512), int64], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(6144,), float32], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(6144,), float32], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(3, 2048), int64], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(6144,), float32], Tensor[(1536,), float32], Tensor[(1536,), int64], Tensor[(1536,), int64], Tensor[(1536,), int64], Tensor[(3, 2048), int64]) {
  %0 = add(%v1:0, %v2:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %1 = add(%0, %v3:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %2 = add(%1, %v4:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %3 = add(%2, %v5:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %4 = add(%3, %v6:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %5 = add(%4, %v7:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %6 = add(%5, %v8:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %7 = add(%6, %v9:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_7/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %8 = sum(%7, framework_op_name="sum0", output_tensors_name=["sum0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %9 = multiply_scalar(%8, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %10 = copy(%9, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %11 = subtract(%7, %10, framework_op_name="subtract0", output_tensors_name=["subtract0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %12 = multiply(%11, %11, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %13 = sum(%12, framework_op_name="sum1", output_tensors_name=["sum1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %14 = multiply_scalar(%13, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %15 = add(%14, meta[relay.Constant][0] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %16 = sqrt(%15, framework_op_name="sqrt0", output_tensors_name=["sqrt0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %17 = rdivide_scalar(%16, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %18 = multiply(%17, meta[relay.Constant][1] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %19 = multiply(%7, %18, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %20 = multiply(%9, %18, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %21 = subtract(meta[relay.Constant][2] // ty=Tensor[(256,), float32], %20, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %22 = add(%19, %21, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %23 = nn.batch_matmul(%22, meta[relay.Constant][3] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul0", output_tensors_name=["nn.batch_matmul0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %24 = add(%23, meta[relay.Constant][4] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %25 = reshape(%24, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %26 = transpose(%25, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %27 = reshape(%26, framework_op_name="reshape2", output_tensors_name=["reshape2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %28 = nn.batch_matmul(%22, meta[relay.Constant][5] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul1", output_tensors_name=["nn.batch_matmul1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %29 = add(%28, meta[relay.Constant][6] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %30 = reshape(%29, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %31 = transpose(%30, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %32 = transpose(%31, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 512), float32]
  %33 = reshape(%32, framework_op_name="reshape5", output_tensors_name=["reshape5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 512]) // ty=Tensor[(12, 64, 512), float32]
  %34 = transpose(%33, framework_op_name="transpose2", output_tensors_name=["transpose2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 512, 64), float32]
  %35 = nn.batch_matmul(%27, %34, framework_op_name="nn.batch_matmul2", output_tensors_name=["nn.batch_matmul2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 512, 512), float32]
  %36 = reshape(%35, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %37 = multiply(%36, meta[relay.Constant][7] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %38 = strided_slice(%tensor.1:0, framework_op_name="strided_slice0", output_tensors_name=["strided_slice0:0"], input_tensors_name=[], framework_op_debug_info="aten_slice/StridedSlice", begin=[0, 0], end=[3, 512], strides=[1, 1]) // ty=Tensor[(3, 512), int64]
  %39 = strided_slice(%38, framework_op_name="strided_slice1", output_tensors_name=["strided_slice1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice/StridedSlice", begin=[0, 0], end=[3, 512], strides=[1, 1]) // ty=Tensor[(3, 512), int64]
  %40 = expand_dims(%39, framework_op_name="TapasModel_7/aten_unsqueeze/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze/ExpandDims", axis=1) // ty=Tensor[(3, 1, 512), int64]
  %41 = expand_dims(%40, framework_op_name="TapasModel_7/aten_unsqueeze_1/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze_1/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze_1/ExpandDims", axis=2) // ty=Tensor[(3, 1, 1, 512), int64]
  %42 = strided_slice(%41, framework_op_name="strided_slice2", output_tensors_name=["strided_slice2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_1/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 512], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 512), int64]
  %43 = strided_slice(%42, framework_op_name="strided_slice3", output_tensors_name=["strided_slice3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_2/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 512], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 512), int64]
  %44 = strided_slice(%43, framework_op_name="strided_slice4", output_tensors_name=["strided_slice4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_3/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 512], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 512), int64]
  %45 = strided_slice(%44, framework_op_name="strided_slice5", output_tensors_name=["strided_slice5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_4/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 512], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 512), int64]
  %46 = cast(%45, framework_op_name="TapasModel_7/aten_to/Cast", output_tensors_name=["TapasModel_7/aten_to/Cast:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_to/Cast", dtype="float32") // ty=Tensor[(3, 1, 1, 512), float32]
  %47 = multiply(meta[relay.Constant][9] // ty=Tensor[(1,), float32], %46, framework_op_name="TapasModel_7/aten_rsub/mul", output_tensors_name=["TapasModel_7/aten_rsub/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/mul", axis=0) // ty=Tensor[(3, 1, 1, 512), float32]
  %48 = subtract(meta[relay.Constant][8] // ty=Tensor[(1,), float32], %47, framework_op_name="TapasModel_7/aten_rsub/sub", output_tensors_name=["TapasModel_7/aten_rsub/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/sub", axis=0) // ty=Tensor[(3, 1, 1, 512), float32]
  %49 = multiply(%48, meta[relay.Constant][10] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/aten_mul/mul", output_tensors_name=["TapasModel_7/aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_mul/mul", axis=0) // ty=Tensor[(3, 1, 1, 512), float32]
  %50 = broadcast_to(%49, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %51 = add(%37, %50, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %52 = nn.softmax(%51, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 512, 512), float32]
  %53 = reshape(%52, framework_op_name="reshape6", output_tensors_name=["reshape6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 512]) // ty=Tensor[(12, 512, 512), float32]
  %54 = nn.batch_matmul(%22, meta[relay.Constant][11] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul3", output_tensors_name=["nn.batch_matmul3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %55 = add(%54, meta[relay.Constant][12] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %56 = reshape(%55, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %57 = transpose(%56, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %58 = reshape(%57, framework_op_name="reshape9", output_tensors_name=["reshape9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %59 = transpose(%58, framework_op_name="transpose4", output_tensors_name=["transpose4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 512), float32]
  %60 = nn.batch_matmul(%53, %59, framework_op_name="nn.batch_matmul4", output_tensors_name=["nn.batch_matmul4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 512, 64), float32]
  %61 = reshape(%60, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 512, 64]) // ty=Tensor[(3, 4, 512, 64), float32]
  %62 = transpose(%61, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 512, 4, 64), float32]
  %63 = reshape(%62, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 512, 256]) // ty=Tensor[(3, 512, 256), float32]
  %64 = nn.batch_matmul(%63, meta[relay.Constant][13] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul5", output_tensors_name=["nn.batch_matmul5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %65 = add(%64, meta[relay.Constant][14] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %66 = add(%65, %22, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %67 = sum(%66, framework_op_name="sum2", output_tensors_name=["sum2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %68 = multiply_scalar(%67, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %69 = copy(%68, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %70 = subtract(%66, %69, framework_op_name="subtract1", output_tensors_name=["subtract1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %71 = multiply(%70, %70, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %72 = sum(%71, framework_op_name="sum3", output_tensors_name=["sum3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %73 = multiply_scalar(%72, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %74 = add(%73, meta[relay.Constant][15] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %75 = sqrt(%74, framework_op_name="sqrt1", output_tensors_name=["sqrt1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %76 = rdivide_scalar(%75, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %77 = multiply(%76, meta[relay.Constant][16] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %78 = multiply(%66, %77, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %79 = multiply(%68, %77, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %80 = subtract(meta[relay.Constant][17] // ty=Tensor[(256,), float32], %79, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %81 = add(%78, %80, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %82 = nn.batch_matmul(%81, meta[relay.Constant][18] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul6", output_tensors_name=["nn.batch_matmul6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %83 = add(%82, meta[relay.Constant][19] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %84 = multiply(%83, meta[relay.Constant][22] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %85 = erf(%84, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %86 = add(meta[relay.Constant][21] // ty=Tensor[(1,), float32], %85, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %87 = multiply(meta[relay.Constant][20] // ty=Tensor[(1,), float32], %86, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %88 = multiply(%83, %87, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %89 = nn.batch_matmul(%88, meta[relay.Constant][23] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul7", output_tensors_name=["nn.batch_matmul7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %90 = add(%89, meta[relay.Constant][24] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %91 = add(%90, %81, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %92 = sum(%91, framework_op_name="sum4", output_tensors_name=["sum4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %93 = multiply_scalar(%92, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %94 = copy(%93, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %95 = subtract(%91, %94, framework_op_name="subtract2", output_tensors_name=["subtract2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %96 = multiply(%95, %95, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %97 = sum(%96, framework_op_name="sum5", output_tensors_name=["sum5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %98 = multiply_scalar(%97, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %99 = add(%98, meta[relay.Constant][25] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %100 = sqrt(%99, framework_op_name="sqrt2", output_tensors_name=["sqrt2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %101 = rdivide_scalar(%100, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %102 = multiply(%101, meta[relay.Constant][26] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %103 = multiply(%91, %102, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %104 = multiply(%93, %102, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %105 = subtract(meta[relay.Constant][27] // ty=Tensor[(256,), float32], %104, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %106 = add(%103, %105, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %107 = nn.batch_matmul(%106, meta[relay.Constant][28] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul8", output_tensors_name=["nn.batch_matmul8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %108 = add(%107, meta[relay.Constant][29] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %109 = reshape(%108, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %110 = transpose(%109, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %111 = reshape(%110, framework_op_name="reshape18", output_tensors_name=["reshape18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %112 = nn.batch_matmul(%106, meta[relay.Constant][30] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul9", output_tensors_name=["nn.batch_matmul9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %113 = add(%112, meta[relay.Constant][31] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %114 = reshape(%113, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %115 = transpose(%114, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %116 = transpose(%115, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 512), float32]
  %117 = reshape(%116, framework_op_name="reshape21", output_tensors_name=["reshape21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 512]) // ty=Tensor[(12, 64, 512), float32]
  %118 = transpose(%117, framework_op_name="transpose10", output_tensors_name=["transpose10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 512, 64), float32]
  %119 = nn.batch_matmul(%111, %118, framework_op_name="nn.batch_matmul10", output_tensors_name=["nn.batch_matmul10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 512, 512), float32]
  %120 = reshape(%119, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %121 = multiply(%120, meta[relay.Constant][32] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %122 = broadcast_to(%49, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %123 = add(%121, %122, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %124 = nn.softmax(%123, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 512, 512), float32]
  %125 = reshape(%124, framework_op_name="reshape22", output_tensors_name=["reshape22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 512]) // ty=Tensor[(12, 512, 512), float32]
  %126 = nn.batch_matmul(%106, meta[relay.Constant][33] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul11", output_tensors_name=["nn.batch_matmul11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %127 = add(%126, meta[relay.Constant][34] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %128 = reshape(%127, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %129 = transpose(%128, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %130 = reshape(%129, framework_op_name="reshape25", output_tensors_name=["reshape25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %131 = transpose(%130, framework_op_name="transpose12", output_tensors_name=["transpose12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 512), float32]
  %132 = nn.batch_matmul(%125, %131, framework_op_name="nn.batch_matmul12", output_tensors_name=["nn.batch_matmul12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 512, 64), float32]
  %133 = reshape(%132, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 512, 64]) // ty=Tensor[(3, 4, 512, 64), float32]
  %134 = transpose(%133, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 512, 4, 64), float32]
  %135 = reshape(%134, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 512, 256]) // ty=Tensor[(3, 512, 256), float32]
  %136 = nn.batch_matmul(%135, meta[relay.Constant][35] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul13", output_tensors_name=["nn.batch_matmul13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %137 = add(%136, meta[relay.Constant][36] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %138 = add(%137, %106, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %139 = sum(%138, framework_op_name="sum6", output_tensors_name=["sum6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %140 = multiply_scalar(%139, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %141 = copy(%140, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %142 = subtract(%138, %141, framework_op_name="subtract3", output_tensors_name=["subtract3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %143 = multiply(%142, %142, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %144 = sum(%143, framework_op_name="sum7", output_tensors_name=["sum7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %145 = multiply_scalar(%144, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %146 = add(%145, meta[relay.Constant][37] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %147 = sqrt(%146, framework_op_name="sqrt3", output_tensors_name=["sqrt3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %148 = rdivide_scalar(%147, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %149 = multiply(%148, meta[relay.Constant][38] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %150 = multiply(%138, %149, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %151 = multiply(%140, %149, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %152 = subtract(meta[relay.Constant][39] // ty=Tensor[(256,), float32], %151, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %153 = add(%150, %152, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %154 = nn.batch_matmul(%153, meta[relay.Constant][40] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul14", output_tensors_name=["nn.batch_matmul14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %155 = add(%154, meta[relay.Constant][41] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %156 = multiply(%155, meta[relay.Constant][44] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %157 = erf(%156, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %158 = add(meta[relay.Constant][43] // ty=Tensor[(1,), float32], %157, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %159 = multiply(meta[relay.Constant][42] // ty=Tensor[(1,), float32], %158, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %160 = multiply(%155, %159, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %161 = nn.batch_matmul(%160, meta[relay.Constant][45] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul15", output_tensors_name=["nn.batch_matmul15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %162 = add(%161, meta[relay.Constant][46] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %163 = add(%162, %153, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %164 = sum(%163, framework_op_name="sum8", output_tensors_name=["sum8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %165 = multiply_scalar(%164, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %166 = copy(%165, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %167 = subtract(%163, %166, framework_op_name="subtract4", output_tensors_name=["subtract4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %168 = multiply(%167, %167, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %169 = sum(%168, framework_op_name="sum9", output_tensors_name=["sum9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %170 = multiply_scalar(%169, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %171 = add(%170, meta[relay.Constant][47] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %172 = sqrt(%171, framework_op_name="sqrt4", output_tensors_name=["sqrt4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %173 = rdivide_scalar(%172, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %174 = multiply(%173, meta[relay.Constant][48] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %175 = multiply(%163, %174, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %176 = multiply(%165, %174, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %177 = subtract(meta[relay.Constant][49] // ty=Tensor[(256,), float32], %176, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %178 = add(%175, %177, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %179 = nn.batch_matmul(%178, meta[relay.Constant][50] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul16", output_tensors_name=["nn.batch_matmul16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %180 = add(%179, meta[relay.Constant][51] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %181 = reshape(%180, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %182 = transpose(%181, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %183 = reshape(%182, framework_op_name="reshape34", output_tensors_name=["reshape34:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %184 = nn.batch_matmul(%178, meta[relay.Constant][52] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul17", output_tensors_name=["nn.batch_matmul17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %185 = add(%184, meta[relay.Constant][53] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %186 = reshape(%185, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %187 = transpose(%186, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %188 = transpose(%187, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 512), float32]
  %189 = reshape(%188, framework_op_name="reshape37", output_tensors_name=["reshape37:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 512]) // ty=Tensor[(12, 64, 512), float32]
  %190 = transpose(%189, framework_op_name="transpose18", output_tensors_name=["transpose18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 512, 64), float32]
  %191 = nn.batch_matmul(%183, %190, framework_op_name="nn.batch_matmul18", output_tensors_name=["nn.batch_matmul18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 512, 512), float32]
  %192 = reshape(%191, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %193 = multiply(%192, meta[relay.Constant][54] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %194 = broadcast_to(%49, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %195 = add(%193, %194, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %196 = nn.softmax(%195, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 512, 512), float32]
  %197 = reshape(%196, framework_op_name="reshape38", output_tensors_name=["reshape38:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 512]) // ty=Tensor[(12, 512, 512), float32]
  %198 = nn.batch_matmul(%178, meta[relay.Constant][55] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul19", output_tensors_name=["nn.batch_matmul19:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %199 = add(%198, meta[relay.Constant][56] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %200 = reshape(%199, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %201 = transpose(%200, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %202 = reshape(%201, framework_op_name="reshape41", output_tensors_name=["reshape41:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %203 = transpose(%202, framework_op_name="transpose20", output_tensors_name=["transpose20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 512), float32]
  %204 = nn.batch_matmul(%197, %203, framework_op_name="nn.batch_matmul20", output_tensors_name=["nn.batch_matmul20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 512, 64), float32]
  %205 = reshape(%204, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 512, 64]) // ty=Tensor[(3, 4, 512, 64), float32]
  %206 = transpose(%205, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 512, 4, 64), float32]
  %207 = reshape(%206, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 512, 256]) // ty=Tensor[(3, 512, 256), float32]
  %208 = nn.batch_matmul(%207, meta[relay.Constant][57] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul21", output_tensors_name=["nn.batch_matmul21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %209 = add(%208, meta[relay.Constant][58] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %210 = add(%209, %178, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %211 = sum(%210, framework_op_name="sum10", output_tensors_name=["sum10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %212 = multiply_scalar(%211, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %213 = copy(%212, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %214 = subtract(%210, %213, framework_op_name="subtract5", output_tensors_name=["subtract5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %215 = multiply(%214, %214, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %216 = sum(%215, framework_op_name="sum11", output_tensors_name=["sum11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %217 = multiply_scalar(%216, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %218 = add(%217, meta[relay.Constant][59] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %219 = sqrt(%218, framework_op_name="sqrt5", output_tensors_name=["sqrt5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %220 = rdivide_scalar(%219, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %221 = multiply(%220, meta[relay.Constant][60] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %222 = multiply(%210, %221, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %223 = multiply(%212, %221, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %224 = subtract(meta[relay.Constant][61] // ty=Tensor[(256,), float32], %223, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %225 = add(%222, %224, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %226 = nn.batch_matmul(%225, meta[relay.Constant][62] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul22", output_tensors_name=["nn.batch_matmul22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %227 = add(%226, meta[relay.Constant][63] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %228 = multiply(%227, meta[relay.Constant][66] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %229 = erf(%228, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %230 = add(meta[relay.Constant][65] // ty=Tensor[(1,), float32], %229, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %231 = multiply(meta[relay.Constant][64] // ty=Tensor[(1,), float32], %230, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %232 = multiply(%227, %231, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %233 = nn.batch_matmul(%232, meta[relay.Constant][67] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul23", output_tensors_name=["nn.batch_matmul23:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %234 = add(%233, meta[relay.Constant][68] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %235 = add(%234, %225, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %236 = sum(%235, framework_op_name="sum12", output_tensors_name=["sum12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %237 = multiply_scalar(%236, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %238 = copy(%237, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %239 = subtract(%235, %238, framework_op_name="subtract6", output_tensors_name=["subtract6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %240 = multiply(%239, %239, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %241 = sum(%240, framework_op_name="sum13", output_tensors_name=["sum13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %242 = multiply_scalar(%241, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %243 = add(%242, meta[relay.Constant][69] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %244 = sqrt(%243, framework_op_name="sqrt6", output_tensors_name=["sqrt6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %245 = rdivide_scalar(%244, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %246 = multiply(%245, meta[relay.Constant][70] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %247 = multiply(%235, %246, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %248 = multiply(%237, %246, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %249 = subtract(meta[relay.Constant][71] // ty=Tensor[(256,), float32], %248, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %250 = add(%247, %249, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %251 = nn.batch_matmul(%250, meta[relay.Constant][72] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul24", output_tensors_name=["nn.batch_matmul24:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %252 = add(%251, meta[relay.Constant][73] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %253 = reshape(%252, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %254 = transpose(%253, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %255 = reshape(%254, framework_op_name="reshape50", output_tensors_name=["reshape50:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %256 = nn.batch_matmul(%250, meta[relay.Constant][74] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul25", output_tensors_name=["nn.batch_matmul25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %257 = add(%256, meta[relay.Constant][75] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %258 = reshape(%257, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %259 = transpose(%258, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %260 = transpose(%259, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 512), float32]
  %261 = reshape(%260, framework_op_name="reshape53", output_tensors_name=["reshape53:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 512]) // ty=Tensor[(12, 64, 512), float32]
  %262 = transpose(%261, framework_op_name="transpose26", output_tensors_name=["transpose26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 512, 64), float32]
  %263 = nn.batch_matmul(%255, %262, framework_op_name="nn.batch_matmul26", output_tensors_name=["nn.batch_matmul26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 512, 512), float32]
  %264 = reshape(%263, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %265 = multiply(%264, meta[relay.Constant][76] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %266 = broadcast_to(%49, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 512, 512]) // ty=Tensor[(3, 4, 512, 512), float32]
  %267 = add(%265, %266, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 512, 512), float32]
  %268 = nn.softmax(%267, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 512, 512), float32]
  %269 = reshape(%268, framework_op_name="reshape54", output_tensors_name=["reshape54:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 512]) // ty=Tensor[(12, 512, 512), float32]
  %270 = nn.batch_matmul(%250, meta[relay.Constant][77] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul27", output_tensors_name=["nn.batch_matmul27:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %271 = add(%270, meta[relay.Constant][78] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %272 = reshape(%271, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 512, 4, 64]) // ty=Tensor[(3, 512, 4, 64), float32]
  %273 = transpose(%272, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 512, 64), float32]
  %274 = reshape(%273, framework_op_name="reshape57", output_tensors_name=["reshape57:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 512, 64]) // ty=Tensor[(12, 512, 64), float32]
  %275 = transpose(%274, framework_op_name="transpose28", output_tensors_name=["transpose28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 512), float32]
  %276 = nn.batch_matmul(%269, %275, framework_op_name="nn.batch_matmul28", output_tensors_name=["nn.batch_matmul28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 512, 64), float32]
  %277 = reshape(%276, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 512, 64]) // ty=Tensor[(3, 4, 512, 64), float32]
  %278 = transpose(%277, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 512, 4, 64), float32]
  %279 = reshape(%278, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 512, 256]) // ty=Tensor[(3, 512, 256), float32]
  %280 = nn.batch_matmul(%279, meta[relay.Constant][79] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul29", output_tensors_name=["nn.batch_matmul29:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %281 = add(%280, meta[relay.Constant][80] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %282 = add(%281, %250, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %283 = sum(%282, framework_op_name="sum14", output_tensors_name=["sum14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %284 = multiply_scalar(%283, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %285 = copy(%284, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %286 = subtract(%282, %285, framework_op_name="subtract7", output_tensors_name=["subtract7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %287 = multiply(%286, %286, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %288 = sum(%287, framework_op_name="sum15", output_tensors_name=["sum15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %289 = multiply_scalar(%288, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %290 = add(%289, meta[relay.Constant][81] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %291 = sqrt(%290, framework_op_name="sqrt7", output_tensors_name=["sqrt7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %292 = rdivide_scalar(%291, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %293 = multiply(%292, meta[relay.Constant][82] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %294 = multiply(%282, %293, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %295 = multiply(%284, %293, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %296 = subtract(meta[relay.Constant][83] // ty=Tensor[(256,), float32], %295, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %297 = add(%294, %296, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %298 = nn.batch_matmul(%297, meta[relay.Constant][84] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul30", output_tensors_name=["nn.batch_matmul30:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %299 = add(%298, meta[relay.Constant][85] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %300 = multiply(%299, meta[relay.Constant][88] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %301 = erf(%300, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %302 = add(meta[relay.Constant][87] // ty=Tensor[(1,), float32], %301, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %303 = multiply(meta[relay.Constant][86] // ty=Tensor[(1,), float32], %302, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %304 = multiply(%299, %303, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 512, 1024), float32]
  %305 = nn.batch_matmul(%304, meta[relay.Constant][89] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul31", output_tensors_name=["nn.batch_matmul31:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %306 = add(%305, meta[relay.Constant][90] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %307 = add(%306, %297, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %308 = sum(%307, framework_op_name="sum16", output_tensors_name=["sum16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %309 = multiply_scalar(%308, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %310 = copy(%309, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %311 = subtract(%307, %310, framework_op_name="subtract8", output_tensors_name=["subtract8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %312 = multiply(%311, %311, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %313 = sum(%312, framework_op_name="sum17", output_tensors_name=["sum17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 512, 1), float32]
  %314 = multiply_scalar(%313, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 512, 1), float32]
  %315 = add(%314, meta[relay.Constant][91] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %316 = sqrt(%315, framework_op_name="sqrt8", output_tensors_name=["sqrt8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 512, 1), float32]
  %317 = rdivide_scalar(%316, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 512, 1), float32]
  %318 = multiply(%317, meta[relay.Constant][92] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %319 = multiply(%307, %318, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %320 = multiply(%309, %318, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %321 = subtract(meta[relay.Constant][93] // ty=Tensor[(256,), float32], %320, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %322 = add(%319, %321, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 512, 256), float32]
  %323 = strided_slice(%322, framework_op_name="strided_slice6", output_tensors_name=["strided_slice6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice/StridedSlice", begin=[0, 0, 0], end=[3, 512, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 256), float32]
  %324 = strided_slice(%323, framework_op_name="strided_slice7", output_tensors_name=["strided_slice7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 512, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 256), float32]
  %325 = strided_slice(%324, framework_op_name="strided_slice8", output_tensors_name=["strided_slice8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 512, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 256), float32]
  %326 = strided_slice(%325, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Slice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Slice", begin=[0, 0, 0], end=[3, 1, 256]) // ty=Tensor[(3, 1, 256), float32]
  %327 = reshape(%326, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Reshape", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Reshape", newshape=[3, 256]) // ty=Tensor[(3, 256), float32]
  %328 = nn.dense(%327, meta[relay.Constant][94] // ty=Tensor[(256, 256), float32], framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", units=256) // ty=Tensor[(3, 256), float32]
  %329 = add(%328, meta[relay.Constant][95] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", axis=0) // ty=Tensor[(3, 256), float32]
  %330 = tanh(%329, framework_op_name="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", output_tensors_name=["TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", axis=0) // ty=Tensor[(3, 256), float32]
  %331 = strided_slice(%tensor.9:0, framework_op_name="strided_slice9", output_tensors_name=["strided_slice9:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_7/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %332 = strided_slice(%331, framework_op_name="strided_slice10", output_tensors_name=["strided_slice10:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_8/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %333 = strided_slice(%332, framework_op_name="strided_slice11", output_tensors_name=["strided_slice11:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_9/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %334 = strided_slice(%333, framework_op_name="strided_slice12", output_tensors_name=["strided_slice12:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_10/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %335 = strided_slice(%334, framework_op_name="strided_slice13", output_tensors_name=["strided_slice13:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_11/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %336 = strided_slice(%335, framework_op_name="strided_slice14", output_tensors_name=["strided_slice14:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_12/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %337 = strided_slice(%336, framework_op_name="aten_select_1/Slice", output_tensors_name=["aten_select_1/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Slice", begin=[0, 0, 1], end=[3, 512, 2]) // ty=Tensor[(3, 512, 1), int64]
  %338 = reshape(%337, framework_op_name="aten_select_1/Reshape", output_tensors_name=["aten_select_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Reshape", newshape=[3, 512]) // ty=Tensor[(3, 512), int64]
  %339 = minimum(%338, meta[relay.Constant][97] // ty=Tensor[(1,), int64], framework_op_name="aten_min_1/Minimum", output_tensors_name=["aten_min_1/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min_1/Minimum", axis=0) // ty=Tensor[(3, 512), int64]
  %340 = strided_slice(%tensor.9:0, framework_op_name="strided_slice15", output_tensors_name=["strided_slice15:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %341 = strided_slice(%340, framework_op_name="strided_slice16", output_tensors_name=["strided_slice16:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %342 = strided_slice(%341, framework_op_name="strided_slice17", output_tensors_name=["strided_slice17:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_3/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %343 = strided_slice(%342, framework_op_name="strided_slice18", output_tensors_name=["strided_slice18:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_4/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %344 = strided_slice(%343, framework_op_name="strided_slice19", output_tensors_name=["strided_slice19:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_5/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %345 = strided_slice(%344, framework_op_name="strided_slice20", output_tensors_name=["strided_slice20:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_6/StridedSlice", begin=[0, 0, 0], end=[3, 512, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 512, 7), int64]
  %346 = strided_slice(%345, framework_op_name="aten_select/Slice", output_tensors_name=["aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Slice", begin=[0, 0, 2], end=[3, 512, 3]) // ty=Tensor[(3, 512, 1), int64]
  %347 = reshape(%346, framework_op_name="aten_select/Reshape", output_tensors_name=["aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Reshape", newshape=[3, 512]) // ty=Tensor[(3, 512), int64]
  %348 = minimum(%347, meta[relay.Constant][98] // ty=Tensor[(1,), int64], framework_op_name="aten_min/Minimum", output_tensors_name=["aten_min/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min/Minimum", axis=0) // ty=Tensor[(3, 512), int64]
  %349 = multiply(%348, meta[relay.Constant][96] // ty=Tensor[(1,), int64], framework_op_name="aten_mul/mul", output_tensors_name=["aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul/mul", axis=0) // ty=Tensor[(3, 512), int64]
  %350 = add(%339, %349, framework_op_name="aten_add/add", output_tensors_name=["aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add/add", axis=0) // ty=Tensor[(3, 512), int64]
  %351 = cast(%tensor.1:0, framework_op_name="aten_to_8/Cast", output_tensors_name=["aten_to_8/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_8/Cast", dtype="float32") // ty=Tensor[(3, 512), float32]
  %352 = reshape(%351, framework_op_name="aten_reshape/Reshape", output_tensors_name=["aten_reshape/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape/Reshape", newshape=[-1]) // ty=Tensor[(1536,), float32]
  %353 = add(meta[relay.Constant][99] // ty=Tensor[(3, 512), int64], %350, framework_op_name="aten_add_1/add", output_tensors_name=["aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_1/add", axis=0) // ty=Tensor[(3, 512), int64]
  %354 = reshape(%353, framework_op_name="aten_view_1/Reshape", output_tensors_name=["aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_1/Reshape", newshape=[-1]) // ty=Tensor[(1536,), int64]
  %355 = cast(%354, framework_op_name="aten_expand/Cast", output_tensors_name=["aten_expand/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %356 = broadcast_to(%355, framework_op_name="aten_expand/BroadcastTo", output_tensors_name=["aten_expand/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %357 = cast(%356, framework_op_name="aten_expand/Cast_1", output_tensors_name=["aten_expand/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %358 = cast(%354, framework_op_name="aten_expand_1/Cast", output_tensors_name=["aten_expand_1/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %359 = broadcast_to(%358, framework_op_name="aten_expand_1/BroadcastTo", output_tensors_name=["aten_expand_1/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %360 = cast(%359, framework_op_name="aten_expand_1/Cast_1", output_tensors_name=["aten_expand_1/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %361 = reshape(%322, framework_op_name="aten_einsum_1/einsum/Reshape", output_tensors_name=["aten_einsum_1/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape", newshape=[1536, 256]) // ty=Tensor[(1536, 256), float32]
  %362 = nn.dense(%361, meta[relay.Constant][102] // ty=Tensor[(1, 256), float32], framework_op_name="aten_einsum_1/einsum/MatMul", output_tensors_name=["aten_einsum_1/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/MatMul", units=1) // ty=Tensor[(1536, 1), float32]
  %363 = reshape(%362, framework_op_name="aten_einsum_1/einsum/Reshape_2", output_tensors_name=["aten_einsum_1/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape_2", newshape=[3, 512]) // ty=Tensor[(3, 512), float32]
  %364 = add(%363, meta[relay.Constant][103] // ty=Tensor[(1,), float32], framework_op_name="aten_add_3/add", output_tensors_name=["aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_3/add", axis=0) // ty=Tensor[(3, 512), float32]
  %365 = reshape(%364, framework_op_name="aten_reshape_1/Reshape", output_tensors_name=["aten_reshape_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_1/Reshape", newshape=[-1]) // ty=Tensor[(1536,), float32]
  %366 = add(meta[relay.Constant][99] // ty=Tensor[(3, 512), int64], %350, framework_op_name="aten_add_4/add", output_tensors_name=["aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_4/add", axis=0) // ty=Tensor[(3, 512), int64]
  %367 = reshape(%366, framework_op_name="aten_view_3/Reshape", output_tensors_name=["aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_3/Reshape", newshape=[-1]) // ty=Tensor[(1536,), int64]
  %368 = cast(%367, framework_op_name="aten_expand_2/Cast", output_tensors_name=["aten_expand_2/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %369 = broadcast_to(%368, framework_op_name="aten_expand_2/BroadcastTo", output_tensors_name=["aten_expand_2/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %370 = cast(%369, framework_op_name="aten_expand_2/Cast_1", output_tensors_name=["aten_expand_2/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %371 = cast(%367, framework_op_name="aten_expand_3/Cast", output_tensors_name=["aten_expand_3/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %372 = broadcast_to(%371, framework_op_name="aten_expand_3/BroadcastTo", output_tensors_name=["aten_expand_3/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %373 = cast(%372, framework_op_name="aten_expand_3/Cast_1", output_tensors_name=["aten_expand_3/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %374 = reshape(%322, framework_op_name="aten_einsum/einsum/Reshape", output_tensors_name=["aten_einsum/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape", newshape=[1536, 256]) // ty=Tensor[(1536, 256), float32]
  %375 = nn.dense(%374, meta[relay.Constant][105] // ty=Tensor[(1, 256), float32], framework_op_name="aten_einsum/einsum/MatMul", output_tensors_name=["aten_einsum/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/MatMul", units=1) // ty=Tensor[(1536, 1), float32]
  %376 = reshape(%375, framework_op_name="aten_einsum/einsum/Reshape_2", output_tensors_name=["aten_einsum/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape_2", newshape=[3, 512]) // ty=Tensor[(3, 512), float32]
  %377 = add(%376, meta[relay.Constant][106] // ty=Tensor[(1,), float32], framework_op_name="aten_add_2/add", output_tensors_name=["aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_2/add", axis=0) // ty=Tensor[(3, 512), float32]
  %378 = multiply(%377, meta[relay.Constant][107] // ty=Tensor[(1,), float32], framework_op_name="aten_div/truediv", output_tensors_name=["aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", axis=0) // ty=Tensor[(3, 512), float32]
  %379 = reshape(%378, framework_op_name="aten_reshape_2/Reshape", output_tensors_name=["aten_reshape_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_2/Reshape", newshape=[-1]) // ty=Tensor[(1536,), float32]
  %380 = add(meta[relay.Constant][99] // ty=Tensor[(3, 512), int64], %350, framework_op_name="aten_add_5/add", output_tensors_name=["aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_5/add", axis=0) // ty=Tensor[(3, 512), int64]
  %381 = reshape(%380, framework_op_name="aten_view_6/Reshape", output_tensors_name=["aten_view_6/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_6/Reshape", newshape=[-1]) // ty=Tensor[(1536,), int64]
  %382 = cast(%381, framework_op_name="aten_expand_4/Cast", output_tensors_name=["aten_expand_4/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %383 = broadcast_to(%382, framework_op_name="aten_expand_4/BroadcastTo", output_tensors_name=["aten_expand_4/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %384 = cast(%383, framework_op_name="aten_expand_4/Cast_1", output_tensors_name=["aten_expand_4/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %385 = cast(%381, framework_op_name="aten_expand_5/Cast", output_tensors_name=["aten_expand_5/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast", dtype="float32") // ty=Tensor[(1536,), float32]
  %386 = broadcast_to(%385, framework_op_name="aten_expand_5/BroadcastTo", output_tensors_name=["aten_expand_5/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/BroadcastTo", shape=[1536]) // ty=Tensor[(1536,), float32]
  %387 = cast(%386, framework_op_name="aten_expand_5/Cast_1", output_tensors_name=["aten_expand_5/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast_1", dtype="int64") // ty=Tensor[(1536,), int64]
  %388 = add(meta[relay.Constant][99] // ty=Tensor[(3, 512), int64], %350, framework_op_name="aten_add_6/add", output_tensors_name=["aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_6/add", axis=0) // ty=Tensor[(3, 512), int64]
  %389 = reshape(%388, framework_op_name="aten_view_8/Reshape", output_tensors_name=["aten_view_8/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_8/Reshape", newshape=[-1]) // ty=Tensor[(1536,), int64]
  %390 = (%330, meta[relay.Constant][96] // ty=Tensor[(1,), int64], %350, %352, %357, meta[relay.Constant][100] // ty=Tensor[(6144,), float32], meta[relay.Constant][101] // ty=Tensor[(1536,), float32], %360, %365, %370, meta[relay.Constant][100] // ty=Tensor[(6144,), float32], meta[relay.Constant][101] // ty=Tensor[(1536,), float32], %373, meta[relay.Constant][104] // ty=Tensor[(3, 2048), int64], %379, %384, meta[relay.Constant][100] // ty=Tensor[(6144,), float32], meta[relay.Constant][101] // ty=Tensor[(1536,), float32], %387, meta[relay.Constant][108] // ty=Tensor[(1536,), int64], %389, meta[relay.Constant][104] // ty=Tensor[(3, 2048), int64])
  %390
}
%391
// meta data omitted. you can use show_meta_data=True to include meta data