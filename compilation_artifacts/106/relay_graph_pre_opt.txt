v0.0.1
%584 = fn (%v1:0: Tensor[(3, 128, 256), float32], %v2:0: Tensor[(3, 128, 256), float32], %v3:0: Tensor[(3, 128, 256), float32], %v4:0: Tensor[(3, 128, 256), float32], %v5:0: Tensor[(3, 128, 256), float32], %v6:0: Tensor[(3, 128, 256), float32], %v7:0: Tensor[(3, 128, 256), float32], %v8:0: Tensor[(3, 128, 256), float32], %v9:0: Tensor[(3, 128, 256), float32], %TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEmbeddings_27/LayerNorm_306/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEmbeddings_27/LayerNorm_306/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0: Tensor[(1,), float32], %TapasModel_7/aten_rsub/Const:0: Tensor[(1,), float32], %TapasModel_7/aten_rsub/Const_1:0: Tensor[(1,), int32], %tensor.1:0: Tensor[(3, 128), int64], %TapasModel_7/aten_mul/Const:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/prim_Constant/Const:0: Tensor[(1024, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0: Tensor[(1024,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Sqrt/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/prim_Constant/Const:0: Tensor[(256, 1024), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/prim_Constant/Const:0: Tensor[(1024, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0: Tensor[(1024,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Sqrt/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/prim_Constant/Const:0: Tensor[(256, 1024), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/prim_Constant/Const:0: Tensor[(1024, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0: Tensor[(1024,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Sqrt/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/prim_Constant/Const:0: Tensor[(256, 1024), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/prim_Constant/Const:0: Tensor[(1024, 256), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0: Tensor[(1024,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Sqrt/x:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/prim_Constant/Const:0: Tensor[(256, 1024), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0: Tensor[(1,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0: Tensor[(256,), float32], %TapasModel_7/TapasPooler_29/Linear_10/prim_Constant/Const:0: Tensor[(256, 256), float32], %TapasModel_7/TapasPooler_29/Linear_10/prim_Constant_1/Const:0: Tensor[(256,), float32], %aten_to_5/Const:0: Tensor[(1,), int64], %tensor.9:0: Tensor[(3, 128, 7), int64], %aten_min_1/Const:0: Tensor[(1,), int64], %aten_min/Const:0: Tensor[(1,), int64], %aten_arange/range: Tensor[(3,), int32], %aten_mul_1/Const:0: Tensor[(1,), int64], %aten_ones/ones:0: Tensor[(384,), float32], %prim_Constant_162/Const:0: Tensor[(256,), float32], %aten_add_3/Const:0: Tensor[(1,), float32], %aten_arange_1/range: Tensor[(3,), int32], %aten_ones_1/ones:0: Tensor[(384,), float32], %aten_arange_2/range: Tensor[(2048,), int32], %prim_Constant_156/Const:0: Tensor[(256,), float32], %aten_add_2/Const:0: Tensor[(1,), float32], %aten_div/Const:0: Tensor[(1,), float32], %aten_arange_3/range: Tensor[(3,), int32], %aten_ones_2/ones:0: Tensor[(384,), float32], %aten_zeros_like/zeros_like:0: Tensor[(3, 128), float32], %aten_arange_4/range: Tensor[(3,), int32], %aten_arange_5/range: Tensor[(2048,), int32]) -> (Tensor[(3, 256), float32], Tensor[(1,), int64], Tensor[(3, 128), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(3, 2048), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(384,), int64], Tensor[(384,), int64], Tensor[(3, 2048), int64]) {
  %0 = add(%v1:0, %v2:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %1 = add(%0, %v3:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %2 = add(%1, %v4:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %3 = add(%2, %v5:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %4 = add(%3, %v6:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %5 = add(%4, %v7:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %6 = add(%5, %v8:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %7 = add(%6, %v9:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_7/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %8 = sum(%7, framework_op_name="sum0", output_tensors_name=["sum0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %9 = multiply_scalar(%8, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %10 = copy(%9, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %11 = subtract(%7, %10, framework_op_name="subtract0", output_tensors_name=["subtract0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %12 = multiply(%11, %11, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %13 = sum(%12, framework_op_name="sum1", output_tensors_name=["sum1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %14 = multiply_scalar(%13, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %15 = add(%14, %TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %16 = sqrt(%15, framework_op_name="sqrt0", output_tensors_name=["sqrt0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %17 = rdivide_scalar(%16, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %18 = multiply(%17, %TapasModel_7/TapasEmbeddings_27/LayerNorm_306/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %19 = multiply(%7, %18, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %20 = multiply(%9, %18, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %21 = subtract(%TapasModel_7/TapasEmbeddings_27/LayerNorm_306/prim_Constant_2/Const:0, %20, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %22 = add(%19, %21, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %23 = reshape(%22, framework_op_name="reshape0", output_tensors_name=["reshape0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %24 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %25 = reshape(%24, framework_op_name="reshape1", output_tensors_name=["reshape1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %26 = transpose(%25, framework_op_name="transpose0", output_tensors_name=["transpose0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %27 = nn.batch_matmul(%23, %26, framework_op_name="nn.batch_matmul0", output_tensors_name=["nn.batch_matmul0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %28 = reshape(%27, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %29 = add(%28, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %30 = reshape(%29, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %31 = transpose(%30, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %32 = reshape(%31, framework_op_name="reshape2", output_tensors_name=["reshape2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %33 = reshape(%22, framework_op_name="reshape3", output_tensors_name=["reshape3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %34 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %35 = reshape(%34, framework_op_name="reshape4", output_tensors_name=["reshape4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %36 = transpose(%35, framework_op_name="transpose1", output_tensors_name=["transpose1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %37 = nn.batch_matmul(%33, %36, framework_op_name="nn.batch_matmul1", output_tensors_name=["nn.batch_matmul1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %38 = reshape(%37, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %39 = add(%38, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %40 = reshape(%39, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %41 = transpose(%40, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %42 = transpose(%41, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %43 = reshape(%42, framework_op_name="reshape5", output_tensors_name=["reshape5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %44 = transpose(%43, framework_op_name="transpose2", output_tensors_name=["transpose2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %45 = nn.batch_matmul(%32, %44, framework_op_name="nn.batch_matmul2", output_tensors_name=["nn.batch_matmul2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %46 = reshape(%45, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %47 = rdivide_scalar(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0, framework_op_name="rdivide_scalar0", output_tensors_name=["rdivide_scalar0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %48 = multiply(%46, %47, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %49 = cast(%TapasModel_7/aten_rsub/Const_1:0, framework_op_name="TapasModel_7/aten_rsub/Cast", output_tensors_name=["TapasModel_7/aten_rsub/Cast:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/Cast", dtype="float32") // ty=Tensor[(1,), float32]
  %50 = strided_slice(%tensor.1:0, framework_op_name="strided_slice0", output_tensors_name=["strided_slice0:0"], input_tensors_name=[], framework_op_debug_info="aten_slice/StridedSlice", begin=[0, 0], end=[3, 128], strides=[1, 1]) // ty=Tensor[(3, 128), int64]
  %51 = reshape(%50, framework_op_name="aten_slice/StridedSlice", output_tensors_name=["aten_slice/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice/StridedSlice", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %52 = strided_slice(%51, framework_op_name="strided_slice1", output_tensors_name=["strided_slice1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice/StridedSlice", begin=[0, 0], end=[3, 128], strides=[1, 1]) // ty=Tensor[(3, 128), int64]
  %53 = reshape(%52, framework_op_name="TapasModel_7/aten_slice/StridedSlice", output_tensors_name=["TapasModel_7/aten_slice/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice/StridedSlice", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %54 = expand_dims(%53, framework_op_name="TapasModel_7/aten_unsqueeze/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze/ExpandDims", axis=1) // ty=Tensor[(3, 1, 128), int64]
  %55 = expand_dims(%54, framework_op_name="TapasModel_7/aten_unsqueeze_1/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze_1/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze_1/ExpandDims", axis=2) // ty=Tensor[(3, 1, 1, 128), int64]
  %56 = strided_slice(%55, framework_op_name="strided_slice2", output_tensors_name=["strided_slice2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_1/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %57 = reshape(%56, framework_op_name="TapasModel_7/aten_slice_1/StridedSlice", output_tensors_name=["TapasModel_7/aten_slice_1/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_1/StridedSlice", newshape=[3, 1, 1, 128]) // ty=Tensor[(3, 1, 1, 128), int64]
  %58 = strided_slice(%57, framework_op_name="strided_slice3", output_tensors_name=["strided_slice3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_2/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %59 = reshape(%58, framework_op_name="TapasModel_7/aten_slice_2/StridedSlice", output_tensors_name=["TapasModel_7/aten_slice_2/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_2/StridedSlice", newshape=[3, 1, 1, 128]) // ty=Tensor[(3, 1, 1, 128), int64]
  %60 = strided_slice(%59, framework_op_name="strided_slice4", output_tensors_name=["strided_slice4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_3/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %61 = reshape(%60, framework_op_name="TapasModel_7/aten_slice_3/StridedSlice", output_tensors_name=["TapasModel_7/aten_slice_3/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_3/StridedSlice", newshape=[3, 1, 1, 128]) // ty=Tensor[(3, 1, 1, 128), int64]
  %62 = strided_slice(%61, framework_op_name="strided_slice5", output_tensors_name=["strided_slice5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_4/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %63 = reshape(%62, framework_op_name="TapasModel_7/aten_slice_4/StridedSlice", output_tensors_name=["TapasModel_7/aten_slice_4/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_4/StridedSlice", newshape=[3, 1, 1, 128]) // ty=Tensor[(3, 1, 1, 128), int64]
  %64 = cast(%63, framework_op_name="TapasModel_7/aten_to/Cast", output_tensors_name=["TapasModel_7/aten_to/Cast:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_to/Cast", dtype="float32") // ty=Tensor[(3, 1, 1, 128), float32]
  %65 = multiply(%49, %64, framework_op_name="TapasModel_7/aten_rsub/mul", output_tensors_name=["TapasModel_7/aten_rsub/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/mul", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %66 = subtract(%TapasModel_7/aten_rsub/Const:0, %65, framework_op_name="TapasModel_7/aten_rsub/sub", output_tensors_name=["TapasModel_7/aten_rsub/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/sub", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %67 = multiply(%66, %TapasModel_7/aten_mul/Const:0, framework_op_name="TapasModel_7/aten_mul/mul", output_tensors_name=["TapasModel_7/aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_mul/mul", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %68 = broadcast_to(%67, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %69 = add(%48, %68, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %70 = nn.softmax(%69, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %71 = reshape(%70, framework_op_name="reshape6", output_tensors_name=["reshape6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %72 = reshape(%22, framework_op_name="reshape7", output_tensors_name=["reshape7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %73 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %74 = reshape(%73, framework_op_name="reshape8", output_tensors_name=["reshape8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %75 = transpose(%74, framework_op_name="transpose3", output_tensors_name=["transpose3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %76 = nn.batch_matmul(%72, %75, framework_op_name="nn.batch_matmul3", output_tensors_name=["nn.batch_matmul3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %77 = reshape(%76, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %78 = add(%77, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %79 = reshape(%78, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %80 = transpose(%79, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %81 = reshape(%80, framework_op_name="reshape9", output_tensors_name=["reshape9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %82 = transpose(%81, framework_op_name="transpose4", output_tensors_name=["transpose4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %83 = nn.batch_matmul(%71, %82, framework_op_name="nn.batch_matmul4", output_tensors_name=["nn.batch_matmul4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %84 = reshape(%83, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %85 = transpose(%84, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %86 = reshape(%85, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %87 = reshape(%86, framework_op_name="reshape10", output_tensors_name=["reshape10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %88 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %89 = reshape(%88, framework_op_name="reshape11", output_tensors_name=["reshape11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %90 = transpose(%89, framework_op_name="transpose5", output_tensors_name=["transpose5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %91 = nn.batch_matmul(%87, %90, framework_op_name="nn.batch_matmul5", output_tensors_name=["nn.batch_matmul5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %92 = reshape(%91, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %93 = add(%92, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %94 = add(%93, %22, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %95 = sum(%94, framework_op_name="sum2", output_tensors_name=["sum2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %96 = multiply_scalar(%95, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %97 = copy(%96, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %98 = subtract(%94, %97, framework_op_name="subtract1", output_tensors_name=["subtract1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %99 = multiply(%98, %98, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %100 = sum(%99, framework_op_name="sum3", output_tensors_name=["sum3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %101 = multiply_scalar(%100, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %102 = add(%101, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %103 = sqrt(%102, framework_op_name="sqrt1", output_tensors_name=["sqrt1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %104 = rdivide_scalar(%103, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %105 = multiply(%104, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %106 = multiply(%94, %105, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %107 = multiply(%96, %105, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %108 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0, %107, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %109 = add(%106, %108, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %110 = reshape(%109, framework_op_name="reshape12", output_tensors_name=["reshape12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %111 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 1024), float32]
  %112 = reshape(%111, framework_op_name="reshape13", output_tensors_name=["reshape13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[1, 256, 1024]) // ty=Tensor[(1, 256, 1024), float32]
  %113 = transpose(%112, framework_op_name="transpose6", output_tensors_name=["transpose6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 1024, 256), float32]
  %114 = nn.batch_matmul(%110, %113, framework_op_name="nn.batch_matmul6", output_tensors_name=["nn.batch_matmul6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %115 = reshape(%114, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %116 = add(%115, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %117 = sqrt(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Sqrt/x:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Sqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Sqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Sqrt", axis=0) // ty=Tensor[(1,), float32]
  %118 = rdivide_scalar(%117, framework_op_name="rdivide_scalar1", output_tensors_name=["rdivide_scalar1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %119 = multiply(%116, %118, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %120 = erf(%119, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %121 = add(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add/x:0, %120, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %122 = multiply(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul/x:0, %121, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %123 = multiply(%116, %122, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %124 = reshape(%123, framework_op_name="reshape14", output_tensors_name=["reshape14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %125 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(1024, 256), float32]
  %126 = reshape(%125, framework_op_name="reshape15", output_tensors_name=["reshape15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[1, 1024, 256]) // ty=Tensor[(1, 1024, 256), float32]
  %127 = transpose(%126, framework_op_name="transpose7", output_tensors_name=["transpose7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 1024), float32]
  %128 = nn.batch_matmul(%124, %127, framework_op_name="nn.batch_matmul7", output_tensors_name=["nn.batch_matmul7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %129 = reshape(%128, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %130 = add(%129, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %131 = add(%130, %109, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %132 = sum(%131, framework_op_name="sum4", output_tensors_name=["sum4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %133 = multiply_scalar(%132, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %134 = copy(%133, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %135 = subtract(%131, %134, framework_op_name="subtract2", output_tensors_name=["subtract2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %136 = multiply(%135, %135, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %137 = sum(%136, framework_op_name="sum5", output_tensors_name=["sum5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %138 = multiply_scalar(%137, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %139 = add(%138, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %140 = sqrt(%139, framework_op_name="sqrt2", output_tensors_name=["sqrt2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %141 = rdivide_scalar(%140, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %142 = multiply(%141, %TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %143 = multiply(%131, %142, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %144 = multiply(%133, %142, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %145 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0, %144, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %146 = add(%143, %145, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %147 = reshape(%146, framework_op_name="reshape16", output_tensors_name=["reshape16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %148 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %149 = reshape(%148, framework_op_name="reshape17", output_tensors_name=["reshape17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %150 = transpose(%149, framework_op_name="transpose8", output_tensors_name=["transpose8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %151 = nn.batch_matmul(%147, %150, framework_op_name="nn.batch_matmul8", output_tensors_name=["nn.batch_matmul8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %152 = reshape(%151, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %153 = add(%152, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %154 = reshape(%153, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %155 = transpose(%154, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %156 = reshape(%155, framework_op_name="reshape18", output_tensors_name=["reshape18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %157 = reshape(%146, framework_op_name="reshape19", output_tensors_name=["reshape19:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %158 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %159 = reshape(%158, framework_op_name="reshape20", output_tensors_name=["reshape20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %160 = transpose(%159, framework_op_name="transpose9", output_tensors_name=["transpose9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %161 = nn.batch_matmul(%157, %160, framework_op_name="nn.batch_matmul9", output_tensors_name=["nn.batch_matmul9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %162 = reshape(%161, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %163 = add(%162, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %164 = reshape(%163, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %165 = transpose(%164, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %166 = transpose(%165, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %167 = reshape(%166, framework_op_name="reshape21", output_tensors_name=["reshape21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %168 = transpose(%167, framework_op_name="transpose10", output_tensors_name=["transpose10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %169 = nn.batch_matmul(%156, %168, framework_op_name="nn.batch_matmul10", output_tensors_name=["nn.batch_matmul10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %170 = reshape(%169, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %171 = rdivide_scalar(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0, framework_op_name="rdivide_scalar2", output_tensors_name=["rdivide_scalar2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %172 = multiply(%170, %171, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %173 = broadcast_to(%67, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %174 = add(%172, %173, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %175 = nn.softmax(%174, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %176 = reshape(%175, framework_op_name="reshape22", output_tensors_name=["reshape22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %177 = reshape(%146, framework_op_name="reshape23", output_tensors_name=["reshape23:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %178 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %179 = reshape(%178, framework_op_name="reshape24", output_tensors_name=["reshape24:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %180 = transpose(%179, framework_op_name="transpose11", output_tensors_name=["transpose11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %181 = nn.batch_matmul(%177, %180, framework_op_name="nn.batch_matmul11", output_tensors_name=["nn.batch_matmul11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %182 = reshape(%181, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %183 = add(%182, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %184 = reshape(%183, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %185 = transpose(%184, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %186 = reshape(%185, framework_op_name="reshape25", output_tensors_name=["reshape25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %187 = transpose(%186, framework_op_name="transpose12", output_tensors_name=["transpose12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %188 = nn.batch_matmul(%176, %187, framework_op_name="nn.batch_matmul12", output_tensors_name=["nn.batch_matmul12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %189 = reshape(%188, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %190 = transpose(%189, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %191 = reshape(%190, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %192 = reshape(%191, framework_op_name="reshape26", output_tensors_name=["reshape26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %193 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %194 = reshape(%193, framework_op_name="reshape27", output_tensors_name=["reshape27:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %195 = transpose(%194, framework_op_name="transpose13", output_tensors_name=["transpose13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %196 = nn.batch_matmul(%192, %195, framework_op_name="nn.batch_matmul13", output_tensors_name=["nn.batch_matmul13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %197 = reshape(%196, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %198 = add(%197, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %199 = add(%198, %146, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %200 = sum(%199, framework_op_name="sum6", output_tensors_name=["sum6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %201 = multiply_scalar(%200, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %202 = copy(%201, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %203 = subtract(%199, %202, framework_op_name="subtract3", output_tensors_name=["subtract3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %204 = multiply(%203, %203, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %205 = sum(%204, framework_op_name="sum7", output_tensors_name=["sum7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %206 = multiply_scalar(%205, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %207 = add(%206, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %208 = sqrt(%207, framework_op_name="sqrt3", output_tensors_name=["sqrt3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %209 = rdivide_scalar(%208, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %210 = multiply(%209, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %211 = multiply(%199, %210, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %212 = multiply(%201, %210, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %213 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0, %212, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %214 = add(%211, %213, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %215 = reshape(%214, framework_op_name="reshape28", output_tensors_name=["reshape28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %216 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 1024), float32]
  %217 = reshape(%216, framework_op_name="reshape29", output_tensors_name=["reshape29:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[1, 256, 1024]) // ty=Tensor[(1, 256, 1024), float32]
  %218 = transpose(%217, framework_op_name="transpose14", output_tensors_name=["transpose14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 1024, 256), float32]
  %219 = nn.batch_matmul(%215, %218, framework_op_name="nn.batch_matmul14", output_tensors_name=["nn.batch_matmul14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %220 = reshape(%219, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %221 = add(%220, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %222 = sqrt(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Sqrt/x:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Sqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Sqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Sqrt", axis=0) // ty=Tensor[(1,), float32]
  %223 = rdivide_scalar(%222, framework_op_name="rdivide_scalar3", output_tensors_name=["rdivide_scalar3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %224 = multiply(%221, %223, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %225 = erf(%224, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %226 = add(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add/x:0, %225, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %227 = multiply(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul/x:0, %226, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %228 = multiply(%221, %227, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %229 = reshape(%228, framework_op_name="reshape30", output_tensors_name=["reshape30:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %230 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(1024, 256), float32]
  %231 = reshape(%230, framework_op_name="reshape31", output_tensors_name=["reshape31:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[1, 1024, 256]) // ty=Tensor[(1, 1024, 256), float32]
  %232 = transpose(%231, framework_op_name="transpose15", output_tensors_name=["transpose15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 1024), float32]
  %233 = nn.batch_matmul(%229, %232, framework_op_name="nn.batch_matmul15", output_tensors_name=["nn.batch_matmul15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %234 = reshape(%233, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %235 = add(%234, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %236 = add(%235, %214, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %237 = sum(%236, framework_op_name="sum8", output_tensors_name=["sum8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %238 = multiply_scalar(%237, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %239 = copy(%238, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %240 = subtract(%236, %239, framework_op_name="subtract4", output_tensors_name=["subtract4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %241 = multiply(%240, %240, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %242 = sum(%241, framework_op_name="sum9", output_tensors_name=["sum9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %243 = multiply_scalar(%242, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %244 = add(%243, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %245 = sqrt(%244, framework_op_name="sqrt4", output_tensors_name=["sqrt4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %246 = rdivide_scalar(%245, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %247 = multiply(%246, %TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %248 = multiply(%236, %247, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %249 = multiply(%238, %247, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %250 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0, %249, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %251 = add(%248, %250, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %252 = reshape(%251, framework_op_name="reshape32", output_tensors_name=["reshape32:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %253 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %254 = reshape(%253, framework_op_name="reshape33", output_tensors_name=["reshape33:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %255 = transpose(%254, framework_op_name="transpose16", output_tensors_name=["transpose16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %256 = nn.batch_matmul(%252, %255, framework_op_name="nn.batch_matmul16", output_tensors_name=["nn.batch_matmul16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %257 = reshape(%256, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %258 = add(%257, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %259 = reshape(%258, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %260 = transpose(%259, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %261 = reshape(%260, framework_op_name="reshape34", output_tensors_name=["reshape34:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %262 = reshape(%251, framework_op_name="reshape35", output_tensors_name=["reshape35:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %263 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %264 = reshape(%263, framework_op_name="reshape36", output_tensors_name=["reshape36:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %265 = transpose(%264, framework_op_name="transpose17", output_tensors_name=["transpose17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %266 = nn.batch_matmul(%262, %265, framework_op_name="nn.batch_matmul17", output_tensors_name=["nn.batch_matmul17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %267 = reshape(%266, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %268 = add(%267, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %269 = reshape(%268, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %270 = transpose(%269, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %271 = transpose(%270, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %272 = reshape(%271, framework_op_name="reshape37", output_tensors_name=["reshape37:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %273 = transpose(%272, framework_op_name="transpose18", output_tensors_name=["transpose18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %274 = nn.batch_matmul(%261, %273, framework_op_name="nn.batch_matmul18", output_tensors_name=["nn.batch_matmul18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %275 = reshape(%274, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %276 = rdivide_scalar(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0, framework_op_name="rdivide_scalar4", output_tensors_name=["rdivide_scalar4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %277 = multiply(%275, %276, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %278 = broadcast_to(%67, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %279 = add(%277, %278, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %280 = nn.softmax(%279, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %281 = reshape(%280, framework_op_name="reshape38", output_tensors_name=["reshape38:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %282 = reshape(%251, framework_op_name="reshape39", output_tensors_name=["reshape39:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %283 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %284 = reshape(%283, framework_op_name="reshape40", output_tensors_name=["reshape40:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %285 = transpose(%284, framework_op_name="transpose19", output_tensors_name=["transpose19:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %286 = nn.batch_matmul(%282, %285, framework_op_name="nn.batch_matmul19", output_tensors_name=["nn.batch_matmul19:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %287 = reshape(%286, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %288 = add(%287, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %289 = reshape(%288, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %290 = transpose(%289, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %291 = reshape(%290, framework_op_name="reshape41", output_tensors_name=["reshape41:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %292 = transpose(%291, framework_op_name="transpose20", output_tensors_name=["transpose20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %293 = nn.batch_matmul(%281, %292, framework_op_name="nn.batch_matmul20", output_tensors_name=["nn.batch_matmul20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %294 = reshape(%293, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %295 = transpose(%294, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %296 = reshape(%295, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %297 = reshape(%296, framework_op_name="reshape42", output_tensors_name=["reshape42:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %298 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %299 = reshape(%298, framework_op_name="reshape43", output_tensors_name=["reshape43:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %300 = transpose(%299, framework_op_name="transpose21", output_tensors_name=["transpose21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %301 = nn.batch_matmul(%297, %300, framework_op_name="nn.batch_matmul21", output_tensors_name=["nn.batch_matmul21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %302 = reshape(%301, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %303 = add(%302, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %304 = add(%303, %251, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %305 = sum(%304, framework_op_name="sum10", output_tensors_name=["sum10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %306 = multiply_scalar(%305, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %307 = copy(%306, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %308 = subtract(%304, %307, framework_op_name="subtract5", output_tensors_name=["subtract5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %309 = multiply(%308, %308, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %310 = sum(%309, framework_op_name="sum11", output_tensors_name=["sum11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %311 = multiply_scalar(%310, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %312 = add(%311, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %313 = sqrt(%312, framework_op_name="sqrt5", output_tensors_name=["sqrt5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %314 = rdivide_scalar(%313, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %315 = multiply(%314, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %316 = multiply(%304, %315, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %317 = multiply(%306, %315, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %318 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0, %317, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %319 = add(%316, %318, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %320 = reshape(%319, framework_op_name="reshape44", output_tensors_name=["reshape44:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %321 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 1024), float32]
  %322 = reshape(%321, framework_op_name="reshape45", output_tensors_name=["reshape45:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[1, 256, 1024]) // ty=Tensor[(1, 256, 1024), float32]
  %323 = transpose(%322, framework_op_name="transpose22", output_tensors_name=["transpose22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 1024, 256), float32]
  %324 = nn.batch_matmul(%320, %323, framework_op_name="nn.batch_matmul22", output_tensors_name=["nn.batch_matmul22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %325 = reshape(%324, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %326 = add(%325, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %327 = sqrt(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Sqrt/x:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Sqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Sqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Sqrt", axis=0) // ty=Tensor[(1,), float32]
  %328 = rdivide_scalar(%327, framework_op_name="rdivide_scalar5", output_tensors_name=["rdivide_scalar5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %329 = multiply(%326, %328, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %330 = erf(%329, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %331 = add(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add/x:0, %330, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %332 = multiply(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul/x:0, %331, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %333 = multiply(%326, %332, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %334 = reshape(%333, framework_op_name="reshape46", output_tensors_name=["reshape46:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %335 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(1024, 256), float32]
  %336 = reshape(%335, framework_op_name="reshape47", output_tensors_name=["reshape47:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[1, 1024, 256]) // ty=Tensor[(1, 1024, 256), float32]
  %337 = transpose(%336, framework_op_name="transpose23", output_tensors_name=["transpose23:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 1024), float32]
  %338 = nn.batch_matmul(%334, %337, framework_op_name="nn.batch_matmul23", output_tensors_name=["nn.batch_matmul23:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %339 = reshape(%338, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %340 = add(%339, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %341 = add(%340, %319, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %342 = sum(%341, framework_op_name="sum12", output_tensors_name=["sum12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %343 = multiply_scalar(%342, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %344 = copy(%343, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %345 = subtract(%341, %344, framework_op_name="subtract6", output_tensors_name=["subtract6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %346 = multiply(%345, %345, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %347 = sum(%346, framework_op_name="sum13", output_tensors_name=["sum13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %348 = multiply_scalar(%347, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %349 = add(%348, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %350 = sqrt(%349, framework_op_name="sqrt6", output_tensors_name=["sqrt6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %351 = rdivide_scalar(%350, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %352 = multiply(%351, %TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %353 = multiply(%341, %352, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %354 = multiply(%343, %352, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %355 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0, %354, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %356 = add(%353, %355, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %357 = reshape(%356, framework_op_name="reshape48", output_tensors_name=["reshape48:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %358 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %359 = reshape(%358, framework_op_name="reshape49", output_tensors_name=["reshape49:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %360 = transpose(%359, framework_op_name="transpose24", output_tensors_name=["transpose24:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %361 = nn.batch_matmul(%357, %360, framework_op_name="nn.batch_matmul24", output_tensors_name=["nn.batch_matmul24:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %362 = reshape(%361, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %363 = add(%362, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %364 = reshape(%363, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %365 = transpose(%364, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %366 = reshape(%365, framework_op_name="reshape50", output_tensors_name=["reshape50:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %367 = reshape(%356, framework_op_name="reshape51", output_tensors_name=["reshape51:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %368 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %369 = reshape(%368, framework_op_name="reshape52", output_tensors_name=["reshape52:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %370 = transpose(%369, framework_op_name="transpose25", output_tensors_name=["transpose25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %371 = nn.batch_matmul(%367, %370, framework_op_name="nn.batch_matmul25", output_tensors_name=["nn.batch_matmul25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %372 = reshape(%371, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %373 = add(%372, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %374 = reshape(%373, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %375 = transpose(%374, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %376 = transpose(%375, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %377 = reshape(%376, framework_op_name="reshape53", output_tensors_name=["reshape53:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %378 = transpose(%377, framework_op_name="transpose26", output_tensors_name=["transpose26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %379 = nn.batch_matmul(%366, %378, framework_op_name="nn.batch_matmul26", output_tensors_name=["nn.batch_matmul26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %380 = reshape(%379, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %381 = rdivide_scalar(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/Const:0, framework_op_name="rdivide_scalar6", output_tensors_name=["rdivide_scalar6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %382 = multiply(%380, %381, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %383 = broadcast_to(%67, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %384 = add(%382, %383, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %385 = nn.softmax(%384, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %386 = reshape(%385, framework_op_name="reshape54", output_tensors_name=["reshape54:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %387 = reshape(%356, framework_op_name="reshape55", output_tensors_name=["reshape55:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %388 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %389 = reshape(%388, framework_op_name="reshape56", output_tensors_name=["reshape56:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %390 = transpose(%389, framework_op_name="transpose27", output_tensors_name=["transpose27:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %391 = nn.batch_matmul(%387, %390, framework_op_name="nn.batch_matmul27", output_tensors_name=["nn.batch_matmul27:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %392 = reshape(%391, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %393 = add(%392, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %394 = reshape(%393, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %395 = transpose(%394, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %396 = reshape(%395, framework_op_name="reshape57", output_tensors_name=["reshape57:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %397 = transpose(%396, framework_op_name="transpose28", output_tensors_name=["transpose28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %398 = nn.batch_matmul(%386, %397, framework_op_name="nn.batch_matmul28", output_tensors_name=["nn.batch_matmul28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %399 = reshape(%398, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %400 = transpose(%399, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %401 = reshape(%400, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %402 = reshape(%401, framework_op_name="reshape58", output_tensors_name=["reshape58:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %403 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %404 = reshape(%403, framework_op_name="reshape59", output_tensors_name=["reshape59:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[1, 256, 256]) // ty=Tensor[(1, 256, 256), float32]
  %405 = transpose(%404, framework_op_name="transpose29", output_tensors_name=["transpose29:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 256), float32]
  %406 = nn.batch_matmul(%402, %405, framework_op_name="nn.batch_matmul29", output_tensors_name=["nn.batch_matmul29:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %407 = reshape(%406, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %408 = add(%407, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %409 = add(%408, %356, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %410 = sum(%409, framework_op_name="sum14", output_tensors_name=["sum14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %411 = multiply_scalar(%410, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %412 = copy(%411, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %413 = subtract(%409, %412, framework_op_name="subtract7", output_tensors_name=["subtract7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %414 = multiply(%413, %413, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %415 = sum(%414, framework_op_name="sum15", output_tensors_name=["sum15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %416 = multiply_scalar(%415, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %417 = add(%416, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %418 = sqrt(%417, framework_op_name="sqrt7", output_tensors_name=["sqrt7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %419 = rdivide_scalar(%418, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %420 = multiply(%419, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %421 = multiply(%409, %420, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %422 = multiply(%411, %420, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %423 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/prim_Constant_2/Const:0, %422, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %424 = add(%421, %423, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %425 = reshape(%424, framework_op_name="reshape60", output_tensors_name=["reshape60:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %426 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 1024), float32]
  %427 = reshape(%426, framework_op_name="reshape61", output_tensors_name=["reshape61:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[1, 256, 1024]) // ty=Tensor[(1, 256, 1024), float32]
  %428 = transpose(%427, framework_op_name="transpose30", output_tensors_name=["transpose30:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 1024, 256), float32]
  %429 = nn.batch_matmul(%425, %428, framework_op_name="nn.batch_matmul30", output_tensors_name=["nn.batch_matmul30:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %430 = reshape(%429, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %431 = add(%430, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %432 = sqrt(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Sqrt/x:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Sqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Sqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Sqrt", axis=0) // ty=Tensor[(1,), float32]
  %433 = rdivide_scalar(%432, framework_op_name="rdivide_scalar7", output_tensors_name=["rdivide_scalar7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %434 = multiply(%431, %433, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %435 = erf(%434, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %436 = add(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add/x:0, %435, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %437 = multiply(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul/x:0, %436, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %438 = multiply(%431, %437, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %439 = reshape(%438, framework_op_name="reshape62", output_tensors_name=["reshape62:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 1024]) // ty=Tensor[(3, 128, 1024), float32]
  %440 = transpose(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(1024, 256), float32]
  %441 = reshape(%440, framework_op_name="reshape63", output_tensors_name=["reshape63:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[1, 1024, 256]) // ty=Tensor[(1, 1024, 256), float32]
  %442 = transpose(%441, framework_op_name="transpose31", output_tensors_name=["transpose31:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(1, 256, 1024), float32]
  %443 = nn.batch_matmul(%439, %442, framework_op_name="nn.batch_matmul31", output_tensors_name=["nn.batch_matmul31:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %444 = reshape(%443, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %445 = add(%444, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %446 = add(%445, %424, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %447 = sum(%446, framework_op_name="sum16", output_tensors_name=["sum16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %448 = multiply_scalar(%447, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %449 = copy(%448, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %450 = subtract(%446, %449, framework_op_name="subtract8", output_tensors_name=["subtract8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %451 = multiply(%450, %450, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %452 = sum(%451, framework_op_name="sum17", output_tensors_name=["sum17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %453 = multiply_scalar(%452, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %454 = add(%453, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add/y:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %455 = sqrt(%454, framework_op_name="sqrt8", output_tensors_name=["sqrt8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %456 = rdivide_scalar(%455, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %457 = multiply(%456, %TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %458 = multiply(%446, %457, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %459 = multiply(%448, %457, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %460 = subtract(%TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/prim_Constant_2/Const:0, %459, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %461 = add(%458, %460, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %462 = strided_slice(%461, framework_op_name="strided_slice6", output_tensors_name=["strided_slice6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %463 = reshape(%462, framework_op_name="TapasModel_7/TapasPooler_29/aten_slice/StridedSlice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_slice/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice/StridedSlice", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %464 = strided_slice(%463, framework_op_name="strided_slice7", output_tensors_name=["strided_slice7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %465 = reshape(%464, framework_op_name="TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %466 = strided_slice(%465, framework_op_name="strided_slice8", output_tensors_name=["strided_slice8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %467 = reshape(%466, framework_op_name="TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %468 = strided_slice(%467, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Slice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Slice", begin=[0, 0, 0], end=[3, 1, 256]) // ty=Tensor[(3, 1, 256), float32]
  %469 = reshape(%468, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Reshape", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Reshape", newshape=[3, 256]) // ty=Tensor[(3, 256), float32]
  %470 = transpose(%TapasModel_7/TapasPooler_29/Linear_10/prim_Constant/Const:0, framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/transpose", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/transpose", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %471 = transpose(%470, framework_op_name="transpose32", output_tensors_name=["transpose32:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", axes=[1, 0]) // ty=Tensor[(256, 256), float32]
  %472 = nn.dense(%469, %471, framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", units=256) // ty=Tensor[(3, 256), float32]
  %473 = add(%472, %TapasModel_7/TapasPooler_29/Linear_10/prim_Constant_1/Const:0, framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", axis=0) // ty=Tensor[(3, 256), float32]
  %474 = tanh(%473, framework_op_name="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", output_tensors_name=["TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", axis=0) // ty=Tensor[(3, 256), float32]
  %475 = strided_slice(%tensor.9:0, framework_op_name="strided_slice9", output_tensors_name=["strided_slice9:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_7/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %476 = reshape(%475, framework_op_name="aten_slice_7/StridedSlice", output_tensors_name=["aten_slice_7/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_7/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %477 = strided_slice(%476, framework_op_name="strided_slice10", output_tensors_name=["strided_slice10:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_8/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %478 = reshape(%477, framework_op_name="aten_slice_8/StridedSlice", output_tensors_name=["aten_slice_8/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_8/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %479 = strided_slice(%478, framework_op_name="strided_slice11", output_tensors_name=["strided_slice11:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_9/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %480 = reshape(%479, framework_op_name="aten_slice_9/StridedSlice", output_tensors_name=["aten_slice_9/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_9/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %481 = strided_slice(%480, framework_op_name="strided_slice12", output_tensors_name=["strided_slice12:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_10/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %482 = reshape(%481, framework_op_name="aten_slice_10/StridedSlice", output_tensors_name=["aten_slice_10/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_10/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %483 = strided_slice(%482, framework_op_name="strided_slice13", output_tensors_name=["strided_slice13:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_11/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %484 = reshape(%483, framework_op_name="aten_slice_11/StridedSlice", output_tensors_name=["aten_slice_11/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_11/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %485 = strided_slice(%484, framework_op_name="strided_slice14", output_tensors_name=["strided_slice14:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_12/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %486 = reshape(%485, framework_op_name="aten_slice_12/StridedSlice", output_tensors_name=["aten_slice_12/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_12/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %487 = strided_slice(%486, framework_op_name="aten_select_1/Slice", output_tensors_name=["aten_select_1/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Slice", begin=[0, 0, 1], end=[3, 128, 2]) // ty=Tensor[(3, 128, 1), int64]
  %488 = reshape(%487, framework_op_name="aten_select_1/Reshape", output_tensors_name=["aten_select_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Reshape", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %489 = minimum(%488, %aten_min_1/Const:0, framework_op_name="aten_min_1/Minimum", output_tensors_name=["aten_min_1/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min_1/Minimum", axis=0) // ty=Tensor[(3, 128), int64]
  %490 = strided_slice(%tensor.9:0, framework_op_name="strided_slice15", output_tensors_name=["strided_slice15:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %491 = reshape(%490, framework_op_name="aten_slice_1/StridedSlice", output_tensors_name=["aten_slice_1/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_1/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %492 = strided_slice(%491, framework_op_name="strided_slice16", output_tensors_name=["strided_slice16:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %493 = reshape(%492, framework_op_name="aten_slice_2/StridedSlice", output_tensors_name=["aten_slice_2/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_2/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %494 = strided_slice(%493, framework_op_name="strided_slice17", output_tensors_name=["strided_slice17:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_3/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %495 = reshape(%494, framework_op_name="aten_slice_3/StridedSlice", output_tensors_name=["aten_slice_3/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_3/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %496 = strided_slice(%495, framework_op_name="strided_slice18", output_tensors_name=["strided_slice18:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_4/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %497 = reshape(%496, framework_op_name="aten_slice_4/StridedSlice", output_tensors_name=["aten_slice_4/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_4/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %498 = strided_slice(%497, framework_op_name="strided_slice19", output_tensors_name=["strided_slice19:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_5/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %499 = reshape(%498, framework_op_name="aten_slice_5/StridedSlice", output_tensors_name=["aten_slice_5/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_5/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %500 = strided_slice(%499, framework_op_name="strided_slice20", output_tensors_name=["strided_slice20:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_6/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %501 = reshape(%500, framework_op_name="aten_slice_6/StridedSlice", output_tensors_name=["aten_slice_6/StridedSlice:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_6/StridedSlice", newshape=[3, 128, 7]) // ty=Tensor[(3, 128, 7), int64]
  %502 = strided_slice(%501, framework_op_name="aten_select/Slice", output_tensors_name=["aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Slice", begin=[0, 0, 2], end=[3, 128, 3]) // ty=Tensor[(3, 128, 1), int64]
  %503 = reshape(%502, framework_op_name="aten_select/Reshape", output_tensors_name=["aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Reshape", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %504 = minimum(%503, %aten_min/Const:0, framework_op_name="aten_min/Minimum", output_tensors_name=["aten_min/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min/Minimum", axis=0) // ty=Tensor[(3, 128), int64]
  %505 = multiply(%504, %aten_to_5/Const:0, framework_op_name="aten_mul/mul", output_tensors_name=["aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul/mul", axis=0) // ty=Tensor[(3, 128), int64]
  %506 = add(%489, %505, framework_op_name="aten_add/add", output_tensors_name=["aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add/add", axis=0) // ty=Tensor[(3, 128), int64]
  %507 = cast(%tensor.1:0, framework_op_name="aten_to_8/Cast", output_tensors_name=["aten_to_8/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_8/Cast", dtype="float32") // ty=Tensor[(3, 128), float32]
  %508 = reshape(%507, framework_op_name="aten_reshape/Reshape", output_tensors_name=["aten_reshape/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape/Reshape", newshape=[-1]) // ty=Tensor[(384,), float32]
  %509 = cast(%aten_arange/range, framework_op_name="aten_mul_2/Cast", output_tensors_name=["aten_mul_2/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_2/Cast", dtype="int64") // ty=Tensor[(3,), int64]
  %510 = multiply(%aten_to_5/Const:0, %aten_mul_1/Const:0, framework_op_name="aten_mul_1/mul", output_tensors_name=["aten_mul_1/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_1/mul", axis=0) // ty=Tensor[(1,), int64]
  %511 = multiply(%509, %510, framework_op_name="aten_mul_2/mul", output_tensors_name=["aten_mul_2/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_2/mul", axis=0) // ty=Tensor[(3,), int64]
  %512 = reshape(%511, framework_op_name="aten_view/Reshape", output_tensors_name=["aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view/Reshape", newshape=[3]) // ty=Tensor[(3,), int64]
  %513 = expand_dims(%512, framework_op_name="aten_unsqueeze/ExpandDims", output_tensors_name=["aten_unsqueeze/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="aten_unsqueeze/ExpandDims", axis=-1) // ty=Tensor[(3, 1), int64]
  %514 = broadcast_to(%513, framework_op_name="aten_add_1/BroadcastTo", output_tensors_name=["aten_add_1/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_add_1/BroadcastTo", shape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %515 = add(%514, %506, framework_op_name="aten_add_1/add", output_tensors_name=["aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_1/add", axis=0) // ty=Tensor[(3, 128), int64]
  %516 = reshape(%515, framework_op_name="aten_view_1/Reshape", output_tensors_name=["aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_1/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %517 = cast(%516, framework_op_name="aten_expand/Cast", output_tensors_name=["aten_expand/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %518 = broadcast_to(%517, framework_op_name="aten_expand/BroadcastTo", output_tensors_name=["aten_expand/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %519 = cast(%518, framework_op_name="aten_expand/Cast_1", output_tensors_name=["aten_expand/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %520 = full(0f, framework_op_name="aten_zeros/zeros", output_tensors_name=["aten_zeros/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros/zeros", shape=[6144], dtype="float32") // ty=Tensor[(6144,), float32]
  %521 = cast(%516, framework_op_name="aten_expand_1/Cast", output_tensors_name=["aten_expand_1/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %522 = broadcast_to(%521, framework_op_name="aten_expand_1/BroadcastTo", output_tensors_name=["aten_expand_1/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %523 = cast(%522, framework_op_name="aten_expand_1/Cast_1", output_tensors_name=["aten_expand_1/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %524 = reshape(%461, framework_op_name="aten_einsum_1/einsum/Reshape", output_tensors_name=["aten_einsum_1/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape", newshape=[384, 256]) // ty=Tensor[(384, 256), float32]
  %525 = reshape(%prim_Constant_162/Const:0, framework_op_name="aten_einsum_1/einsum/Reshape_1", output_tensors_name=["aten_einsum_1/einsum/Reshape_1:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape_1", newshape=[256, 1]) // ty=Tensor[(256, 1), float32]
  %526 = transpose(%525, framework_op_name="transpose33", output_tensors_name=["transpose33:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/MatMul", axes=[1, 0]) // ty=Tensor[(1, 256), float32]
  %527 = nn.dense(%524, %526, framework_op_name="aten_einsum_1/einsum/MatMul", output_tensors_name=["aten_einsum_1/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/MatMul", units=1) // ty=Tensor[(384, 1), float32]
  %528 = reshape(%527, framework_op_name="aten_einsum_1/einsum/Reshape_2", output_tensors_name=["aten_einsum_1/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape_2", newshape=[3, 128]) // ty=Tensor[(3, 128), float32]
  %529 = add(%528, %aten_add_3/Const:0, framework_op_name="aten_add_3/add", output_tensors_name=["aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_3/add", axis=0) // ty=Tensor[(3, 128), float32]
  %530 = reshape(%529, framework_op_name="aten_reshape_1/Reshape", output_tensors_name=["aten_reshape_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_1/Reshape", newshape=[-1]) // ty=Tensor[(384,), float32]
  %531 = cast(%aten_arange_1/range, framework_op_name="aten_mul_3/Cast", output_tensors_name=["aten_mul_3/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_3/Cast", dtype="int64") // ty=Tensor[(3,), int64]
  %532 = multiply(%531, %510, framework_op_name="aten_mul_3/mul", output_tensors_name=["aten_mul_3/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_3/mul", axis=0) // ty=Tensor[(3,), int64]
  %533 = reshape(%532, framework_op_name="aten_view_2/Reshape", output_tensors_name=["aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_2/Reshape", newshape=[3]) // ty=Tensor[(3,), int64]
  %534 = expand_dims(%533, framework_op_name="aten_unsqueeze_1/ExpandDims", output_tensors_name=["aten_unsqueeze_1/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="aten_unsqueeze_1/ExpandDims", axis=-1) // ty=Tensor[(3, 1), int64]
  %535 = broadcast_to(%534, framework_op_name="aten_add_4/BroadcastTo", output_tensors_name=["aten_add_4/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_add_4/BroadcastTo", shape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %536 = add(%535, %506, framework_op_name="aten_add_4/add", output_tensors_name=["aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_4/add", axis=0) // ty=Tensor[(3, 128), int64]
  %537 = reshape(%536, framework_op_name="aten_view_3/Reshape", output_tensors_name=["aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_3/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %538 = cast(%537, framework_op_name="aten_expand_2/Cast", output_tensors_name=["aten_expand_2/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %539 = broadcast_to(%538, framework_op_name="aten_expand_2/BroadcastTo", output_tensors_name=["aten_expand_2/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %540 = cast(%539, framework_op_name="aten_expand_2/Cast_1", output_tensors_name=["aten_expand_2/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %541 = full(0f, framework_op_name="aten_zeros_1/zeros", output_tensors_name=["aten_zeros_1/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros_1/zeros", shape=[6144], dtype="float32") // ty=Tensor[(6144,), float32]
  %542 = cast(%537, framework_op_name="aten_expand_3/Cast", output_tensors_name=["aten_expand_3/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %543 = broadcast_to(%542, framework_op_name="aten_expand_3/BroadcastTo", output_tensors_name=["aten_expand_3/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %544 = cast(%543, framework_op_name="aten_expand_3/Cast_1", output_tensors_name=["aten_expand_3/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %545 = reshape(%aten_arange_2/range, framework_op_name="aten_view_4/Reshape", output_tensors_name=["aten_view_4/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_4/Reshape", newshape=[1, 2048]) // ty=Tensor[(1, 2048), int32]
  %546 = tile(%545, framework_op_name="aten_repeat/Tile", output_tensors_name=["aten_repeat/Tile:0"], input_tensors_name=[], framework_op_debug_info="aten_repeat/Tile", reps=[3, 1]) // ty=Tensor[(3, 2048), int32]
  %547 = cast(%546, framework_op_name="aten_to_18/Cast", output_tensors_name=["aten_to_18/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_18/Cast", dtype="int64") // ty=Tensor[(3, 2048), int64]
  %548 = reshape(%461, framework_op_name="aten_einsum/einsum/Reshape", output_tensors_name=["aten_einsum/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape", newshape=[384, 256]) // ty=Tensor[(384, 256), float32]
  %549 = reshape(%prim_Constant_156/Const:0, framework_op_name="aten_einsum/einsum/Reshape_1", output_tensors_name=["aten_einsum/einsum/Reshape_1:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape_1", newshape=[256, 1]) // ty=Tensor[(256, 1), float32]
  %550 = transpose(%549, framework_op_name="transpose34", output_tensors_name=["transpose34:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/MatMul", axes=[1, 0]) // ty=Tensor[(1, 256), float32]
  %551 = nn.dense(%548, %550, framework_op_name="aten_einsum/einsum/MatMul", output_tensors_name=["aten_einsum/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/MatMul", units=1) // ty=Tensor[(384, 1), float32]
  %552 = reshape(%551, framework_op_name="aten_einsum/einsum/Reshape_2", output_tensors_name=["aten_einsum/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape_2", newshape=[3, 128]) // ty=Tensor[(3, 128), float32]
  %553 = add(%552, %aten_add_2/Const:0, framework_op_name="aten_add_2/add", output_tensors_name=["aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_2/add", axis=0) // ty=Tensor[(3, 128), float32]
  %554 = rdivide_scalar(%aten_div/Const:0, framework_op_name="rdivide_scalar8", output_tensors_name=["rdivide_scalar8:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", scalar=1) // ty=Tensor[(1,), float32]
  %555 = multiply(%553, %554, framework_op_name="aten_div/truediv", output_tensors_name=["aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", axis=0) // ty=Tensor[(3, 128), float32]
  %556 = reshape(%555, framework_op_name="aten_reshape_2/Reshape", output_tensors_name=["aten_reshape_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_2/Reshape", newshape=[-1]) // ty=Tensor[(384,), float32]
  %557 = cast(%aten_arange_3/range, framework_op_name="aten_mul_4/Cast", output_tensors_name=["aten_mul_4/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_4/Cast", dtype="int64") // ty=Tensor[(3,), int64]
  %558 = multiply(%557, %510, framework_op_name="aten_mul_4/mul", output_tensors_name=["aten_mul_4/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_4/mul", axis=0) // ty=Tensor[(3,), int64]
  %559 = reshape(%558, framework_op_name="aten_view_5/Reshape", output_tensors_name=["aten_view_5/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_5/Reshape", newshape=[3]) // ty=Tensor[(3,), int64]
  %560 = expand_dims(%559, framework_op_name="aten_unsqueeze_2/ExpandDims", output_tensors_name=["aten_unsqueeze_2/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="aten_unsqueeze_2/ExpandDims", axis=-1) // ty=Tensor[(3, 1), int64]
  %561 = broadcast_to(%560, framework_op_name="aten_add_5/BroadcastTo", output_tensors_name=["aten_add_5/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_add_5/BroadcastTo", shape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %562 = add(%561, %506, framework_op_name="aten_add_5/add", output_tensors_name=["aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_5/add", axis=0) // ty=Tensor[(3, 128), int64]
  %563 = reshape(%562, framework_op_name="aten_view_6/Reshape", output_tensors_name=["aten_view_6/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_6/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %564 = cast(%563, framework_op_name="aten_expand_4/Cast", output_tensors_name=["aten_expand_4/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %565 = broadcast_to(%564, framework_op_name="aten_expand_4/BroadcastTo", output_tensors_name=["aten_expand_4/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %566 = cast(%565, framework_op_name="aten_expand_4/Cast_1", output_tensors_name=["aten_expand_4/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %567 = full(0f, framework_op_name="aten_zeros_2/zeros", output_tensors_name=["aten_zeros_2/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros_2/zeros", shape=[6144], dtype="float32") // ty=Tensor[(6144,), float32]
  %568 = cast(%563, framework_op_name="aten_expand_5/Cast", output_tensors_name=["aten_expand_5/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %569 = broadcast_to(%568, framework_op_name="aten_expand_5/BroadcastTo", output_tensors_name=["aten_expand_5/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %570 = cast(%569, framework_op_name="aten_expand_5/Cast_1", output_tensors_name=["aten_expand_5/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast_1", dtype="int64") // ty=Tensor[(384,), int64]
  %571 = cast(%aten_zeros_like/zeros_like:0, framework_op_name="aten_to_25/Cast", output_tensors_name=["aten_to_25/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_25/Cast", dtype="int64") // ty=Tensor[(3, 128), int64]
  %572 = reshape(%571, framework_op_name="aten_reshape_3/Reshape", output_tensors_name=["aten_reshape_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_3/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %573 = cast(%aten_arange_4/range, framework_op_name="aten_mul_5/Cast", output_tensors_name=["aten_mul_5/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_5/Cast", dtype="int64") // ty=Tensor[(3,), int64]
  %574 = multiply(%573, %510, framework_op_name="aten_mul_5/mul", output_tensors_name=["aten_mul_5/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_5/mul", axis=0) // ty=Tensor[(3,), int64]
  %575 = reshape(%574, framework_op_name="aten_view_7/Reshape", output_tensors_name=["aten_view_7/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_7/Reshape", newshape=[3]) // ty=Tensor[(3,), int64]
  %576 = expand_dims(%575, framework_op_name="aten_unsqueeze_3/ExpandDims", output_tensors_name=["aten_unsqueeze_3/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="aten_unsqueeze_3/ExpandDims", axis=-1) // ty=Tensor[(3, 1), int64]
  %577 = broadcast_to(%576, framework_op_name="aten_add_6/BroadcastTo", output_tensors_name=["aten_add_6/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_add_6/BroadcastTo", shape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %578 = add(%577, %506, framework_op_name="aten_add_6/add", output_tensors_name=["aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_6/add", axis=0) // ty=Tensor[(3, 128), int64]
  %579 = reshape(%578, framework_op_name="aten_view_8/Reshape", output_tensors_name=["aten_view_8/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_8/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %580 = reshape(%aten_arange_5/range, framework_op_name="aten_view_9/Reshape", output_tensors_name=["aten_view_9/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_9/Reshape", newshape=[1, 2048]) // ty=Tensor[(1, 2048), int32]
  %581 = tile(%580, framework_op_name="aten_repeat_1/Tile", output_tensors_name=["aten_repeat_1/Tile:0"], input_tensors_name=[], framework_op_debug_info="aten_repeat_1/Tile", reps=[3, 1]) // ty=Tensor[(3, 2048), int32]
  %582 = cast(%581, framework_op_name="aten_to_28/Cast", output_tensors_name=["aten_to_28/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_28/Cast", dtype="int64") // ty=Tensor[(3, 2048), int64]
  %583 = (%474, %aten_to_5/Const:0, %506, %508, %519, %520, %aten_ones/ones:0, %523, %530, %540, %541, %aten_ones_1/ones:0, %544, %547, %556, %566, %567, %aten_ones_2/ones:0, %570, %572, %579, %582)
  %583
}
%584