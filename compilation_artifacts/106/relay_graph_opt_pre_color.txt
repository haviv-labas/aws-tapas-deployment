v0.0.1
%423 = fn (%v1:0: Tensor[(3, 128, 256), float32], %v2:0: Tensor[(3, 128, 256), float32], %v3:0: Tensor[(3, 128, 256), float32], %v4:0: Tensor[(3, 128, 256), float32], %v5:0: Tensor[(3, 128, 256), float32], %v6:0: Tensor[(3, 128, 256), float32], %v7:0: Tensor[(3, 128, 256), float32], %v8:0: Tensor[(3, 128, 256), float32], %v9:0: Tensor[(3, 128, 256), float32], %tensor.1:0: Tensor[(3, 128), int64], %tensor.9:0: Tensor[(3, 128, 7), int64]) -> (Tensor[(3, 256), float32], Tensor[(1,), int64], Tensor[(3, 128), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(3, 2048), int64], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(6144,), float32], Tensor[(384,), float32], Tensor[(384,), int64], Tensor[(384,), int64], Tensor[(384,), int64], Tensor[(3, 2048), int64]) {
  %0 = copy(%v1:0, framework_op_name="copy42", output_tensors_name=["copy42:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %1 = copy(%v2:0, framework_op_name="copy43", output_tensors_name=["copy43:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %2 = add(%0, %1, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %3 = copy(%v3:0, framework_op_name="copy44", output_tensors_name=["copy44:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %4 = add(%2, %3, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_1/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %5 = copy(%v4:0, framework_op_name="copy45", output_tensors_name=["copy45:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %6 = add(%4, %5, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_2/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %7 = copy(%v5:0, framework_op_name="copy46", output_tensors_name=["copy46:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %8 = add(%6, %7, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_3/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %9 = copy(%v6:0, framework_op_name="copy47", output_tensors_name=["copy47:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %10 = add(%8, %9, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_4/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %11 = copy(%v7:0, framework_op_name="copy48", output_tensors_name=["copy48:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %12 = add(%10, %11, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_5/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %13 = copy(%v8:0, framework_op_name="copy49", output_tensors_name=["copy49:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %14 = add(%12, %13, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_6/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %15 = copy(%v9:0, framework_op_name="copy50", output_tensors_name=["copy50:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %16 = add(%14, %15, framework_op_name="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/aten_add_7/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/aten_add_7/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %17 = sum(%16, framework_op_name="sum0", output_tensors_name=["sum0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %18 = multiply_scalar(%17, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %19 = copy(%18, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %20 = subtract(%16, %19, framework_op_name="subtract0", output_tensors_name=["subtract0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %21 = multiply(%20, %20, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %22 = sum(%21, framework_op_name="sum1", output_tensors_name=["sum1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %23 = multiply_scalar(%22, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %24 = add(%23, meta[relay.Constant][0] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %25 = sqrt(%24, framework_op_name="sqrt0", output_tensors_name=["sqrt0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %26 = rdivide_scalar(%25, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %27 = multiply(%26, meta[relay.Constant][1] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %28 = multiply(%16, %27, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %29 = multiply(%18, %27, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %30 = subtract(meta[relay.Constant][2] // ty=Tensor[(256,), float32], %29, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %31 = add(%28, %30, framework_op_name="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %32 = nn.batch_matmul(%31, meta[relay.Constant][3] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul0", output_tensors_name=["nn.batch_matmul0:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %33 = add(%32, meta[relay.Constant][4] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %34 = reshape(%33, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %35 = transpose(%34, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %36 = reshape(%35, framework_op_name="reshape2", output_tensors_name=["reshape2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %37 = nn.batch_matmul(%31, meta[relay.Constant][5] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul1", output_tensors_name=["nn.batch_matmul1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %38 = add(%37, meta[relay.Constant][6] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %39 = reshape(%38, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %40 = transpose(%39, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %41 = transpose(%40, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %42 = reshape(%41, framework_op_name="reshape5", output_tensors_name=["reshape5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %43 = transpose(%42, framework_op_name="transpose2", output_tensors_name=["transpose2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %44 = nn.batch_matmul(%36, %43, framework_op_name="nn.batch_matmul2", output_tensors_name=["nn.batch_matmul2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %45 = reshape(%44, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %46 = multiply(%45, meta[relay.Constant][7] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %47 = copy(%tensor.1:0, framework_op_name="copy51", output_tensors_name=["copy51:0"], input_tensors_name=[], framework_op_debug_info="aten_slice/StridedSlice", axis=0) // ty=Tensor[(3, 128), int64]
  %48 = strided_slice(%47, framework_op_name="strided_slice0", output_tensors_name=["strided_slice0:0"], input_tensors_name=[], framework_op_debug_info="aten_slice/StridedSlice", begin=[0, 0], end=[3, 128], strides=[1, 1]) // ty=Tensor[(3, 128), int64]
  %49 = strided_slice(%48, framework_op_name="strided_slice1", output_tensors_name=["strided_slice1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice/StridedSlice", begin=[0, 0], end=[3, 128], strides=[1, 1]) // ty=Tensor[(3, 128), int64]
  %50 = expand_dims(%49, framework_op_name="TapasModel_7/aten_unsqueeze/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze/ExpandDims", axis=1) // ty=Tensor[(3, 1, 128), int64]
  %51 = expand_dims(%50, framework_op_name="TapasModel_7/aten_unsqueeze_1/ExpandDims", output_tensors_name=["TapasModel_7/aten_unsqueeze_1/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_unsqueeze_1/ExpandDims", axis=2) // ty=Tensor[(3, 1, 1, 128), int64]
  %52 = strided_slice(%51, framework_op_name="strided_slice2", output_tensors_name=["strided_slice2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_1/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %53 = strided_slice(%52, framework_op_name="strided_slice3", output_tensors_name=["strided_slice3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_2/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %54 = strided_slice(%53, framework_op_name="strided_slice4", output_tensors_name=["strided_slice4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_3/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %55 = strided_slice(%54, framework_op_name="strided_slice5", output_tensors_name=["strided_slice5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_slice_4/StridedSlice", begin=[0, 0, 0, 0], end=[3, 1, 1, 128], strides=[1, 1, 1, 1]) // ty=Tensor[(3, 1, 1, 128), int64]
  %56 = cast(%55, framework_op_name="TapasModel_7/aten_to/Cast", output_tensors_name=["TapasModel_7/aten_to/Cast:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_to/Cast", dtype="float32") // ty=Tensor[(3, 1, 1, 128), float32]
  %57 = multiply(meta[relay.Constant][9] // ty=Tensor[(1,), float32], %56, framework_op_name="TapasModel_7/aten_rsub/mul", output_tensors_name=["TapasModel_7/aten_rsub/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/mul", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %58 = subtract(meta[relay.Constant][8] // ty=Tensor[(1,), float32], %57, framework_op_name="TapasModel_7/aten_rsub/sub", output_tensors_name=["TapasModel_7/aten_rsub/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_rsub/sub", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %59 = multiply(%58, meta[relay.Constant][10] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/aten_mul/mul", output_tensors_name=["TapasModel_7/aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/aten_mul/mul", axis=0) // ty=Tensor[(3, 1, 1, 128), float32]
  %60 = broadcast_to(%59, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %61 = add(%46, %60, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %62 = nn.softmax(%61, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %63 = reshape(%62, framework_op_name="reshape6", output_tensors_name=["reshape6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %64 = nn.batch_matmul(%31, meta[relay.Constant][11] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul3", output_tensors_name=["nn.batch_matmul3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %65 = add(%64, meta[relay.Constant][12] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %66 = reshape(%65, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %67 = transpose(%66, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %68 = reshape(%67, framework_op_name="reshape9", output_tensors_name=["reshape9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %69 = transpose(%68, framework_op_name="transpose4", output_tensors_name=["transpose4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %70 = nn.batch_matmul(%63, %69, framework_op_name="nn.batch_matmul4", output_tensors_name=["nn.batch_matmul4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %71 = reshape(%70, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %72 = transpose(%71, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %73 = reshape(%72, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %74 = nn.batch_matmul(%73, meta[relay.Constant][13] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul5", output_tensors_name=["nn.batch_matmul5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %75 = add(%74, meta[relay.Constant][14] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %76 = add(%75, %31, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %77 = sum(%76, framework_op_name="sum2", output_tensors_name=["sum2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %78 = multiply_scalar(%77, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %79 = copy(%78, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %80 = subtract(%76, %79, framework_op_name="subtract1", output_tensors_name=["subtract1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %81 = multiply(%80, %80, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %82 = sum(%81, framework_op_name="sum3", output_tensors_name=["sum3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %83 = multiply_scalar(%82, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %84 = add(%83, meta[relay.Constant][15] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %85 = sqrt(%84, framework_op_name="sqrt1", output_tensors_name=["sqrt1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %86 = rdivide_scalar(%85, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %87 = multiply(%86, meta[relay.Constant][16] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %88 = multiply(%76, %87, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %89 = multiply(%78, %87, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %90 = subtract(meta[relay.Constant][17] // ty=Tensor[(256,), float32], %89, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %91 = add(%88, %90, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %92 = nn.batch_matmul(%91, meta[relay.Constant][18] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul6", output_tensors_name=["nn.batch_matmul6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %93 = add(%92, meta[relay.Constant][19] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %94 = multiply(%93, meta[relay.Constant][22] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %95 = erf(%94, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %96 = add(meta[relay.Constant][21] // ty=Tensor[(1,), float32], %95, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %97 = multiply(meta[relay.Constant][20] // ty=Tensor[(1,), float32], %96, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %98 = multiply(%93, %97, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %99 = nn.batch_matmul(%98, meta[relay.Constant][23] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul7", output_tensors_name=["nn.batch_matmul7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %100 = add(%99, meta[relay.Constant][24] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %101 = add(%100, %91, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %102 = sum(%101, framework_op_name="sum4", output_tensors_name=["sum4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %103 = multiply_scalar(%102, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %104 = copy(%103, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %105 = subtract(%101, %104, framework_op_name="subtract2", output_tensors_name=["subtract2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %106 = multiply(%105, %105, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %107 = sum(%106, framework_op_name="sum5", output_tensors_name=["sum5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %108 = multiply_scalar(%107, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %109 = add(%108, meta[relay.Constant][25] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %110 = sqrt(%109, framework_op_name="sqrt2", output_tensors_name=["sqrt2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %111 = rdivide_scalar(%110, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %112 = multiply(%111, meta[relay.Constant][26] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %113 = multiply(%101, %112, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %114 = multiply(%103, %112, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %115 = subtract(meta[relay.Constant][27] // ty=Tensor[(256,), float32], %114, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %116 = add(%113, %115, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %117 = nn.batch_matmul(%116, meta[relay.Constant][28] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul8", output_tensors_name=["nn.batch_matmul8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %118 = add(%117, meta[relay.Constant][29] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %119 = reshape(%118, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %120 = transpose(%119, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %121 = reshape(%120, framework_op_name="reshape18", output_tensors_name=["reshape18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %122 = nn.batch_matmul(%116, meta[relay.Constant][30] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul9", output_tensors_name=["nn.batch_matmul9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %123 = add(%122, meta[relay.Constant][31] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %124 = reshape(%123, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %125 = transpose(%124, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %126 = transpose(%125, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %127 = reshape(%126, framework_op_name="reshape21", output_tensors_name=["reshape21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %128 = transpose(%127, framework_op_name="transpose10", output_tensors_name=["transpose10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %129 = nn.batch_matmul(%121, %128, framework_op_name="nn.batch_matmul10", output_tensors_name=["nn.batch_matmul10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %130 = reshape(%129, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %131 = multiply(%130, meta[relay.Constant][32] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %132 = broadcast_to(%59, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %133 = add(%131, %132, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %134 = nn.softmax(%133, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %135 = reshape(%134, framework_op_name="reshape22", output_tensors_name=["reshape22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %136 = nn.batch_matmul(%116, meta[relay.Constant][33] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul11", output_tensors_name=["nn.batch_matmul11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %137 = add(%136, meta[relay.Constant][34] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %138 = reshape(%137, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %139 = transpose(%138, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %140 = reshape(%139, framework_op_name="reshape25", output_tensors_name=["reshape25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %141 = transpose(%140, framework_op_name="transpose12", output_tensors_name=["transpose12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %142 = nn.batch_matmul(%135, %141, framework_op_name="nn.batch_matmul12", output_tensors_name=["nn.batch_matmul12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %143 = reshape(%142, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %144 = transpose(%143, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %145 = reshape(%144, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %146 = nn.batch_matmul(%145, meta[relay.Constant][35] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul13", output_tensors_name=["nn.batch_matmul13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %147 = add(%146, meta[relay.Constant][36] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %148 = add(%147, %116, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %149 = sum(%148, framework_op_name="sum6", output_tensors_name=["sum6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %150 = multiply_scalar(%149, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %151 = copy(%150, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %152 = subtract(%148, %151, framework_op_name="subtract3", output_tensors_name=["subtract3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %153 = multiply(%152, %152, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %154 = sum(%153, framework_op_name="sum7", output_tensors_name=["sum7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %155 = multiply_scalar(%154, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %156 = add(%155, meta[relay.Constant][37] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %157 = sqrt(%156, framework_op_name="sqrt3", output_tensors_name=["sqrt3:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %158 = rdivide_scalar(%157, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %159 = multiply(%158, meta[relay.Constant][38] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %160 = multiply(%148, %159, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %161 = multiply(%150, %159, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %162 = subtract(meta[relay.Constant][39] // ty=Tensor[(256,), float32], %161, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %163 = add(%160, %162, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %164 = nn.batch_matmul(%163, meta[relay.Constant][40] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul14", output_tensors_name=["nn.batch_matmul14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %165 = add(%164, meta[relay.Constant][41] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %166 = multiply(%165, meta[relay.Constant][44] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %167 = erf(%166, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %168 = add(meta[relay.Constant][43] // ty=Tensor[(1,), float32], %167, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %169 = multiply(meta[relay.Constant][42] // ty=Tensor[(1,), float32], %168, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %170 = multiply(%165, %169, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %171 = nn.batch_matmul(%170, meta[relay.Constant][45] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul15", output_tensors_name=["nn.batch_matmul15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %172 = add(%171, meta[relay.Constant][46] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %173 = add(%172, %163, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %174 = sum(%173, framework_op_name="sum8", output_tensors_name=["sum8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %175 = multiply_scalar(%174, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %176 = copy(%175, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %177 = subtract(%173, %176, framework_op_name="subtract4", output_tensors_name=["subtract4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %178 = multiply(%177, %177, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %179 = sum(%178, framework_op_name="sum9", output_tensors_name=["sum9:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %180 = multiply_scalar(%179, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %181 = add(%180, meta[relay.Constant][47] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %182 = sqrt(%181, framework_op_name="sqrt4", output_tensors_name=["sqrt4:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %183 = rdivide_scalar(%182, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %184 = multiply(%183, meta[relay.Constant][48] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %185 = multiply(%173, %184, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %186 = multiply(%175, %184, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %187 = subtract(meta[relay.Constant][49] // ty=Tensor[(256,), float32], %186, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %188 = add(%185, %187, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %189 = nn.batch_matmul(%188, meta[relay.Constant][50] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul16", output_tensors_name=["nn.batch_matmul16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %190 = add(%189, meta[relay.Constant][51] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %191 = reshape(%190, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %192 = transpose(%191, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %193 = reshape(%192, framework_op_name="reshape34", output_tensors_name=["reshape34:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %194 = nn.batch_matmul(%188, meta[relay.Constant][52] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul17", output_tensors_name=["nn.batch_matmul17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %195 = add(%194, meta[relay.Constant][53] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %196 = reshape(%195, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %197 = transpose(%196, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %198 = transpose(%197, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %199 = reshape(%198, framework_op_name="reshape37", output_tensors_name=["reshape37:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %200 = transpose(%199, framework_op_name="transpose18", output_tensors_name=["transpose18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %201 = nn.batch_matmul(%193, %200, framework_op_name="nn.batch_matmul18", output_tensors_name=["nn.batch_matmul18:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %202 = reshape(%201, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %203 = multiply(%202, meta[relay.Constant][54] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %204 = broadcast_to(%59, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %205 = add(%203, %204, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %206 = nn.softmax(%205, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %207 = reshape(%206, framework_op_name="reshape38", output_tensors_name=["reshape38:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %208 = nn.batch_matmul(%188, meta[relay.Constant][55] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul19", output_tensors_name=["nn.batch_matmul19:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %209 = add(%208, meta[relay.Constant][56] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %210 = reshape(%209, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %211 = transpose(%210, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %212 = reshape(%211, framework_op_name="reshape41", output_tensors_name=["reshape41:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %213 = transpose(%212, framework_op_name="transpose20", output_tensors_name=["transpose20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %214 = nn.batch_matmul(%207, %213, framework_op_name="nn.batch_matmul20", output_tensors_name=["nn.batch_matmul20:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %215 = reshape(%214, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %216 = transpose(%215, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %217 = reshape(%216, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %218 = nn.batch_matmul(%217, meta[relay.Constant][57] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul21", output_tensors_name=["nn.batch_matmul21:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %219 = add(%218, meta[relay.Constant][58] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %220 = add(%219, %188, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %221 = sum(%220, framework_op_name="sum10", output_tensors_name=["sum10:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %222 = multiply_scalar(%221, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %223 = copy(%222, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %224 = subtract(%220, %223, framework_op_name="subtract5", output_tensors_name=["subtract5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %225 = multiply(%224, %224, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %226 = sum(%225, framework_op_name="sum11", output_tensors_name=["sum11:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %227 = multiply_scalar(%226, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %228 = add(%227, meta[relay.Constant][59] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %229 = sqrt(%228, framework_op_name="sqrt5", output_tensors_name=["sqrt5:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %230 = rdivide_scalar(%229, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %231 = multiply(%230, meta[relay.Constant][60] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %232 = multiply(%220, %231, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %233 = multiply(%222, %231, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %234 = subtract(meta[relay.Constant][61] // ty=Tensor[(256,), float32], %233, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %235 = add(%232, %234, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %236 = nn.batch_matmul(%235, meta[relay.Constant][62] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul22", output_tensors_name=["nn.batch_matmul22:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %237 = add(%236, meta[relay.Constant][63] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %238 = multiply(%237, meta[relay.Constant][66] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %239 = erf(%238, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %240 = add(meta[relay.Constant][65] // ty=Tensor[(1,), float32], %239, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %241 = multiply(meta[relay.Constant][64] // ty=Tensor[(1,), float32], %240, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %242 = multiply(%237, %241, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %243 = nn.batch_matmul(%242, meta[relay.Constant][67] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul23", output_tensors_name=["nn.batch_matmul23:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %244 = add(%243, meta[relay.Constant][68] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %245 = add(%244, %235, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %246 = sum(%245, framework_op_name="sum12", output_tensors_name=["sum12:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %247 = multiply_scalar(%246, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %248 = copy(%247, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %249 = subtract(%245, %248, framework_op_name="subtract6", output_tensors_name=["subtract6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %250 = multiply(%249, %249, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %251 = sum(%250, framework_op_name="sum13", output_tensors_name=["sum13:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %252 = multiply_scalar(%251, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %253 = add(%252, meta[relay.Constant][69] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %254 = sqrt(%253, framework_op_name="sqrt6", output_tensors_name=["sqrt6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %255 = rdivide_scalar(%254, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %256 = multiply(%255, meta[relay.Constant][70] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %257 = multiply(%245, %256, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %258 = multiply(%247, %256, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %259 = subtract(meta[relay.Constant][71] // ty=Tensor[(256,), float32], %258, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %260 = add(%257, %259, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %261 = nn.batch_matmul(%260, meta[relay.Constant][72] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul24", output_tensors_name=["nn.batch_matmul24:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %262 = add(%261, meta[relay.Constant][73] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %263 = reshape(%262, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %264 = transpose(%263, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %265 = reshape(%264, framework_op_name="reshape50", output_tensors_name=["reshape50:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %266 = nn.batch_matmul(%260, meta[relay.Constant][74] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul25", output_tensors_name=["nn.batch_matmul25:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %267 = add(%266, meta[relay.Constant][75] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %268 = reshape(%267, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %269 = transpose(%268, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %270 = transpose(%269, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose", axes=[0, 1, 3, 2]) // ty=Tensor[(3, 4, 64, 128), float32]
  %271 = reshape(%270, framework_op_name="reshape53", output_tensors_name=["reshape53:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[12, 64, 128]) // ty=Tensor[(12, 64, 128), float32]
  %272 = transpose(%271, framework_op_name="transpose26", output_tensors_name=["transpose26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 128, 64), float32]
  %273 = nn.batch_matmul(%265, %272, framework_op_name="nn.batch_matmul26", output_tensors_name=["nn.batch_matmul26:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", axis=0) // ty=Tensor[(12, 128, 128), float32]
  %274 = reshape(%273, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul", newshape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %275 = multiply(%274, meta[relay.Constant][76] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %276 = broadcast_to(%59, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo", shape=[3, 4, 128, 128]) // ty=Tensor[(3, 4, 128, 128), float32]
  %277 = add(%275, %276, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add", axis=0) // ty=Tensor[(3, 4, 128, 128), float32]
  %278 = nn.softmax(%277, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax") // ty=Tensor[(3, 4, 128, 128), float32]
  %279 = reshape(%278, framework_op_name="reshape54", output_tensors_name=["reshape54:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 128]) // ty=Tensor[(12, 128, 128), float32]
  %280 = nn.batch_matmul(%260, meta[relay.Constant][77] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul27", output_tensors_name=["nn.batch_matmul27:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %281 = add(%280, meta[relay.Constant][78] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %282 = reshape(%281, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape", newshape=[3, 128, 4, 64]) // ty=Tensor[(3, 128, 4, 64), float32]
  %283 = transpose(%282, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 4, 128, 64), float32]
  %284 = reshape(%283, framework_op_name="reshape57", output_tensors_name=["reshape57:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[12, 128, 64]) // ty=Tensor[(12, 128, 64), float32]
  %285 = transpose(%284, framework_op_name="transpose28", output_tensors_name=["transpose28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axes=[-3, -1, -2]) // ty=Tensor[(12, 64, 128), float32]
  %286 = nn.batch_matmul(%279, %285, framework_op_name="nn.batch_matmul28", output_tensors_name=["nn.batch_matmul28:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", axis=0) // ty=Tensor[(12, 128, 64), float32]
  %287 = reshape(%286, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul", newshape=[3, 4, 128, 64]) // ty=Tensor[(3, 4, 128, 64), float32]
  %288 = transpose(%287, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose", axes=[0, 2, 1, 3]) // ty=Tensor[(3, 128, 4, 64), float32]
  %289 = reshape(%288, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape", newshape=[3, 128, 256]) // ty=Tensor[(3, 128, 256), float32]
  %290 = nn.batch_matmul(%289, meta[relay.Constant][79] // ty=Tensor[(1, 256, 256), float32], framework_op_name="nn.batch_matmul29", output_tensors_name=["nn.batch_matmul29:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %291 = add(%290, meta[relay.Constant][80] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %292 = add(%291, %260, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %293 = sum(%292, framework_op_name="sum14", output_tensors_name=["sum14:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %294 = multiply_scalar(%293, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %295 = copy(%294, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %296 = subtract(%292, %295, framework_op_name="subtract7", output_tensors_name=["subtract7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %297 = multiply(%296, %296, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %298 = sum(%297, framework_op_name="sum15", output_tensors_name=["sum15:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %299 = multiply_scalar(%298, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %300 = add(%299, meta[relay.Constant][81] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %301 = sqrt(%300, framework_op_name="sqrt7", output_tensors_name=["sqrt7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %302 = rdivide_scalar(%301, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %303 = multiply(%302, meta[relay.Constant][82] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %304 = multiply(%292, %303, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %305 = multiply(%294, %303, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %306 = subtract(meta[relay.Constant][83] // ty=Tensor[(256,), float32], %305, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %307 = add(%304, %306, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %308 = nn.batch_matmul(%307, meta[relay.Constant][84] // ty=Tensor[(1, 1024, 256), float32], framework_op_name="nn.batch_matmul30", output_tensors_name=["nn.batch_matmul30:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %309 = add(%308, meta[relay.Constant][85] // ty=Tensor[(1024,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %310 = multiply(%309, meta[relay.Constant][88] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %311 = erf(%310, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %312 = add(meta[relay.Constant][87] // ty=Tensor[(1,), float32], %311, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %313 = multiply(meta[relay.Constant][86] // ty=Tensor[(1,), float32], %312, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %314 = multiply(%309, %313, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1", axis=0) // ty=Tensor[(3, 128, 1024), float32]
  %315 = nn.batch_matmul(%314, meta[relay.Constant][89] // ty=Tensor[(1, 256, 1024), float32], framework_op_name="nn.batch_matmul31", output_tensors_name=["nn.batch_matmul31:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/MatMul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %316 = add(%315, meta[relay.Constant][90] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %317 = add(%316, %307, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %318 = sum(%317, framework_op_name="sum16", output_tensors_name=["sum16:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %319 = multiply_scalar(%318, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %320 = copy(%319, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %321 = subtract(%317, %320, framework_op_name="subtract8", output_tensors_name=["subtract8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %322 = multiply(%321, %321, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %323 = sum(%322, framework_op_name="sum17", output_tensors_name=["sum17:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", axis=[2], keepdims=True) // ty=Tensor[(3, 128, 1), float32]
  %324 = multiply_scalar(%323, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance", scalar=0.00390625) // ty=Tensor[(3, 128, 1), float32]
  %325 = add(%324, meta[relay.Constant][91] // ty=Tensor[(1,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %326 = sqrt(%325, framework_op_name="sqrt8", output_tensors_name=["sqrt8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", axis=0) // ty=Tensor[(3, 128, 1), float32]
  %327 = rdivide_scalar(%326, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt", scalar=1) // ty=Tensor[(3, 128, 1), float32]
  %328 = multiply(%327, meta[relay.Constant][92] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %329 = multiply(%317, %328, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %330 = multiply(%319, %328, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %331 = subtract(meta[relay.Constant][93] // ty=Tensor[(256,), float32], %330, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %332 = add(%329, %331, framework_op_name="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", output_tensors_name=["TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1", axis=0) // ty=Tensor[(3, 128, 256), float32]
  %333 = strided_slice(%332, framework_op_name="strided_slice6", output_tensors_name=["strided_slice6:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %334 = strided_slice(%333, framework_op_name="strided_slice7", output_tensors_name=["strided_slice7:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %335 = strided_slice(%334, framework_op_name="strided_slice8", output_tensors_name=["strided_slice8:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 128, 256], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 256), float32]
  %336 = strided_slice(%335, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Slice", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Slice", begin=[0, 0, 0], end=[3, 1, 256]) // ty=Tensor[(3, 1, 256), float32]
  %337 = reshape(%336, framework_op_name="TapasModel_7/TapasPooler_29/aten_select/Reshape", output_tensors_name=["TapasModel_7/TapasPooler_29/aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/aten_select/Reshape", newshape=[3, 256]) // ty=Tensor[(3, 256), float32]
  %338 = nn.dense(%337, meta[relay.Constant][94] // ty=Tensor[(256, 256), float32], framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul", units=256) // ty=Tensor[(3, 256), float32]
  %339 = add(%338, meta[relay.Constant][95] // ty=Tensor[(256,), float32], framework_op_name="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", output_tensors_name=["TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add", axis=0) // ty=Tensor[(3, 256), float32]
  %340 = tanh(%339, framework_op_name="tanh0", output_tensors_name=["tanh0:0"], input_tensors_name=[], framework_op_debug_info="", axis=0) // ty=Tensor[(3, 256), float32]
  %341 = copy(%340, framework_op_name="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", output_tensors_name=["TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0"], input_tensors_name=[], framework_op_debug_info="TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh", axis=0) // ty=Tensor[(3, 256), float32]
  %342 = copy(meta[relay.Constant][96] // ty=Tensor[(1,), int64], framework_op_name="aten_to_5/Const", output_tensors_name=["aten_to_5/Const:0"], input_tensors_name=[], framework_op_debug_info="aten_to_5/Const", axis=0) // ty=Tensor[(1,), int64]
  %343 = copy(%tensor.9:0, framework_op_name="copy52", output_tensors_name=["copy52:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_7/StridedSlice", axis=0) // ty=Tensor[(3, 128, 7), int64]
  %344 = strided_slice(%343, framework_op_name="strided_slice9", output_tensors_name=["strided_slice9:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_7/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %345 = strided_slice(%344, framework_op_name="strided_slice10", output_tensors_name=["strided_slice10:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_8/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %346 = strided_slice(%345, framework_op_name="strided_slice11", output_tensors_name=["strided_slice11:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_9/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %347 = strided_slice(%346, framework_op_name="strided_slice12", output_tensors_name=["strided_slice12:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_10/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %348 = strided_slice(%347, framework_op_name="strided_slice13", output_tensors_name=["strided_slice13:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_11/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %349 = strided_slice(%348, framework_op_name="strided_slice14", output_tensors_name=["strided_slice14:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_12/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %350 = strided_slice(%349, framework_op_name="aten_select_1/Slice", output_tensors_name=["aten_select_1/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Slice", begin=[0, 0, 1], end=[3, 128, 2]) // ty=Tensor[(3, 128, 1), int64]
  %351 = reshape(%350, framework_op_name="aten_select_1/Reshape", output_tensors_name=["aten_select_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select_1/Reshape", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %352 = minimum(%351, meta[relay.Constant][97] // ty=Tensor[(1,), int64], framework_op_name="aten_min_1/Minimum", output_tensors_name=["aten_min_1/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min_1/Minimum", axis=0) // ty=Tensor[(3, 128), int64]
  %353 = copy(%tensor.9:0, framework_op_name="copy53", output_tensors_name=["copy53:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_1/StridedSlice", axis=0) // ty=Tensor[(3, 128, 7), int64]
  %354 = strided_slice(%353, framework_op_name="strided_slice15", output_tensors_name=["strided_slice15:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_1/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %355 = strided_slice(%354, framework_op_name="strided_slice16", output_tensors_name=["strided_slice16:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_2/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %356 = strided_slice(%355, framework_op_name="strided_slice17", output_tensors_name=["strided_slice17:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_3/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %357 = strided_slice(%356, framework_op_name="strided_slice18", output_tensors_name=["strided_slice18:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_4/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %358 = strided_slice(%357, framework_op_name="strided_slice19", output_tensors_name=["strided_slice19:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_5/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %359 = strided_slice(%358, framework_op_name="strided_slice20", output_tensors_name=["strided_slice20:0"], input_tensors_name=[], framework_op_debug_info="aten_slice_6/StridedSlice", begin=[0, 0, 0], end=[3, 128, 7], strides=[1, 1, 1]) // ty=Tensor[(3, 128, 7), int64]
  %360 = strided_slice(%359, framework_op_name="aten_select/Slice", output_tensors_name=["aten_select/Slice:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Slice", begin=[0, 0, 2], end=[3, 128, 3]) // ty=Tensor[(3, 128, 1), int64]
  %361 = reshape(%360, framework_op_name="aten_select/Reshape", output_tensors_name=["aten_select/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_select/Reshape", newshape=[3, 128]) // ty=Tensor[(3, 128), int64]
  %362 = minimum(%361, meta[relay.Constant][98] // ty=Tensor[(1,), int64], framework_op_name="aten_min/Minimum", output_tensors_name=["aten_min/Minimum:0"], input_tensors_name=[], framework_op_debug_info="aten_min/Minimum", axis=0) // ty=Tensor[(3, 128), int64]
  %363 = multiply(%362, meta[relay.Constant][96] // ty=Tensor[(1,), int64], framework_op_name="aten_mul/mul", output_tensors_name=["aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul/mul", axis=0) // ty=Tensor[(3, 128), int64]
  %364 = add(%352, %363, framework_op_name="add0", output_tensors_name=["add0:0"], input_tensors_name=[], framework_op_debug_info="", axis=0) // ty=Tensor[(3, 128), int64]
  %365 = copy(%364, framework_op_name="aten_add/add", output_tensors_name=["aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add/add", axis=0) // ty=Tensor[(3, 128), int64]
  %366 = copy(%tensor.1:0, framework_op_name="copy54", output_tensors_name=["copy54:0"], input_tensors_name=[], framework_op_debug_info="aten_to_8/Cast", axis=0) // ty=Tensor[(3, 128), int64]
  %367 = cast(%366, framework_op_name="aten_to_8/Cast", output_tensors_name=["aten_to_8/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_8/Cast", dtype="float32") // ty=Tensor[(3, 128), float32]
  %368 = reshape(%367, framework_op_name="reshape64", output_tensors_name=["reshape64:0"], input_tensors_name=[], framework_op_debug_info="", newshape=[-1]) // ty=Tensor[(384,), float32]
  %369 = copy(%368, framework_op_name="aten_reshape/Reshape", output_tensors_name=["aten_reshape/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape/Reshape", axis=0) // ty=Tensor[(384,), float32]
  %370 = add(meta[relay.Constant][99] // ty=Tensor[(3, 128), int64], %364, framework_op_name="aten_add_1/add", output_tensors_name=["aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_1/add", axis=0) // ty=Tensor[(3, 128), int64]
  %371 = reshape(%370, framework_op_name="aten_view_1/Reshape", output_tensors_name=["aten_view_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_1/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %372 = cast(%371, framework_op_name="aten_expand/Cast", output_tensors_name=["aten_expand/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %373 = broadcast_to(%372, framework_op_name="aten_expand/BroadcastTo", output_tensors_name=["aten_expand/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %374 = cast(%373, framework_op_name="cast0", output_tensors_name=["cast0:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %375 = copy(%374, framework_op_name="aten_expand/Cast_1", output_tensors_name=["aten_expand/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/Cast_1", axis=0) // ty=Tensor[(384,), int64]
  %376 = copy(meta[relay.Constant][100] // ty=Tensor[(6144,), float32], framework_op_name="aten_zeros/zeros", output_tensors_name=["aten_zeros/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros/zeros", axis=0) // ty=Tensor[(6144,), float32]
  %377 = copy(meta[relay.Constant][101] // ty=Tensor[(384,), float32], framework_op_name="aten_ones/ones", output_tensors_name=["aten_ones/ones:0"], input_tensors_name=[], framework_op_debug_info="aten_ones/ones", axis=0) // ty=Tensor[(384,), float32]
  %378 = cast(%371, framework_op_name="aten_expand_1/Cast", output_tensors_name=["aten_expand_1/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %379 = broadcast_to(%378, framework_op_name="aten_expand_1/BroadcastTo", output_tensors_name=["aten_expand_1/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %380 = cast(%379, framework_op_name="cast1", output_tensors_name=["cast1:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %381 = copy(%380, framework_op_name="aten_expand_1/Cast_1", output_tensors_name=["aten_expand_1/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_1/Cast_1", axis=0) // ty=Tensor[(384,), int64]
  %382 = reshape(%332, framework_op_name="aten_einsum_1/einsum/Reshape", output_tensors_name=["aten_einsum_1/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape", newshape=[384, 256]) // ty=Tensor[(384, 256), float32]
  %383 = nn.dense(%382, meta[relay.Constant][102] // ty=Tensor[(1, 256), float32], framework_op_name="aten_einsum_1/einsum/MatMul", output_tensors_name=["aten_einsum_1/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/MatMul", units=1) // ty=Tensor[(384, 1), float32]
  %384 = reshape(%383, framework_op_name="aten_einsum_1/einsum/Reshape_2", output_tensors_name=["aten_einsum_1/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum_1/einsum/Reshape_2", newshape=[3, 128]) // ty=Tensor[(3, 128), float32]
  %385 = add(%384, meta[relay.Constant][103] // ty=Tensor[(1,), float32], framework_op_name="aten_add_3/add", output_tensors_name=["aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_3/add", axis=0) // ty=Tensor[(3, 128), float32]
  %386 = reshape(%385, framework_op_name="reshape65", output_tensors_name=["reshape65:0"], input_tensors_name=[], framework_op_debug_info="", newshape=[-1]) // ty=Tensor[(384,), float32]
  %387 = copy(%386, framework_op_name="aten_reshape_1/Reshape", output_tensors_name=["aten_reshape_1/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_1/Reshape", axis=0) // ty=Tensor[(384,), float32]
  %388 = add(meta[relay.Constant][99] // ty=Tensor[(3, 128), int64], %364, framework_op_name="aten_add_4/add", output_tensors_name=["aten_add_4/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_4/add", axis=0) // ty=Tensor[(3, 128), int64]
  %389 = reshape(%388, framework_op_name="aten_view_3/Reshape", output_tensors_name=["aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_3/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %390 = cast(%389, framework_op_name="aten_expand_2/Cast", output_tensors_name=["aten_expand_2/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %391 = broadcast_to(%390, framework_op_name="aten_expand_2/BroadcastTo", output_tensors_name=["aten_expand_2/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %392 = cast(%391, framework_op_name="cast2", output_tensors_name=["cast2:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %393 = copy(%392, framework_op_name="aten_expand_2/Cast_1", output_tensors_name=["aten_expand_2/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_2/Cast_1", axis=0) // ty=Tensor[(384,), int64]
  %394 = copy(meta[relay.Constant][104] // ty=Tensor[(384,), float32], framework_op_name="aten_zeros_1/zeros", output_tensors_name=["aten_zeros_1/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros_1/zeros", axis=0) // ty=Tensor[(384,), float32]
  %395 = cast(%389, framework_op_name="aten_expand_3/Cast", output_tensors_name=["aten_expand_3/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %396 = broadcast_to(%395, framework_op_name="aten_expand_3/BroadcastTo", output_tensors_name=["aten_expand_3/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %397 = cast(%396, framework_op_name="cast3", output_tensors_name=["cast3:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %398 = copy(%397, framework_op_name="aten_ones_1/ones", output_tensors_name=["aten_ones_1/ones:0"], input_tensors_name=[], framework_op_debug_info="aten_ones_1/ones", axis=0) // ty=Tensor[(384,), int64]
  %399 = copy(meta[relay.Constant][105] // ty=Tensor[(3, 2048), int64], framework_op_name="aten_expand_3/Cast_1", output_tensors_name=["aten_expand_3/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_3/Cast_1", axis=0) // ty=Tensor[(3, 2048), int64]
  %400 = reshape(%332, framework_op_name="aten_einsum/einsum/Reshape", output_tensors_name=["aten_einsum/einsum/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape", newshape=[384, 256]) // ty=Tensor[(384, 256), float32]
  %401 = nn.dense(%400, meta[relay.Constant][106] // ty=Tensor[(1, 256), float32], framework_op_name="aten_einsum/einsum/MatMul", output_tensors_name=["aten_einsum/einsum/MatMul:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/MatMul", units=1) // ty=Tensor[(384, 1), float32]
  %402 = reshape(%401, framework_op_name="aten_einsum/einsum/Reshape_2", output_tensors_name=["aten_einsum/einsum/Reshape_2:0"], input_tensors_name=[], framework_op_debug_info="aten_einsum/einsum/Reshape_2", newshape=[3, 128]) // ty=Tensor[(3, 128), float32]
  %403 = add(%402, meta[relay.Constant][107] // ty=Tensor[(1,), float32], framework_op_name="aten_add_2/add", output_tensors_name=["aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_2/add", axis=0) // ty=Tensor[(3, 128), float32]
  %404 = multiply(%403, meta[relay.Constant][108] // ty=Tensor[(1,), float32], framework_op_name="aten_div/truediv", output_tensors_name=["aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", axis=0) // ty=Tensor[(3, 128), float32]
  %405 = reshape(%404, framework_op_name="reshape66", output_tensors_name=["reshape66:0"], input_tensors_name=[], framework_op_debug_info="", newshape=[-1]) // ty=Tensor[(384,), float32]
  %406 = copy(%405, framework_op_name="aten_to_18/Cast", output_tensors_name=["aten_to_18/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_18/Cast", axis=0) // ty=Tensor[(384,), float32]
  %407 = add(meta[relay.Constant][99] // ty=Tensor[(3, 128), int64], %364, framework_op_name="aten_add_5/add", output_tensors_name=["aten_add_5/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_5/add", axis=0) // ty=Tensor[(3, 128), int64]
  %408 = reshape(%407, framework_op_name="aten_view_6/Reshape", output_tensors_name=["aten_view_6/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_6/Reshape", newshape=[-1]) // ty=Tensor[(384,), int64]
  %409 = cast(%408, framework_op_name="aten_expand_4/Cast", output_tensors_name=["aten_expand_4/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %410 = broadcast_to(%409, framework_op_name="aten_expand_4/BroadcastTo", output_tensors_name=["aten_expand_4/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %411 = cast(%410, framework_op_name="cast4", output_tensors_name=["cast4:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %412 = copy(%411, framework_op_name="aten_reshape_2/Reshape", output_tensors_name=["aten_reshape_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape_2/Reshape", axis=0) // ty=Tensor[(384,), int64]
  %413 = copy(meta[relay.Constant][109] // ty=Tensor[(384,), float32], framework_op_name="aten_expand_4/Cast_1", output_tensors_name=["aten_expand_4/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_4/Cast_1", axis=0) // ty=Tensor[(384,), float32]
  %414 = cast(%408, framework_op_name="aten_expand_5/Cast", output_tensors_name=["aten_expand_5/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast", dtype="float32") // ty=Tensor[(384,), float32]
  %415 = broadcast_to(%414, framework_op_name="aten_expand_5/BroadcastTo", output_tensors_name=["aten_expand_5/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/BroadcastTo", shape=[384]) // ty=Tensor[(384,), float32]
  %416 = cast(%415, framework_op_name="cast5", output_tensors_name=["cast5:0"], input_tensors_name=[], framework_op_debug_info="", dtype="int64") // ty=Tensor[(384,), int64]
  %417 = copy(%416, framework_op_name="aten_zeros_2/zeros", output_tensors_name=["aten_zeros_2/zeros:0"], input_tensors_name=[], framework_op_debug_info="aten_zeros_2/zeros", axis=0) // ty=Tensor[(384,), int64]
  %418 = copy(meta[relay.Constant][110] // ty=Tensor[(384,), int64], framework_op_name="aten_ones_2/ones", output_tensors_name=["aten_ones_2/ones:0"], input_tensors_name=[], framework_op_debug_info="aten_ones_2/ones", axis=0) // ty=Tensor[(384,), int64]
  %419 = add(meta[relay.Constant][99] // ty=Tensor[(3, 128), int64], %364, framework_op_name="aten_add_6/add", output_tensors_name=["aten_add_6/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_6/add", axis=0) // ty=Tensor[(3, 128), int64]
  %420 = reshape(%419, framework_op_name="reshape67", output_tensors_name=["reshape67:0"], input_tensors_name=[], framework_op_debug_info="", newshape=[-1]) // ty=Tensor[(384,), int64]
  %421 = copy(%420, framework_op_name="aten_expand_5/Cast_1", output_tensors_name=["aten_expand_5/Cast_1:0"], input_tensors_name=[], framework_op_debug_info="aten_expand_5/Cast_1", axis=0) // ty=Tensor[(384,), int64]
  %422 = (%341, %342, %365, %369, %375, %376, %377, %381, %387, %393, %376, %394, %398, %399, %406, %412, %376, %413, %417, %418, %421, %399)
  %422
}
%423
// meta data omitted. you can use show_meta_data=True to include meta data