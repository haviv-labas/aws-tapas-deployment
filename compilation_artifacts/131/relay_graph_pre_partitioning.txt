v0.0.1
%34 = fn (%v3:0: Tensor[(6144,), float32], %v4:0: Tensor[(6144,), float32], %v7:0: Tensor[(3, 2048), float32], %tensor.11:0: Tensor[(3, 2048), int64], %v0:0: Tensor[(96,), float32], %v2:0: Tensor[(96,), float32], %v8:0: Tensor[(3, 512), int64]) -> (Tensor[(3, 2048), float32], Tensor[(3, 512), int64]) {
  %0 = broadcast_to(%v4:0, framework_op_name="aten_expand/BroadcastTo", output_tensors_name=["aten_expand/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_expand/BroadcastTo", shape=[6144]) // ty=Tensor[(6144,), float32]
  %1 = rdivide_scalar(%0, framework_op_name="rdivide_scalar0", output_tensors_name=["rdivide_scalar0:0"], input_tensors_name=[], framework_op_debug_info="aten_div_1/truediv", scalar=1) // ty=Tensor[(6144,), float32]
  %2 = multiply(%v3:0, %1, framework_op_name="aten_div_1/truediv", output_tensors_name=["aten_div_1/truediv:0"], input_tensors_name=[], framework_op_debug_info="aten_div_1/truediv", axis=0) // ty=Tensor[(6144,), float32]
  %3 = reshape(%2, framework_op_name="aten_view_4/Reshape", output_tensors_name=["aten_view_4/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_4/Reshape", newshape=[3, 2048]) // ty=Tensor[(3, 2048), float32]
  %4 = cast(%tensor.11:0, framework_op_name="aten_to_3/Cast", output_tensors_name=["aten_to_3/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_3/Cast", dtype="float32") // ty=Tensor[(3, 2048), float32]
  %5 = floor(%4, framework_op_name="aten_floor/Floor", output_tensors_name=["aten_floor/Floor:0"], input_tensors_name=[], framework_op_debug_info="aten_floor/Floor", axis=0) // ty=Tensor[(3, 2048), float32]
  %6 = cast(%5, framework_op_name="aten_to_4/Cast", output_tensors_name=["aten_to_4/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_4/Cast", dtype="int64") // ty=Tensor[(3, 2048), int64]
  %7 = equal(%6, meta[relay.Constant][2] // ty=Tensor[(1,), int64], framework_op_name="aten_eq_3/Equal", output_tensors_name=["aten_eq_3/Equal:0"], input_tensors_name=[], framework_op_debug_info="aten_eq_3/Equal", axis=0) // ty=Tensor[(3, 2048), bool]
  %8 = reshape(%v0:0, framework_op_name="aten_view/Reshape", output_tensors_name=["aten_view/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view/Reshape", newshape=[3, 32]) // ty=Tensor[(3, 32), float32]
  %9 = reshape(%v2:0, framework_op_name="aten_view_2/Reshape", output_tensors_name=["aten_view_2/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_2/Reshape", newshape=[3, 32]) // ty=Tensor[(3, 32), float32]
  %10 = add(%9, meta[relay.Constant][4] // ty=Tensor[(1,), float32], framework_op_name="aten_add/add", output_tensors_name=["aten_add/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add/add", axis=0) // ty=Tensor[(3, 32), float32]
  %11 = rdivide_scalar(%10, framework_op_name="rdivide_scalar1", output_tensors_name=["rdivide_scalar1:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", scalar=1) // ty=Tensor[(3, 32), float32]
  %12 = multiply(%8, %11, framework_op_name="aten_div/truediv", output_tensors_name=["aten_div/truediv:0"], input_tensors_name=[], framework_op_debug_info="aten_div/truediv", axis=0) // ty=Tensor[(3, 32), float32]
  %13 = reshape(%12, framework_op_name="aten_reshape/Reshape", output_tensors_name=["aten_reshape/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_reshape/Reshape", newshape=[96]) // ty=Tensor[(96,), float32]
  %14 = reshape(%13, framework_op_name="aten_view_3/Reshape", output_tensors_name=["aten_view_3/Reshape:0"], input_tensors_name=[], framework_op_debug_info="aten_view_3/Reshape", newshape=[3, 32]) // ty=Tensor[(3, 32), float32]
  %15 = less(%9, meta[relay.Constant][5] // ty=Tensor[(1,), float32], framework_op_name="aten_lt/Less", output_tensors_name=["aten_lt/Less:0"], input_tensors_name=[], framework_op_debug_info="aten_lt/Less", axis=0) // ty=Tensor[(3, 32), bool]
  %16 = logical_and(%15, meta[relay.Constant][6] // ty=Tensor[(3, 32), bool], framework_op_name="aten_logical_and/LogicalAnd", output_tensors_name=["aten_logical_and/LogicalAnd:0"], input_tensors_name=[], framework_op_debug_info="aten_logical_and/LogicalAnd", axis=0) // ty=Tensor[(3, 32), bool]
  %17 = cast(%16, framework_op_name="aten_to_1/Cast", output_tensors_name=["aten_to_1/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_1/Cast", dtype="float32") // ty=Tensor[(3, 32), float32]
  %18 = multiply(%17, meta[relay.Constant][7] // ty=Tensor[(1,), float32], framework_op_name="aten_mul/mul", output_tensors_name=["aten_mul/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul/mul", axis=0) // ty=Tensor[(3, 32), float32]
  %19 = add(%14, %18, framework_op_name="aten_add_1/add", output_tensors_name=["aten_add_1/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_1/add", axis=0) // ty=Tensor[(3, 32), float32]
  %20 = add(%19, meta[relay.Constant][8] // ty=Tensor[(3, 32), float32], framework_op_name="aten_add_2/add", output_tensors_name=["aten_add_2/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_2/add", axis=0) // ty=Tensor[(3, 32), float32]
  %21 = argmax(%20, framework_op_name="aten_argmax/ArgMax", output_tensors_name=["aten_argmax/ArgMax:0"], input_tensors_name=[], framework_op_debug_info="aten_argmax/ArgMax", axis=[-1]) // ty=Tensor[(3,), int32]
  %22 = cast(%21, framework_op_name="aten_to_7/Cast", output_tensors_name=["aten_to_7/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_7/Cast", dtype="int64") // ty=Tensor[(3,), int64]
  %23 = expand_dims(%22, framework_op_name="aten_unsqueeze/ExpandDims", output_tensors_name=["aten_unsqueeze/ExpandDims:0"], input_tensors_name=[], framework_op_debug_info="aten_unsqueeze/ExpandDims", axis=-1) // ty=Tensor[(3, 1), int64]
  %24 = broadcast_to(%23, framework_op_name="aten_eq_2/BroadcastTo", output_tensors_name=["aten_eq_2/BroadcastTo:0"], input_tensors_name=[], framework_op_debug_info="aten_eq_2/BroadcastTo", shape=[3, 2048]) // ty=Tensor[(3, 2048), int64]
  %25 = equal(%6, %24, framework_op_name="aten_eq_2/Equal", output_tensors_name=["aten_eq_2/Equal:0"], input_tensors_name=[], framework_op_debug_info="aten_eq_2/Equal", axis=0) // ty=Tensor[(3, 2048), bool]
  %26 = cast(%25, framework_op_name="aten_to_8/Cast", output_tensors_name=["aten_to_8/Cast:0"], input_tensors_name=[], framework_op_debug_info="aten_to_8/Cast", dtype="float32") // ty=Tensor[(3, 2048), float32]
  %27 = where(%7, meta[relay.Constant][3] // ty=Tensor[(3, 2048), float32], %26, framework_op_name="aten_where/Select", output_tensors_name=["aten_where/Select:0"], input_tensors_name=[], framework_op_debug_info="aten_where/Select", axis=0) // ty=Tensor[(3, 2048), float32]
  %28 = multiply(%v7:0, %27, framework_op_name="aten_mul_2/mul", output_tensors_name=["aten_mul_2/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_2/mul", axis=0) // ty=Tensor[(3, 2048), float32]
  %29 = multiply(meta[relay.Constant][1] // ty=Tensor[(1,), float32], %28, framework_op_name="aten_rsub/mul", output_tensors_name=["aten_rsub/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_rsub/mul", axis=0) // ty=Tensor[(3, 2048), float32]
  %30 = subtract(meta[relay.Constant][0] // ty=Tensor[(1,), float32], %29, framework_op_name="aten_rsub/sub", output_tensors_name=["aten_rsub/sub:0"], input_tensors_name=[], framework_op_debug_info="aten_rsub/sub", axis=0) // ty=Tensor[(3, 2048), float32]
  %31 = multiply(%30, meta[relay.Constant][9] // ty=Tensor[(1,), float32], framework_op_name="aten_mul_3/mul", output_tensors_name=["aten_mul_3/mul:0"], input_tensors_name=[], framework_op_debug_info="aten_mul_3/mul", axis=0) // ty=Tensor[(3, 2048), float32]
  %32 = add(%3, %31, framework_op_name="aten_add_3/add", output_tensors_name=["aten_add_3/add:0"], input_tensors_name=[], framework_op_debug_info="aten_add_3/add", axis=0) // ty=Tensor[(3, 2048), float32]
  %33 = (%32, %v8:0)
  %33
}
%34
// meta data omitted. you can use show_meta_data=True to include meta data