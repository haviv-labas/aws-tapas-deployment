{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4674f667",
   "metadata": {},
   "source": [
    "# Deploy a pretrained PyTorch BERT model from HuggingFace on Amazon SageMaker with Neuron container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39838",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c454f",
   "metadata": {},
   "source": [
    "In this tutotial we will deploy on SageMaker a pretraine BERT Base model from HuggingFace Transformers, using the [AWS Deep Learning Containers](https://github.com/aws/deep-learning-containers). We will use the same model as shown in the [Neuron Tutorial \"PyTorch - HuggingFace Pretrained BERT Tutorial\"](../../../../frameworks/torch/torch-neuronx/tutorials/training/bert.html#). We will compile the model and build a custom AWS Deep Learning Container, to include the HuggingFace Transformers Library. \n",
    "\n",
    "This Jupyter Notebook should run on a ml.c5.4xlarge SageMaker Notebook instance. You can set up your SageMaker Notebook instance by following the [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html) documentation. \n",
    "\n",
    "> We recommend increasing the size of the base root volume of you SM notebook instance, to accomodate the models and containers built locally. A root volume of 10Gb should suffice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37445ad2",
   "metadata": {},
   "source": [
    "## Install Dependencies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecd765f",
   "metadata": {},
   "source": [
    "This tutorial requires the following pip packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3092c",
   "metadata": {},
   "source": [
    "- torch-neuron\n",
    "- neuron-cc[tensorflow]\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066c3731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-neuron in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1.2.7.1.0)\n",
      "Requirement already satisfied: neuron-cc[tensorflow] in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.15.0.0+eec0c3604)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: dmlc-nnvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: dmlc-tvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: numpy<2,>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.18.5)\n",
      "Requirement already satisfied: islpy<=2022.1.1,>2021.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2022.1.1)\n",
      "Requirement already satisfied: dmlc-topi==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: inferentia-hwm==1.14.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.14.1.0+a9fb5c73a)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (3.20.1)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.7.3)\n",
      "Requirement already satisfied: networkx<=2.6.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2.6.3)\n",
      "Requirement already satisfied: tensorflow<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.5)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-topi==1.15.0.0->neuron-cc[tensorflow]) (5.1.1)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-tvm==1.15.0.0->neuron-cc[tensorflow]) (22.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pytest>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (7.3.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.0.8)\n",
      "Requirement already satisfied: h5py<=2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.1)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.54.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.1)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (4.11.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (3.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers==4.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (4.6.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.64.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (21.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (1.18.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (3.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->transformers==4.6.0) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2022.12.7)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "!pip install --upgrade --no-cache-dir 'transformers==4.6.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4796d3a",
   "metadata": {},
   "source": [
    "## Compile the model into an AWS Neuron optimized TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe85f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuron\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5c253a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\", return_dict=False)\n",
    "\n",
    "# Setup some example inputs\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "max_length=128\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Run the original PyTorch model on compilation exaple\n",
    "paraphrase_classification_logits = model(**paraphrase)[0]\n",
    "\n",
    "# Convert example inputs to a format that is compatible with TorchScript tracing\n",
    "example_inputs_paraphrase = paraphrase['input_ids'], paraphrase['attention_mask'], paraphrase['token_type_ids']\n",
    "example_inputs_not_paraphrase = not_paraphrase['input_ids'], not_paraphrase['attention_mask'], not_paraphrase['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44255ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/modeling_utils.py:1968: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:There are 3 ops of 1 different types in the TorchScript that are not compiled by neuron-cc: aten::embedding, (For more information see https://awsdocs-neuron.readthedocs-hosted.com/en/latest/release-notes/compiler/neuron-cc/neuron-cc-ops/neuron-cc-ops-pytorch.html)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 565, fused = 548, percent fused = 96.99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/ops/aten.py:2387: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$659 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]} --verbose 1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/02/2023 04:31:23 PM INFO 25521 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]}' --verbose 1\n",
      "06/02/2023 04:31:24 PM INFO 25521 [root]: Intermediate files stored in /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60, output in /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60\n",
      "06/02/2023 04:31:24 PM INFO 25521 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/02/2023 04:31:24 PM INFO 25521 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/02/2023 04:31:24 PM INFO 25521 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/02/2023 04:31:24 PM INFO 25521 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/02/2023 04:31:24 PM INFO 25521 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"0:0\": [[1, 128, 768], \"float32\"], \"1:0\": [[1, 1, 1, 128], \"float32\"]}, \"outputs\": [\"Linear_5/aten_linear/Add:0\"]}'\n",
      "06/02/2023 04:31:30 PM INFO 25521 [job.Frontend.4]: IR signature: 4242ebe2660a87886aa73e07ad4e35c8c0c99cdc19517e4c968a69ab8be671eb for graph_def.pb\n",
      "06/02/2023 04:31:30 PM INFO 25521 [job.Frontend.4]: total padded opcount is 22348434432\n",
      "06/02/2023 04:31:30 PM INFO 25521 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/02/2023 04:31:30 PM INFO 25521 [job.Frontend.4]: Start tensorization\n",
      "[16:31:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[16:31:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=11174217216\n",
      "Coloring: Total const bytes per part=1338326\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[16:31:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 11,174,217,216. Average number of cycles per partition: 11,174,217,216\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0  11,174,217,216 1,338,326           0         0         2         903\n",
      "Coloring: Total nubmer of cycles = 11,174,217,216\n",
      "Coloring: Largest number of cycles in part = 11,174,217,216, Ratio worst/best avg = 1\n",
      "\n",
      "\n",
      "\n",
      "[16:31:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEmbeddings_27/LayerNorm_29/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_25/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_26/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_27/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_28/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_29/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_30/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_31/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_32/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_33/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_34/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertAttention_3/BertSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertEncoder_28/BertLayer_35/BertOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Linear_10/aten_linear/Add:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Linear_10/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/Tanh_11/aten_tanh/Tanh:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/aten_select/Reshape:0\n",
      "     tonga0:tpb0  BertModel_3/BertPooler_29/aten_select/Slice:0\n",
      "     tonga0:tpb0  Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  Linear_5/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  add0:0\n",
      "     tonga0:tpb0  copy10:0\n",
      "     tonga0:tpb0  copy11:0\n",
      "     tonga0:tpb0  copy12:0\n",
      "     tonga0:tpb0  copy13:0\n",
      "     tonga0:tpb0  copy14:0\n",
      "     tonga0:tpb0  copy15:0\n",
      "     tonga0:tpb0  copy16:0\n",
      "     tonga0:tpb0  copy17:0\n",
      "     tonga0:tpb0  copy18:0\n",
      "     tonga0:tpb0  copy19:0\n",
      "     tonga0:tpb0  copy20:0\n",
      "     tonga0:tpb0  copy6:0\n",
      "     tonga0:tpb0  copy7:0\n",
      "     tonga0:tpb0  copy8:0\n",
      "     tonga0:tpb0  copy9:0\n",
      "     tonga0:tpb0  nn.batch_matmul0:0\n",
      "     tonga0:tpb0  nn.batch_matmul10:0\n",
      "     tonga0:tpb0  nn.batch_matmul11:0\n",
      "     tonga0:tpb0  nn.batch_matmul12:0\n",
      "     tonga0:tpb0  nn.batch_matmul13:0\n",
      "     tonga0:tpb0  nn.batch_matmul14:0\n",
      "     tonga0:tpb0  nn.batch_matmul15:0\n",
      "     tonga0:tpb0  nn.batch_matmul16:0\n",
      "     tonga0:tpb0  nn.batch_matmul17:0\n",
      "     tonga0:tpb0  nn.batch_matmul18:0\n",
      "     tonga0:tpb0  nn.batch_matmul19:0\n",
      "     tonga0:tpb0  nn.batch_matmul1:0\n",
      "     tonga0:tpb0  nn.batch_matmul20:0\n",
      "     tonga0:tpb0  nn.batch_matmul21:0\n",
      "     tonga0:tpb0  nn.batch_matmul22:0\n",
      "     tonga0:tpb0  nn.batch_matmul23:0\n",
      "     tonga0:tpb0  nn.batch_matmul24:0\n",
      "     tonga0:tpb0  nn.batch_matmul25:0\n",
      "     tonga0:tpb0  nn.batch_matmul26:0\n",
      "     tonga0:tpb0  nn.batch_matmul27:0\n",
      "     tonga0:tpb0  nn.batch_matmul28:0\n",
      "     tonga0:tpb0  nn.batch_matmul29:0\n",
      "     tonga0:tpb0  nn.batch_matmul2:0\n",
      "     tonga0:tpb0  nn.batch_matmul30:0\n",
      "     tonga0:tpb0  nn.batch_matmul31:0\n",
      "     tonga0:tpb0  nn.batch_matmul32:0\n",
      "     tonga0:tpb0  nn.batch_matmul33:0\n",
      "     tonga0:tpb0  nn.batch_matmul34:0\n",
      "     tonga0:tpb0  nn.batch_matmul35:0\n",
      "     tonga0:tpb0  nn.batch_matmul36:0\n",
      "     tonga0:tpb0  nn.batch_matmul37:0\n",
      "     tonga0:tpb0  nn.batch_matmul38:0\n",
      "     tonga0:tpb0  nn.batch_matmul39:0\n",
      "     tonga0:tpb0  nn.batch_matmul3:0\n",
      "     tonga0:tpb0  nn.batch_matmul40:0\n",
      "     tonga0:tpb0  nn.batch_matmul41:0\n",
      "     tonga0:tpb0  nn.batch_matmul42:0\n",
      "     tonga0:tpb0  nn.batch_matmul43:0\n",
      "     tonga0:tpb0  nn.batch_matmul44:0\n",
      "     tonga0:tpb0  nn.batch_matmul45:0\n",
      "     tonga0:tpb0  nn.batch_matmul46:0\n",
      "     tonga0:tpb0  nn.batch_matmul47:0\n",
      "     tonga0:tpb0  nn.batch_matmul48:0\n",
      "     tonga0:tpb0  nn.batch_matmul49:0\n",
      "     tonga0:tpb0  nn.batch_matmul4:0\n",
      "     tonga0:tpb0  nn.batch_matmul50:0\n",
      "     tonga0:tpb0  nn.batch_matmul51:0\n",
      "     tonga0:tpb0  nn.batch_matmul52:0\n",
      "     tonga0:tpb0  nn.batch_matmul53:0\n",
      "     tonga0:tpb0  nn.batch_matmul54:0\n",
      "     tonga0:tpb0  nn.batch_matmul55:0\n",
      "     tonga0:tpb0  nn.batch_matmul56:0\n",
      "     tonga0:tpb0  nn.batch_matmul57:0\n",
      "     tonga0:tpb0  nn.batch_matmul58:0\n",
      "     tonga0:tpb0  nn.batch_matmul59:0\n",
      "     tonga0:tpb0  nn.batch_matmul5:0\n",
      "     tonga0:tpb0  nn.batch_matmul60:0\n",
      "     tonga0:tpb0  nn.batch_matmul61:0\n",
      "     tonga0:tpb0  nn.batch_matmul62:0\n",
      "     tonga0:tpb0  nn.batch_matmul63:0\n",
      "     tonga0:tpb0  nn.batch_matmul64:0\n",
      "     tonga0:tpb0  nn.batch_matmul65:0\n",
      "     tonga0:tpb0  nn.batch_matmul66:0\n",
      "     tonga0:tpb0  nn.batch_matmul67:0\n",
      "     tonga0:tpb0  nn.batch_matmul68:0\n",
      "     tonga0:tpb0  nn.batch_matmul69:0\n",
      "     tonga0:tpb0  nn.batch_matmul6:0\n",
      "     tonga0:tpb0  nn.batch_matmul70:0\n",
      "     tonga0:tpb0  nn.batch_matmul71:0\n",
      "     tonga0:tpb0  nn.batch_matmul72:0\n",
      "     tonga0:tpb0  nn.batch_matmul73:0\n",
      "     tonga0:tpb0  nn.batch_matmul74:0\n",
      "     tonga0:tpb0  nn.batch_matmul75:0\n",
      "     tonga0:tpb0  nn.batch_matmul76:0\n",
      "     tonga0:tpb0  nn.batch_matmul77:0\n",
      "     tonga0:tpb0  nn.batch_matmul78:0\n",
      "     tonga0:tpb0  nn.batch_matmul79:0\n",
      "     tonga0:tpb0  nn.batch_matmul7:0\n",
      "     tonga0:tpb0  nn.batch_matmul80:0\n",
      "     tonga0:tpb0  nn.batch_matmul81:0\n",
      "     tonga0:tpb0  nn.batch_matmul82:0\n",
      "     tonga0:tpb0  nn.batch_matmul83:0\n",
      "     tonga0:tpb0  nn.batch_matmul84:0\n",
      "     tonga0:tpb0  nn.batch_matmul85:0\n",
      "     tonga0:tpb0  nn.batch_matmul86:0\n",
      "     tonga0:tpb0  nn.batch_matmul87:0\n",
      "     tonga0:tpb0  nn.batch_matmul88:0\n",
      "     tonga0:tpb0  nn.batch_matmul89:0\n",
      "     tonga0:tpb0  nn.batch_matmul8:0\n",
      "     tonga0:tpb0  nn.batch_matmul90:0\n",
      "     tonga0:tpb0  nn.batch_matmul91:0\n",
      "     tonga0:tpb0  nn.batch_matmul92:0\n",
      "     tonga0:tpb0  nn.batch_matmul93:0\n",
      "     tonga0:tpb0  nn.batch_matmul94:0\n",
      "     tonga0:tpb0  nn.batch_matmul95:0\n",
      "     tonga0:tpb0  nn.batch_matmul9:0\n",
      "     tonga0:tpb0  reshape101:0\n",
      "     tonga0:tpb0  reshape102:0\n",
      "     tonga0:tpb0  reshape105:0\n",
      "     tonga0:tpb0  reshape114:0\n",
      "     tonga0:tpb0  reshape117:0\n",
      "     tonga0:tpb0  reshape118:0\n",
      "     tonga0:tpb0  reshape121:0\n",
      "     tonga0:tpb0  reshape130:0\n",
      "     tonga0:tpb0  reshape133:0\n",
      "     tonga0:tpb0  reshape134:0\n",
      "     tonga0:tpb0  reshape137:0\n",
      "     tonga0:tpb0  reshape146:0\n",
      "     tonga0:tpb0  reshape149:0\n",
      "     tonga0:tpb0  reshape150:0\n",
      "     tonga0:tpb0  reshape153:0\n",
      "     tonga0:tpb0  reshape162:0\n",
      "     tonga0:tpb0  reshape165:0\n",
      "     tonga0:tpb0  reshape166:0\n",
      "     tonga0:tpb0  reshape169:0\n",
      "     tonga0:tpb0  reshape178:0\n",
      "     tonga0:tpb0  reshape181:0\n",
      "     tonga0:tpb0  reshape182:0\n",
      "     tonga0:tpb0  reshape185:0\n",
      "     tonga0:tpb0  reshape18:0\n",
      "     tonga0:tpb0  reshape21:0\n",
      "     tonga0:tpb0  reshape22:0\n",
      "     tonga0:tpb0  reshape25:0\n",
      "     tonga0:tpb0  reshape2:0\n",
      "     tonga0:tpb0  reshape34:0\n",
      "     tonga0:tpb0  reshape37:0\n",
      "     tonga0:tpb0  reshape38:0\n",
      "     tonga0:tpb0  reshape41:0\n",
      "     tonga0:tpb0  reshape50:0\n",
      "     tonga0:tpb0  reshape53:0\n",
      "     tonga0:tpb0  reshape54:0\n",
      "     tonga0:tpb0  reshape57:0\n",
      "     tonga0:tpb0  reshape5:0\n",
      "     tonga0:tpb0  reshape66:0\n",
      "     tonga0:tpb0  reshape69:0\n",
      "     tonga0:tpb0  reshape6:0\n",
      "     tonga0:tpb0  reshape70:0\n",
      "     tonga0:tpb0  reshape73:0\n",
      "     tonga0:tpb0  reshape82:0\n",
      "     tonga0:tpb0  reshape85:0\n",
      "     tonga0:tpb0  reshape86:0\n",
      "     tonga0:tpb0  reshape89:0\n",
      "     tonga0:tpb0  reshape98:0\n",
      "     tonga0:tpb0  reshape9:0\n",
      "     tonga0:tpb0  sqrt0:0\n",
      "     tonga0:tpb0  sqrt10:0\n",
      "     tonga0:tpb0  sqrt11:0\n",
      "     tonga0:tpb0  sqrt12:0\n",
      "     tonga0:tpb0  sqrt13:0\n",
      "     tonga0:tpb0  sqrt14:0\n",
      "     tonga0:tpb0  sqrt15:0\n",
      "     tonga0:tpb0  sqrt16:0\n",
      "     tonga0:tpb0  sqrt17:0\n",
      "     tonga0:tpb0  sqrt18:0\n",
      "     tonga0:tpb0  sqrt19:0\n",
      "     tonga0:tpb0  sqrt1:0\n",
      "     tonga0:tpb0  sqrt20:0\n",
      "     tonga0:tpb0  sqrt21:0\n",
      "     tonga0:tpb0  sqrt22:0\n",
      "     tonga0:tpb0  sqrt23:0\n",
      "     tonga0:tpb0  sqrt24:0\n",
      "     tonga0:tpb0  sqrt2:0\n",
      "     tonga0:tpb0  sqrt3:0\n",
      "     tonga0:tpb0  sqrt4:0\n",
      "     tonga0:tpb0  sqrt5:0\n",
      "     tonga0:tpb0  sqrt6:0\n",
      "     tonga0:tpb0  sqrt7:0\n",
      "     tonga0:tpb0  sqrt8:0\n",
      "     tonga0:tpb0  sqrt9:0\n",
      "     tonga0:tpb0  strided_slice0:0\n",
      "     tonga0:tpb0  strided_slice1:0\n",
      "     tonga0:tpb0  strided_slice2:0\n",
      "     tonga0:tpb0  subtract0:0\n",
      "     tonga0:tpb0  subtract10:0\n",
      "     tonga0:tpb0  subtract11:0\n",
      "     tonga0:tpb0  subtract12:0\n",
      "     tonga0:tpb0  subtract13:0\n",
      "     tonga0:tpb0  subtract14:0\n",
      "     tonga0:tpb0  subtract15:0\n",
      "     tonga0:tpb0  subtract16:0\n",
      "     tonga0:tpb0  subtract17:0\n",
      "     tonga0:tpb0  subtract18:0\n",
      "     tonga0:tpb0  subtract19:0\n",
      "     tonga0:tpb0  subtract1:0\n",
      "     tonga0:tpb0  subtract20:0\n",
      "     tonga0:tpb0  subtract21:0\n",
      "     tonga0:tpb0  subtract22:0\n",
      "     tonga0:tpb0  subtract23:0\n",
      "     tonga0:tpb0  subtract24:0\n",
      "     tonga0:tpb0  subtract2:0\n",
      "     tonga0:tpb0  subtract3:0\n",
      "     tonga0:tpb0  subtract4:0\n",
      "     tonga0:tpb0  subtract5:0\n",
      "     tonga0:tpb0  subtract6:0\n",
      "     tonga0:tpb0  subtract7:0\n",
      "     tonga0:tpb0  subtract8:0\n",
      "     tonga0:tpb0  subtract9:0\n",
      "     tonga0:tpb0  sum0:0\n",
      "     tonga0:tpb0  sum10:0\n",
      "     tonga0:tpb0  sum11:0\n",
      "     tonga0:tpb0  sum12:0\n",
      "     tonga0:tpb0  sum13:0\n",
      "     tonga0:tpb0  sum14:0\n",
      "     tonga0:tpb0  sum15:0\n",
      "     tonga0:tpb0  sum16:0\n",
      "     tonga0:tpb0  sum17:0\n",
      "     tonga0:tpb0  sum18:0\n",
      "     tonga0:tpb0  sum19:0\n",
      "     tonga0:tpb0  sum1:0\n",
      "     tonga0:tpb0  sum20:0\n",
      "     tonga0:tpb0  sum21:0\n",
      "     tonga0:tpb0  sum22:0\n",
      "     tonga0:tpb0  sum23:0\n",
      "     tonga0:tpb0  sum24:0\n",
      "     tonga0:tpb0  sum25:0\n",
      "     tonga0:tpb0  sum26:0\n",
      "     tonga0:tpb0  sum27:0\n",
      "     tonga0:tpb0  sum28:0\n",
      "     tonga0:tpb0  sum29:0\n",
      "     tonga0:tpb0  sum2:0\n",
      "     tonga0:tpb0  sum30:0\n",
      "     tonga0:tpb0  sum31:0\n",
      "     tonga0:tpb0  sum32:0\n",
      "     tonga0:tpb0  sum33:0\n",
      "     tonga0:tpb0  sum34:0\n",
      "     tonga0:tpb0  sum35:0\n",
      "     tonga0:tpb0  sum36:0\n",
      "     tonga0:tpb0  sum37:0\n",
      "     tonga0:tpb0  sum38:0\n",
      "     tonga0:tpb0  sum39:0\n",
      "     tonga0:tpb0  sum3:0\n",
      "     tonga0:tpb0  sum40:0\n",
      "     tonga0:tpb0  sum41:0\n",
      "     tonga0:tpb0  sum42:0\n",
      "     tonga0:tpb0  sum43:0\n",
      "     tonga0:tpb0  sum44:0\n",
      "     tonga0:tpb0  sum45:0\n",
      "     tonga0:tpb0  sum46:0\n",
      "     tonga0:tpb0  sum47:0\n",
      "     tonga0:tpb0  sum48:0\n",
      "     tonga0:tpb0  sum49:0\n",
      "     tonga0:tpb0  sum4:0\n",
      "     tonga0:tpb0  sum5:0\n",
      "     tonga0:tpb0  sum6:0\n",
      "     tonga0:tpb0  sum7:0\n",
      "     tonga0:tpb0  sum8:0\n",
      "     tonga0:tpb0  sum9:0\n",
      "     tonga0:tpb0  transpose10:0\n",
      "     tonga0:tpb0  transpose12:0\n",
      "     tonga0:tpb0  transpose18:0\n",
      "     tonga0:tpb0  transpose20:0\n",
      "     tonga0:tpb0  transpose26:0\n",
      "     tonga0:tpb0  transpose28:0\n",
      "     tonga0:tpb0  transpose2:0\n",
      "     tonga0:tpb0  transpose34:0\n",
      "     tonga0:tpb0  transpose36:0\n",
      "     tonga0:tpb0  transpose42:0\n",
      "     tonga0:tpb0  transpose44:0\n",
      "     tonga0:tpb0  transpose4:0\n",
      "     tonga0:tpb0  transpose50:0\n",
      "     tonga0:tpb0  transpose52:0\n",
      "     tonga0:tpb0  transpose58:0\n",
      "     tonga0:tpb0  transpose60:0\n",
      "     tonga0:tpb0  transpose66:0\n",
      "     tonga0:tpb0  transpose68:0\n",
      "     tonga0:tpb0  transpose74:0\n",
      "     tonga0:tpb0  transpose76:0\n",
      "     tonga0:tpb0  transpose82:0\n",
      "     tonga0:tpb0  transpose84:0\n",
      "     tonga0:tpb0  transpose90:0\n",
      "     tonga0:tpb0  transpose92:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/02/2023 04:31:41 PM INFO 25521 [job.Frontend.4]: IR signature: 3ffb0937f8d8c6a8f56a6b5c33ce449435142967dcbdc3ca9203b23dbd1915d5 for relay_graph_post_opt_unit_level.txt\n",
      "06/02/2023 04:31:41 PM INFO 25521 [root/Tensorizer/All]: Enter time region\n",
      "06/02/2023 04:31:41 PM INFO 25521 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/02/2023 04:31:41 PM INFO 25521 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/02/2023 04:31:42 PM INFO 25521 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.665s\n",
      "06/02/2023 04:31:42 PM INFO 25521 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=1.256s\n",
      "06/02/2023 04:31:43 PM INFO 25521 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/02/2023 04:31:43 PM INFO 25521 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/02/2023 04:31:43 PM INFO 25521 [Statistics]: Weights total number of bytes: 342592812\n",
      "06/02/2023 04:31:43 PM INFO 25521 [Statistics]: RelayIF total number of bytes: 393728.0\n",
      "06/02/2023 04:31:43 PM INFO 25521 [Statistics]: RelayOF total number of bytes: 8.0\n",
      "06/02/2023 04:31:43 PM INFO 25521 [Statistics]: Weights total number of bytes: 342592812.0\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/02/2023 04:31:43 PM INFO 25521 [DoNothing]: Finished (changed=False)\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.258s\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/02/2023 04:31:43 PM INFO 25521 [MutateDataType]: Finished (changed=False)\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.251s\n",
      "06/02/2023 04:31:43 PM INFO 25521 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/02/2023 04:31:44 PM INFO 25521 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.250s\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/02/2023 04:31:44 PM INFO 25521 [EliminateDivs]: Finished (changed=False)\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.255s\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/02/2023 04:31:44 PM INFO 25521 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.561s\n",
      "06/02/2023 04:31:44 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:45 PM INFO 25521 [Simplifier]: Finished (changed=True #instances=56215414160)\n",
      "06/02/2023 04:31:45 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.660s\n",
      "06/02/2023 04:31:45 PM INFO 25521 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/02/2023 04:31:45 PM INFO 25521 [TCTransform]: Finished (changed=True #instances=45041196944)\n",
      "06/02/2023 04:31:45 PM INFO 25521 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.282s\n",
      "06/02/2023 04:31:45 PM INFO 25521 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/02/2023 04:31:46 PM INFO 25521 [CommuteConcat]: Finished (changed=False)\n",
      "06/02/2023 04:31:46 PM INFO 25521 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.251s\n",
      "06/02/2023 04:31:46 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/02/2023 04:31:48 PM INFO 25521 [LoopFusion]: Finished (changed=True #instances=94185661440)\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=2.066s\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:48 PM INFO 25521 [Simplifier]: Finished (changed=False)\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.150s\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/02/2023 04:31:48 PM INFO 25521 [DelinearIndices]: Finished (changed=True #instances=94185661440)\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.268s\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/02/2023 04:31:48 PM INFO 25521 [Delinearization]: Finished (changed=False)\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.120s\n",
      "06/02/2023 04:31:48 PM INFO 25521 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/02/2023 04:31:50 PM INFO 25521 [DeadStoreElimination]: Finished (changed=True #instances=87297669120)\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=1.791s\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:50 PM INFO 25521 [Simplifier]: Finished (changed=True #instances=87297669120)\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.318s\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:31:50 PM INFO 25521 [LICM]: Finished (changed=True #instances=31335397206)\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.094s\n",
      "06/02/2023 04:31:50 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/02/2023 04:31:51 PM INFO 25521 [DelinearIndices]: Finished (changed=True #instances=31335397206)\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.124s\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/02/2023 04:31:51 PM INFO 25521 [Delinearization]: Finished (changed=False)\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.118s\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/02/2023 04:31:51 PM INFO 25521 [LoopFusion]: Finished (changed=True #instances=31331073360)\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.305s\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:31:51 PM INFO 25521 [LICM]: Finished (changed=True #instances=31331068758)\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.078s\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:51 PM INFO 25521 [Simplifier]: Finished (changed=True #instances=31331068748)\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.297s\n",
      "06/02/2023 04:31:51 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [ValueNumbering]: Finished (changed=True #instances=31328806220)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.142s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [LICM]: Finished (changed=False)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.065s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [MemcpyElimination]: Finished (changed=True #instances=31328413004)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.174s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [PadElimination]: Finished (changed=False)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.062s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [DelinearIndices]: Finished (changed=False)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.093s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [Delinearization]: Finished (changed=False)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.106s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/02/2023 04:31:52 PM INFO 25521 [LoopFusion]: Finished (changed=True #instances=31328409932)\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.369s\n",
      "06/02/2023 04:31:52 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [Simplifier]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.193s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [LICM]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.064s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [ValueNumbering]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.087s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [TCTransform]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.067s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [CommuteConcat]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.068s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [LoopFusion]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.186s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [ValueNumbering]: Finished (changed=False)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.087s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/02/2023 04:31:53 PM INFO 25521 [RecognizeOpIdiom]: Finished (changed=True #instances=31311093194)\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.215s\n",
      "06/02/2023 04:31:53 PM INFO 25521 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.067s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [Tensorizer]: After optimization: 1 statements\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [AutoCastFP32]: Finished (changed=True #instances=31311388492)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.083s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [LoopFusion]: Finished (changed=False)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.183s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [Simplifier]: Finished (changed=False)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.136s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [Delinearization]: Finished (changed=True #instances=31311388492)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.129s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/02/2023 04:31:54 PM INFO 25521 [ResolveAccessConflict]: Finished (changed=True #instances=31326879270)\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.198s\n",
      "06/02/2023 04:31:54 PM INFO 25521 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/02/2023 04:31:55 PM INFO 25521 [TransformLayout]: Finished (changed=True #instances=31349406374)\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.453s\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/02/2023 04:31:55 PM INFO 25521 [PartitionLocalityOpt]: Finished (changed=True #instances=31349406374)\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.178s\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/02/2023 04:31:55 PM INFO 25521 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.088s\n",
      "06/02/2023 04:31:55 PM INFO 25521 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/02/2023 04:31:57 PM INFO 25521 [TongaSizeTiling]: Finished (changed=True #instances=10060)\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=1.708s\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/02/2023 04:31:57 PM INFO 25521 [TilingProfiler]: Finished (changed=False)\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.182s\n",
      "06/02/2023 04:31:57 PM INFO 25521 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/02/2023 04:31:57 PM INFO 25521 [FlattenMacroLoop]: Finished (changed=True #instances=10060)\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.206s\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/02/2023 04:31:57 PM INFO 25521 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.141s\n",
      "06/02/2023 04:31:57 PM INFO 25521 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/02/2023 04:31:58 PM INFO 25521 [InferTongaTensor]: Finished (changed=True #instances=10060)\n",
      "06/02/2023 04:31:58 PM INFO 25521 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.818s\n",
      "06/02/2023 04:31:58 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/02/2023 04:31:58 PM INFO 25521 [TongaSimplifier]: Finished (changed=False)\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.225s\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:31:59 PM INFO 25521 [LICM]: Finished (changed=True #instances=10060)\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.197s\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/02/2023 04:31:59 PM INFO 25521 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.163s\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/02/2023 04:31:59 PM INFO 25521 [FlattenMacroLoop]: Finished (changed=True #instances=10060)\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.211s\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/02/2023 04:31:59 PM INFO 25521 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.331s\n",
      "06/02/2023 04:31:59 PM INFO 25521 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/02/2023 04:32:05 PM INFO 25521 [DataLocalityOpt]: Finished (changed=True #instances=10659)\n",
      "06/02/2023 04:32:05 PM INFO 25521 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=5.854s\n",
      "06/02/2023 04:32:05 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/02/2023 04:32:06 PM INFO 25521 [TongaSimplifier]: Finished (changed=False)\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.239s\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/02/2023 04:32:06 PM INFO 25521 [LegalizeTongaMacro]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.348s\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/02/2023 04:32:06 PM INFO 25521 [TongaSimplifier]: Finished (changed=False)\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.260s\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/02/2023 04:32:06 PM INFO 25521 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.236s\n",
      "06/02/2023 04:32:06 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/02/2023 04:32:07 PM INFO 25521 [FlattenMacroLoop]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:07 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.334s\n",
      "06/02/2023 04:32:07 PM INFO 25521 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  0.0013020833333333333 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM WARNING 25521 [RewriteWeights]: Invalid value in const scalar:  1e-12 with dtype: bfloat16\n",
      "06/02/2023 04:32:09 PM INFO 25521 [RewriteWeights]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:09 PM INFO 25521 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=2.598s\n",
      "06/02/2023 04:32:09 PM INFO 25521 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/02/2023 04:32:10 PM INFO 25521 [ReshapeWeights]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.275s\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/02/2023 04:32:10 PM INFO 25521 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.230s\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/02/2023 04:32:10 PM INFO 25521 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.473s\n",
      "06/02/2023 04:32:10 PM INFO 25521 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/02/2023 04:32:12 PM INFO 25521 [InferInitValue]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:12 PM INFO 25521 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=1.876s\n",
      "06/02/2023 04:32:12 PM INFO 25521 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/02/2023 04:32:12 PM INFO 25521 [SplitUnionSets]: Finished (changed=False)\n",
      "06/02/2023 04:32:12 PM INFO 25521 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.223s\n",
      "06/02/2023 04:32:12 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/02/2023 04:32:13 PM INFO 25521 [TongaSimplifier]: Finished (changed=False)\n",
      "06/02/2023 04:32:13 PM INFO 25521 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.252s\n",
      "06/02/2023 04:32:13 PM INFO 25521 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/02/2023 04:32:13 PM INFO 25521 [SimplifyTongaTensor]: Finished (changed=True #instances=10852)\n",
      "06/02/2023 04:32:13 PM INFO 25521 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.600s\n",
      "06/02/2023 04:32:13 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/02/2023 04:32:14 PM INFO 25521 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.257s\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/02/2023 04:32:14 PM INFO 25521 [LICM]: Finished (changed=False)\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/LICM]: Exit time region: delta=0.226s\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/02/2023 04:32:14 PM INFO 25521 [TongaISel]: Finished (changed=True #instances=13670)\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.600s\n",
      "06/02/2023 04:32:14 PM INFO 25521 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/02/2023 04:32:15 PM INFO 25521 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/02/2023 04:32:15 PM INFO 25521 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.252s\n",
      "06/02/2023 04:32:15 PM INFO 25521 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/02/2023 04:32:16 PM INFO 25521 [TongaLoopFusion]: Finished (changed=True #instances=13670)\n",
      "06/02/2023 04:32:16 PM INFO 25521 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=1.330s\n",
      "06/02/2023 04:32:16 PM INFO 25521 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/02/2023 04:32:16 PM INFO 25521 [TongaLICM]: Finished (changed=False)\n",
      "06/02/2023 04:32:16 PM INFO 25521 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.241s\n",
      "06/02/2023 04:32:16 PM INFO 25521 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/02/2023 04:32:17 PM INFO 25521 [FactorizeBlkDims]: Finished (changed=True #instances=13670)\n",
      "06/02/2023 04:32:17 PM INFO 25521 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.800s\n",
      "06/02/2023 04:32:17 PM INFO 25521 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/02/2023 04:32:18 PM INFO 25521 [TongaInstComb]: Finished (changed=True #instances=12166)\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.798s\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/02/2023 04:32:18 PM INFO 25521 [TongaValueNumbering]: Finished (changed=True #instances=11899)\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.282s\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/02/2023 04:32:18 PM INFO 25521 [LowerTranspose]: Finished (changed=True #instances=12328)\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.324s\n",
      "06/02/2023 04:32:18 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/02/2023 04:32:19 PM INFO 25521 [LegalizeTongaType]: Finished (changed=True #instances=12613)\n",
      "06/02/2023 04:32:19 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.252s\n",
      "06/02/2023 04:32:19 PM INFO 25521 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/02/2023 04:32:20 PM INFO 25521 [PartialLoopFusion]: Finished (changed=True #instances=12613)\n",
      "06/02/2023 04:32:20 PM INFO 25521 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=1.514s\n",
      "06/02/2023 04:32:20 PM INFO 25521 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/02/2023 04:32:21 PM INFO 25521 [ShortenLifeInterval]: Finished (changed=True #instances=12613)\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.434s\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/02/2023 04:32:21 PM INFO 25521 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.210s\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/02/2023 04:32:21 PM INFO 25521 [SpillPSum]: Finished (changed=True #instances=12757)\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.398s\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/02/2023 04:32:21 PM INFO 25521 [LegalizeTongaType]: Finished (changed=False)\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.222s\n",
      "06/02/2023 04:32:21 PM INFO 25521 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/02/2023 04:32:22 PM INFO 25521 [InferPSumTensor]: Finished (changed=True #instances=12757)\n",
      "06/02/2023 04:32:22 PM INFO 25521 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=1.004s\n",
      "06/02/2023 04:32:22 PM INFO 25521 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/02/2023 04:32:23 PM INFO 25521 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/02/2023 04:32:23 PM INFO 25521 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.232s\n",
      "06/02/2023 04:32:23 PM INFO 25521 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/02/2023 04:32:23 PM INFO 25521 [WeightCoalescing]: Finished (changed=True #instances=12670)\n",
      "06/02/2023 04:32:23 PM INFO 25521 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.254s\n",
      "06/02/2023 04:32:23 PM INFO 25521 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/02/2023 04:32:24 PM INFO 25521 [LowerPartitionTile]: Finished (changed=True #instances=21402)\n",
      "06/02/2023 04:32:24 PM INFO 25521 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.969s\n",
      "06/02/2023 04:32:24 PM INFO 25521 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/02/2023 04:32:24 PM INFO 25521 [BroadcastWeights]: Finished (changed=False)\n",
      "06/02/2023 04:32:24 PM INFO 25521 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.297s\n",
      "06/02/2023 04:32:24 PM INFO 25521 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/02/2023 04:32:25 PM INFO 25521 [TensorInitialization]: Finished (changed=False)\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.298s\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/02/2023 04:32:25 PM INFO 25521 [LegalizeTongaAccess]: Finished (changed=True #instances=21402)\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.557s\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/02/2023 04:32:25 PM INFO 25521 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.298s\n",
      "06/02/2023 04:32:25 PM INFO 25521 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/02/2023 04:32:26 PM INFO 25521 [RelaxPredicates]: Finished (changed=False)\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.305s\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/02/2023 04:32:26 PM INFO 25521 [TensorInitialization]: Finished (changed=False)\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.298s\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/02/2023 04:32:26 PM INFO 25521 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.351s\n",
      "06/02/2023 04:32:26 PM INFO 25521 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/02/2023 04:32:27 PM INFO 25521 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/02/2023 04:32:27 PM INFO 25521 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.341s\n",
      "06/02/2023 04:32:27 PM INFO 25521 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/02/2023 04:32:27 PM INFO 25521 [SimplifyTongaTensor]: Finished (changed=True #instances=21402)\n",
      "06/02/2023 04:32:27 PM INFO 25521 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.646s\n",
      "06/02/2023 04:32:27 PM INFO 25521 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/02/2023 04:32:28 PM INFO 25521 [LinearizeFreeDim]: Finished (changed=True #instances=21402)\n",
      "06/02/2023 04:32:28 PM INFO 25521 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.314s\n",
      "06/02/2023 04:32:28 PM INFO 25521 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/02/2023 04:32:28 PM INFO 25521 [DataStreaming]: Finished (changed=False)\n",
      "06/02/2023 04:32:28 PM INFO 25521 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.347s\n",
      "06/02/2023 04:32:28 PM INFO 25521 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/02/2023 04:32:30 PM INFO 25521 [ILPOpt]: Finished (changed=True #instances=21152)\n",
      "06/02/2023 04:32:30 PM INFO 25521 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=2.028s\n",
      "06/02/2023 04:32:30 PM INFO 25521 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/02/2023 04:32:30 PM INFO 25521 [StaticProfiler]: Finished (changed=False)\n",
      "06/02/2023 04:32:30 PM INFO 25521 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.372s\n",
      "06/02/2023 04:32:30 PM INFO 25521 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/02/2023 04:32:31 PM INFO 25521 [LowerAPIndices]: Finished (changed=True #instances=21156)\n",
      "06/02/2023 04:32:31 PM INFO 25521 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.655s\n",
      "06/02/2023 04:32:31 PM INFO 25521 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/02/2023 04:32:31 PM INFO 25521 [LowerMisc]: Finished (changed=False)\n",
      "06/02/2023 04:32:31 PM INFO 25521 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.186s\n",
      "06/02/2023 04:32:31 PM INFO 25521 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/02/2023 04:32:32 PM INFO 25521 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.469s\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Tensorizer]: IR signature: 358c306ad8a9a4c71195432bc72e01bc3b499ce4540b8e12ca35dbf8fde5b2b2 for sg00/Tensorizer\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Tensorizer]: Weights total number of bytes: 171877380\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Tensorizer]: Finalize\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]: --- Penguin Statistics ---\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:           122880  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               80  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               18  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              197  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              200  DataLocalityOpt   Number of prefetch inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                1  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          7036816  DeadStoreElimination  Number of bytes eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              831  DelinearizationBase  Number of tensors delinearized\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              595  FlattenMacroLoop  Number of axes coalesced\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              371  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               51  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         17713152  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              516  InferTongaTensor  Number of local tensor inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        102378824  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               42  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                4  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             1388  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              817  LoopFusion        Number of loops fused\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               18  LoopFusion        Number of trivial copy eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              154  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              563  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              110  LowerTranspose    Number of lossless transpose generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                2  LowerTranspose    Number of lossy transpose generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:           786432  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:           786432  MemcpyElimination  Number of bytes eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                2  MemcpyElimination  Number of memcopy eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              405  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               49  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              341  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              131  PartialLoopFusion  Number of loops fused\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               95  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               12  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               25  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:      11174217216  RelayFE           Number of MAC count in relay\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        897394500  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              198  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               23  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              173  SimplifyTensorBase  Number of tensors simplified\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              173  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          9437184  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:       59694.3242  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         136.7467  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:       59694.3242  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        2910.3307  StaticProfiler    Average dma length per-partition\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        1197.3333  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          90.4226  StaticProfiler    Average partition utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          88.7769  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             3072  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:           0.4246  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             1483  StaticProfiler    Num of matmul transpose instructions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:      23503804434  StaticProfiler    Number of arithmetic computation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          8758928  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:      23457602560  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:            16908  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          8813796  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          2184080  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         15213056  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         11215106  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         31220556  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        171484676  StaticProfiler    Number of bytes of weights loaded\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          1492318  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        171878412  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               14  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:            13593  StaticProfiler    Number of matmul instructions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              870  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             1014  StaticProfiler    Number of tensorcopy from psum\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             1638  StaticProfiler    Number of tensorcopy instructions\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:            22131  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          35.7754  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:          90.4056  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:         145.3976  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:             7380  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              740  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                7  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              733  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              316  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              111  TilingProfiler    Number of pf transposes\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                2  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              109  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:            10060  TilingProfiler    Number of total insts after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              116  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               39  TongaInstComb     Number of bias_add combined to activation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               25  TongaInstComb     Number of scale combined to activation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              259  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              273  TongaLoopFusion   Number of loops fused\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              109  TongaSizeTiling   Number of inherit tiles\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                8  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               25  TongaValueNumbering  Number of instructions deleted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                1  TongaValueNumbering  Number of tensors deleted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:              111  TransformLayoutPass  Number of transpose inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               25  ValueNumbering    Number of instructions deleted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               68  Vectorizer        Number of instruction vectorized\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               96  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:               96  WeightCoalescing  Number of load instruction merged\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:        342592516  WeightRewriter    Number of bytes re-written for weights\n",
      "06/02/2023 04:32:32 PM INFO 25521 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/02/2023 04:32:33 PM INFO 25521 [root/Tensorizer/All]: Exit time region: delta=52.071s\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.Frontend.4]: wrote bir.json\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.Frontend.4]: End tensorization\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.Frontend.4]: Job finished\n",
      "06/02/2023 04:32:34 PM INFO 25521 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/02/2023 04:32:34 PM INFO 25521 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.HHChecker.0]: Job finished\n",
      "06/02/2023 04:32:34 PM INFO 25521 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/02/2023 04:32:34 PM INFO 25521 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/02/2023 04:32:34 PM INFO 25521 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/02/2023 04:32:35 PM INFO 25521 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: max_allowed_parallelism=4\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=1081 blocks=1 instructions=216\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Total count: 20452\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Matmult: 13401\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: TensorScalarPtr: 1837\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: TensorCopy: 1530\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: TensorTensor: 1165\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Activation: 959\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Load: 513\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: TensorReduce: 428\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: TensorScalar: 405\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Shuffle: 97\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Reciprocal: 67\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Memset: 49\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Save: 1\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0.024 seconds\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0.015 seconds\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 513 loads, 1 saves, 0 copies.\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/02/2023 04:32:35 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start DCE Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: End DCE Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/02/2023 04:32:35 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Fri Jun  2 16:32:35 2023\n",
      "06/02/2023 04:32:36 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Fri Jun  2 16:32:36 2023\n",
      "06/02/2023 04:32:36 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Fri Jun  2 16:32:36 2023\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6108 memory location(s), 1 block(s), and 20452 instruction(s).\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6108 blocks=1 instructions=20452\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 171878412\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 3012 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 2559\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 409281 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: 150% PSUM demand before spilling\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 6 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 1456 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 11648 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             lo = 2362\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             hi = 100\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             inf = 97\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             total = 2559\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 27\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           PSUM spills = 27 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         PSUM score = 14578 (lower is better)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best PSUM heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       collect spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       insert spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 2562\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 410241 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 4 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 1264 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 10112 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             lo = 2534\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             hi = 27\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             inf = 1\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             total = 2562\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 14578 cycles\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: number of tensors spilled from PSUM = 27\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: 100% PSUM utilization after allocation\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/MatMul_t8997_i0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         511 pin count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         511 pinned tensors will require about 1484504 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: 1518% SB demand before allocation\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB high-water mark = 1492456 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             1492456 bytes in partitions [0, 31]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             1492456 bytes in partitions [32, 63]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             1245784 bytes in partitions [64, 95]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             1245784 bytes in partitions [96, 127]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 1683789 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 13470312 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:               safe = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             unsafe = 2880\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                inf = 580\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 496\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:            unpinned = 475 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 1407120 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         SB score = 1.62953e+07\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       collect spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       insert spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/MatMul_t8997_i0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         36 pin count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         475 remat count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         36 pinned tensors will require about 85208 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB high-water mark = 101128 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             101128 bytes in partitions [0, 31]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             101128 bytes in partitions [32, 63]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             99544 bytes in partitions [64, 95]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             99544 bytes in partitions [96, 127]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 186382 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 1491056 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:               safe = 493\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             unsafe = 2471\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                inf = 496\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 29\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:            unpinned = 8 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 8168 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         SB score = 108393\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       collect spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       insert spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/MatMul_t8997_i0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         28 pin count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         483 remat count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         28 pinned tensors will require about 77040 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB high-water mark = 94200 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             94200 bytes in partitions [0, 31]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             94200 bytes in partitions [32, 63]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             93360 bytes in partitions [64, 95]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             93360 bytes in partitions [96, 127]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 168023 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 1344184 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:               safe = 971\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             unsafe = 2038\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                inf = 451\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 22\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB spills = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 0 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              remats = 0 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:            unpinned = 1 tensors\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                size = 3072 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         SB score = 39821\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best SB heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       collect spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       insert spills\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         size = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 2253 accumulation groups\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           largest = BertModel_3/BertEncoder_28/BertLayer_24/BertOutput_5/Linear_3/aten_linear/MatMul_t8997_i0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             tensors = 26\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             requires 12288 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         27 pin count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         484 remat count\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         27 pinned tensors will require about 73968 bytes/partition\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 748225 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           SB high-water mark = 91128 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             91128 bytes in partitions [0, 31]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             91128 bytes in partitions [32, 63]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             90288 bytes in partitions [64, 95]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             90288 bytes in partitions [96, 127]\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         found 164619 edges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 1316952 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:               safe = 1413\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             unsafe = 1607\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:                inf = 440\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:              total = 3460\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:             new candidates = 21\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:           success\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: spilling from SB cost about 1.64435e+07 cycles\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: number of tensors unpinned from SB = 484\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: total size of unpinned tensors = 1418360 bytes/partition\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: tried to pin 1484504 bytes/partition\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: 73968 bytes/partition (4%) successfully pinned\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: pinning saved approximately 960174 cycles\n",
      "06/02/2023 04:32:36 PM WARNING [WalrusDriver.0]: 92% SB utilization after allocation\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 171878412, 100% input load, 4.65445e-06% output write, 0% spill/reload \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 171878412, 100% input load, 4.65445e-06% output write, 0% spill/reload \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 171878404\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 3012 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 8\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 171878404\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 3012 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 8\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 41 Sb address, reduced 14 consecutive Load overlapping address \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/02/2023 04:32:36 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:37 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Fri Jun  2 16:32:37 2023\n",
      "06/02/2023 04:32:37 PM INFO [TheScheduler.0]: Done  PosT ScheD Fri Jun  2 16:32:37 2023\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/02/2023 04:32:37 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6138 blocks=1 instructions=20482\n",
      "06/02/2023 04:32:37 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/02/2023 04:32:37 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/sg00\"\n",
      "06/02/2023 04:32:37 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 171878412\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 3012 bytes\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Loads in Func = 513\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Saves in Func = 1\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Input Loads in Func= 513\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Output Saves in Func= 1\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: \n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Transitive reduction removed 24 redundant edges, time: 0:00:00\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Sync Critical Load Chains added 161 new Load-2-Load syncs\n",
      "06/02/2023 04:32:38 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/02/2023 04:32:39 PM WARNING [Stargazer.0]: SBUF DMA write size != 0 mod 4: SBUF address=0x10808, size=2\n",
      "06/02/2023 04:32:39 PM WARNING [Stargazer.0]: SBUF DMA write size != 0 mod 4: SBUF address=0x141880, size=2\n",
      "06/02/2023 04:32:39 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/02/2023 04:32:39 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/02/2023 04:32:40 PM INFO [Stargazer.0]: Virtual memory peak = 3449896 K bytes\n",
      "06/02/2023 04:32:40 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:02\n",
      "06/02/2023 04:32:40 PM INFO [WalrusDriver.0]: ru_maxrss:  2220mb (delta=0mb)\n",
      "06/02/2023 04:32:40 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/02/2023 04:32:40 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6138 memory location(s), 1 block(s), and 20482 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/02/2023 04:32:45 PM INFO 25521 [job.WalrusDriver.3]: IR signature: 2377b4ffd8df0c403922bcf9bade5f154c6326ec4999d50be3ba8b636d4460be for sg00/walrus_bir.out.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.WalrusDriver.3]: Job finished\n",
      "06/02/2023 04:32:45 PM INFO 25521 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/02/2023 04:32:45 PM INFO 25521 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: IR signature: 6c42dc1d8d7bcc30c89aeed04c71be66583728f7dfee22f482d19306491d28ed for sg00/wavegraph-bin.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: IR signature: 9c8151d0c0be3fc70a00ae86bc3d9b83cb1704742882285f4068e5a9b003ed3b for sg00/def.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: IR signature: 98e1ba11ba6d3793a5d1a45c9c9342206ba5205d0c8d1d870cf00083804382ab for sg00/pool.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: IR signature: ed68ec0cab7f853899a886f328af8386ce157a404f71e5e103b80ac27bd8391d for sg00/act.json\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Backend.3]: Job finished\n",
      "06/02/2023 04:32:45 PM INFO 25521 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/02/2023 04:32:45 PM INFO 25521 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/02/2023 04:32:45 PM INFO 25521 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3703-8479-9827-10223_CRSM_0.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3703-8479-9827-10223_CRSM_1.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3731-8498-9831-10227_CRSM_0.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3731-8498-9831-10227_CRSM_1.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3833-8517-9835-10231_CRSM_0.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3833-8517-9835-10231_CRSM_1.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3975-8570-9847-10243_CRSM_0.npy\n",
      "06/02/2023 04:33:01 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t3975-8570-9847-10243_CRSM_1.npy\n",
      "06/02/2023 04:33:02 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t4779-8860-9911-10307_CRSM_0.npy\n",
      "06/02/2023 04:33:02 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/value_sg00_t4779-8860-9911-10307_CRSM_1.npy\n",
      "06/02/2023 04:33:03 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/02/2023 04:33:03 PM WARNING 25521 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/02/2023 04:33:03 PM INFO 25521 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/02/2023 04:33:04 PM INFO 25521 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/scrub/aws-neuron-sdk/src/examples/pytorch/byoc_sm_bert_tutorial/compilation_artifacts/60/graph_def.neff\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.compile.0]: Job finished\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/02/2023 04:33:04 PM INFO 25521 [pipeline.custom.0]: Job finished\n",
      "06/02/2023 04:33:04 PM INFO 25521 [root]: Compiler status PASS\n",
      "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 565, compiled = 548, percent compiled = 96.99%\n",
      "INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
      "INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
      "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 96\n",
      "INFO:Neuron: => aten::add: 36\n",
      "INFO:Neuron: => aten::contiguous: 12\n",
      "INFO:Neuron: => aten::div: 12\n",
      "INFO:Neuron: => aten::dropout: 38\n",
      "INFO:Neuron: => aten::gelu: 12\n",
      "INFO:Neuron: => aten::layer_norm: 25\n",
      "INFO:Neuron: => aten::linear: 74\n",
      "INFO:Neuron: => aten::matmul: 24\n",
      "INFO:Neuron: => aten::permute: 48\n",
      "INFO:Neuron: => aten::select: 1\n",
      "INFO:Neuron: => aten::size: 96\n",
      "INFO:Neuron: => aten::slice: 1\n",
      "INFO:Neuron: => aten::softmax: 12\n",
      "INFO:Neuron: => aten::tanh: 1\n",
      "INFO:Neuron: => aten::transpose: 12\n",
      "INFO:Neuron: => aten::view: 48\n",
      "INFO:Neuron:Not compiled operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 1 [supported]\n",
      "INFO:Neuron: => aten::add: 2 [supported]\n",
      "INFO:Neuron: => aten::add_: 1 [supported]\n",
      "INFO:Neuron: => aten::embedding: 3 [not supported]\n",
      "INFO:Neuron: => aten::mul: 1 [supported]\n",
      "INFO:Neuron: => aten::rsub: 1 [supported]\n",
      "INFO:Neuron: => aten::size: 1 [supported]\n",
      "INFO:Neuron: => aten::slice: 4 [supported]\n",
      "INFO:Neuron: => aten::to: 1 [supported]\n",
      "INFO:Neuron: => aten::unsqueeze: 2 [supported]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# Run torch.neuron.trace to generate a TorchScript that is optimized by AWS Neuron\n",
    "# This step may need 3-5 min\n",
    "model_neuron = torch.neuron.trace(model, example_inputs_paraphrase, verbose=1, compiler_workdir='./compilation_artifacts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4752ac",
   "metadata": {},
   "source": [
    "You may inspect **model_neuron.graph** to see which part is running on CPU versus running on the accelerator. All native **aten** operators in the graph will be running on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc00889e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.torch_neuron.runtime.___torch_mangle_423.AwsNeuronGraphModule,\n",
      "      %7 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %tensor.1 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu),\n",
      "      %9 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu)):\n",
      "  %_NeuronGraph#60 : __torch__.torch_neuron.decorators.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#60\"](%self.1)\n",
      "  %16 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %17 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %18 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %19 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %20 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.1, %16, %17, %18, %19) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %21 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %22 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %23 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %24 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %25 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = aten::slice(%20, %21, %22, %23, %24) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %26 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %27 : Long(1, 1, 128, strides=[128, 128, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%25, %26) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %28 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.3 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%27, %28) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %42 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %43 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %44 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %45 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %46 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.3, %42, %43, %44, %45) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %47 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %48 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %49 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %50 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %51 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%46, %47, %48, %49, %50) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %52 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %53 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %54 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %55 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %56 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%51, %52, %53, %54, %55) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %57 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %58 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %59 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %60 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %tensor.5 : Long(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::slice(%56, %57, %58, %59, %60) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %62 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %63 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %64 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %65 : NoneType = prim::Constant()\n",
      "  %66 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %62, %63, %64, %65) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %67 : float = prim::Constant[value=1.]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %68 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %69 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::rsub(%66, %67, %68) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %70 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %71 : Float(1, 1, 1, 128, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = aten::mul(%69, %70) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.7 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:28:0\n",
      "  %90 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %91 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %92 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %93 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %94 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %90, %91, %92, %93) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %95 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %96 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %97 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %98 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %tensor : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%94, %95, %96, %97, %98) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %106 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %107 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %108 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %109 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %110 : Long(1, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor, %106, %107, %108, %109) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %111 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %112 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %113 : int = prim::Constant[value=128]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %114 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %115 : Long(1, 128, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%110, %111, %112, %113, %114) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %116 : Float(28996, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %117 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %118 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %119 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %120 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%116, %7, %117, %118, %119) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %121 : Float(2, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %122 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %123 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %124 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %125 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%121, %9, %122, %123, %124) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %126 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %127 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::add(%120, %125, %126) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %128 : Float(512, 768, strides=[768, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %129 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %130 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %131 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %132 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::embedding(%128, %115, %129, %130, %131) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %133 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %134 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=0, device=cpu) = aten::add_(%127, %132, %133) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#60)\n",
      "  %144 : Tensor[] = prim::ListConstruct(%134, %71), scope: __module._NeuronGraph#60\n",
      "  %145 : Float(1, 2, strides=[2, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%144, %model), scope: __module._NeuronGraph#60 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %137 : (Float(1, 2, strides=[2, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%145)\n",
      "  return (%137)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See  which part is running on CPU versus running on the accelerator.\n",
    "print(model_neuron.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fb30d",
   "metadata": {},
   "source": [
    "Save the compiled model, so it can be packaged and sent to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027c4f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the TorchScript for later use\n",
    "model_neuron.save('neuron_compiled_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362c579",
   "metadata": {},
   "source": [
    "### Package the pre-trained model and upload it to S3\n",
    "\n",
    "To make the model available for the SageMaker deployment, you will TAR the serialized graph and upload it to the default Amazon S3 bucket for your SageMaker session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c7f7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "neuron_compiled_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Now you'll create a model.tar.gz file to be used by SageMaker endpoint\n",
    "!tar -czvf model.tar.gz neuron_compiled_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1beadca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ad87d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload model to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "sess=sagemaker.Session()\n",
    "region=sess.boto_region_name\n",
    "bucket=sess.default_bucket()\n",
    "sm_client=boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5205ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded model to S3:\n",
      "s3://sagemaker-eu-north-1-058095970122/inf1_compiled_model/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_key = '{}/model/model.tar.gz'.format('inf1_compiled_model')\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model.tar.gz', model_key)\n",
    "print(\"Uploaded model to S3:\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b425d4",
   "metadata": {},
   "source": [
    "## Build and Push the container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e6ed2",
   "metadata": {},
   "source": [
    "The following shell code shows how to build the container image using docker build and push the container image to ECR using docker push.\n",
    "The Dockerfile in this example is available in the ***container*** folder.\n",
    "Here's an example of the Dockerfile:\n",
    "\n",
    "```Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuron:1.7.1-neuron-py36-ubuntu18.04\n",
    "\n",
    "# Install packages \n",
    "RUN pip install \"transformers==4.7.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3970025d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuron:1.7.1-neuron-py36-ubuntu18.04\n",
      "\n",
      "# Install packages \n",
      "RUN pip install \"transformers==4.7.0\"\n",
      "# CMD [\"/usr/local/bin/entrypoint.sh\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f78b0f",
   "metadata": {},
   "source": [
    "Before running the next cell, make sure your SageMaker IAM role has access to ECR. If not, you can attache the role `AmazonEC2ContainerRegistryPowerUser` to your IAM role ARN, which allows you to upload image layers to ECR.  \n",
    "\n",
    "It takes 5 minutes to build docker images and upload image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd51acf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  2.048kB\n",
      "Step 1/2 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuron:1.7.1-neuron-py36-ubuntu18.04\n",
      " ---> 388bfe7d2429\n",
      "Step 2/2 : RUN pip install \"transformers==4.7.0\"\n",
      " ---> Using cache\n",
      " ---> af9a9780c160\n",
      "[Warning] One or more build-args [REGION] were not consumed\n",
      "Successfully built af9a9780c160\n",
      "Successfully tagged neuron-py36-inference:latest\n",
      "Login Succeeded\n",
      "The push refers to repository [058095970122.dkr.ecr.eu-north-1.amazonaws.com/neuron-py36-inference]\n",
      "64d7fb3bd65e: Preparing\n",
      "5d32c72ad027: Preparing\n",
      "f4d9427d752b: Preparing\n",
      "62b8cb6215cb: Preparing\n",
      "877b36f2f41c: Preparing\n",
      "4beb4e23ce0b: Preparing\n",
      "629f76e0ebfa: Preparing\n",
      "55aafc4b4134: Preparing\n",
      "5b505b65f8e8: Preparing\n",
      "4383d9750962: Preparing\n",
      "120ef6a75dae: Preparing\n",
      "d1a63e051735: Preparing\n",
      "1353ff378dc3: Preparing\n",
      "3d7573db3c3f: Preparing\n",
      "2858c813c4e4: Preparing\n",
      "e8b427e8fb51: Preparing\n",
      "6b9a1856b2e9: Preparing\n",
      "79ec63999885: Preparing\n",
      "5dcdeb94f6a5: Preparing\n",
      "b8b74f1e44f0: Preparing\n",
      "bf9a431aeda6: Preparing\n",
      "5f08512fd434: Preparing\n",
      "c7bb31fc0e08: Preparing\n",
      "50858308da3d: Preparing\n",
      "4beb4e23ce0b: Waiting\n",
      "629f76e0ebfa: Waiting\n",
      "55aafc4b4134: Waiting\n",
      "5b505b65f8e8: Waiting\n",
      "4383d9750962: Waiting\n",
      "120ef6a75dae: Waiting\n",
      "5dcdeb94f6a5: Waiting\n",
      "d1a63e051735: Waiting\n",
      "b8b74f1e44f0: Waiting\n",
      "bf9a431aeda6: Waiting\n",
      "5f08512fd434: Waiting\n",
      "c7bb31fc0e08: Waiting\n",
      "50858308da3d: Waiting\n",
      "1353ff378dc3: Waiting\n",
      "e8b427e8fb51: Waiting\n",
      "3d7573db3c3f: Waiting\n",
      "2858c813c4e4: Waiting\n",
      "6b9a1856b2e9: Waiting\n",
      "79ec63999885: Waiting\n",
      "f4d9427d752b: Layer already exists\n",
      "62b8cb6215cb: Layer already exists\n",
      "877b36f2f41c: Layer already exists\n",
      "5d32c72ad027: Layer already exists\n",
      "64d7fb3bd65e: Layer already exists\n",
      "4beb4e23ce0b: Layer already exists\n",
      "55aafc4b4134: Layer already exists\n",
      "5b505b65f8e8: Layer already exists\n",
      "629f76e0ebfa: Layer already exists\n",
      "4383d9750962: Layer already exists\n",
      "d1a63e051735: Layer already exists\n",
      "120ef6a75dae: Layer already exists\n",
      "6b9a1856b2e9: Layer already exists\n",
      "79ec63999885: Pushed\n",
      "5dcdeb94f6a5: Pushed\n",
      "b8b74f1e44f0: Pushed\n",
      "3d7573db3c3f: Pushed\n",
      "5f08512fd434: Pushed\n",
      "c7bb31fc0e08: Pushed\n",
      "50858308da3d: Pushed\n",
      "e8b427e8fb51: Pushed\n",
      "2858c813c4e4: Pushed\n",
      "bf9a431aeda6: Pushed\n",
      "1353ff378dc3: Pushed\n",
      "latest: digest: sha256:feb4eeb2bb8e84783ca97f42c2a96233dc8e94809c57f77d4ec8f4a51a6bc881 size: 5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=neuron-py36-inference\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${account}.dkr.ecr.${region}.amazonaws.com\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6bbda",
   "metadata": {},
   "source": [
    "## Deploy Container and run inference based on the pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65e31",
   "metadata": {},
   "source": [
    "To deploy a pretrained PyTorch model, you'll need to use the PyTorch estimator object to create a PyTorchModel object and set a different entry_point.\n",
    "\n",
    "You'll use the PyTorchModel object to deploy a PyTorchPredictor. This creates a SageMaker Endpoint -- a hosted prediction service that we can use to perform inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f343d3b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: Transformers in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (0.0.8)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (1.18.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (0.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (4.11.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from Transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->Transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->Transformers) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->Transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->Transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->Transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->Transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->Transformers) (2022.12.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->Transformers) (1.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->Transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->Transformers) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bd73b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "058095970122.dkr.ecr.eu-north-1.amazonaws.com/neuron-py36-inference:latest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"inf1_compiled_model/model\"\n",
    "\n",
    "# Get container name in ECR\n",
    "client=boto3.client('sts')\n",
    "account=client.get_caller_identity()['Account']\n",
    "\n",
    "my_session=boto3.session.Session()\n",
    "region=my_session.region_name\n",
    "\n",
    "algorithm_name=\"neuron-py36-inference\"\n",
    "ecr_image='{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "print(ecr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9298f2a7",
   "metadata": {},
   "source": [
    "An implementation of *model_fn* is required for inference script.\n",
    "We are going to implement our own **model_fn** and **predict_fn** for Hugging Face Bert, and use default implementations of **input_fn** and **output_fn** defined in sagemaker-pytorch-containers.\n",
    "\n",
    "In this example, the inference script is put in ***code*** folder. Run the next cell to see it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfea75b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m  \u001b[37m# to workaround a protobuf version conflict issue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mneuron\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "JSON_CONTENT_TYPE = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer_init = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39;49;00m\u001b[33mbert-base-cased-finetuned-mrpc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model_file =os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mneuron_compiled_model.pt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model_neuron = torch.jit.load(model_file)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#    print(\"using {}\".format(model_file))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m (model_neuron, tokenizer_init)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(serialized_input_data, content_type=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        input_data = json.loads(serialized_input_data)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#        print(input_data)\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m input_data\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + content_type)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, models):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#    print('Got input Data: {}'.format(input_data))\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model_bert, tokenizer = models\u001b[37m\u001b[39;49;00m\n",
      "    sequence_0 = input_data[\u001b[34m0\u001b[39;49;00m] \u001b[37m\u001b[39;49;00m\n",
      "    sequence_1 = input_data[\u001b[34m1\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    max_length=\u001b[34m128\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, max_length=max_length, padding=\u001b[33m'\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Convert example inputs to a format that is compatible with TorchScript tracing\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    example_inputs_paraphrase = paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], paraphrase[\u001b[33m'\u001b[39;49;00m\u001b[33mtoken_type_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]  \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Verify the TorchScript works on example inputs\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase_classification_logits_neuron = model_bert(*example_inputs_paraphrase)\u001b[37m\u001b[39;49;00m\n",
      "    classes = [\u001b[33m'\u001b[39;49;00m\u001b[33mnot paraphrase\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mparaphrase\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "    paraphrase_prediction = paraphrase_classification_logits_neuron[\u001b[34m0\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m].argmax().item()\u001b[37m\u001b[39;49;00m\n",
      "    out_str = \u001b[33m'\u001b[39;49;00m\u001b[33mBERT says that \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m and \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m are \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(sequence_0, sequence_1, classes[paraphrase_prediction])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m out_str\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction_output, accept=JSON_CONTENT_TYPE):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m accept == JSON_CONTENT_TYPE:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(prediction_output), accept\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mraise\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mRequested unsupported ContentType in Accept: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + accept)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31a7b8",
   "metadata": {},
   "source": [
    "Path of compiled pretrained model in S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f3556e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-north-1-058095970122/inf1_compiled_model/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "key = os.path.join(prefix, \"model.tar.gz\")\n",
    "pretrained_model_data = \"s3://{}/{}\".format(bucket, key)\n",
    "print(pretrained_model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7557a5f",
   "metadata": {},
   "source": [
    "The model object is defined by using the SageMaker Python SDK's PyTorchModel and pass in the model from the estimator and the entry_point. The endpoint's entry point for inference is defined by model_fn as seen in the previous code block that prints out **inference.py**. The model_fn function will load the model and required tokenizer.\n",
    "\n",
    "Note, **image_uri** must be user's own ECR images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bd99768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=pretrained_model_data,\n",
    "    role=role,\n",
    "    source_dir=\"code\",\n",
    "    framework_version=\"1.7.1\",\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=ecr_image\n",
    ")\n",
    "\n",
    "# Let SageMaker know that we've already compiled the model via neuron-cc\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67439fe7",
   "metadata": {},
   "source": [
    "The arguments to the deploy function allow us to set the number and type of instances that will be used for the Endpoint.\n",
    "\n",
    "Here you will deploy the model to a single **ml.inf1.2xlarge** instance.\n",
    "It may take 6-10 min to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d771fc7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 10.5 s, sys: 2 s, total: 12.5 s\n",
      "Wall time: 7min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = pytorch_model.deploy(initial_instance_count=1, instance_type=\"ml.inf1.2xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab6342f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron-py36-inference-ml-inf1-2023-06-02-16-51-14-376\n"
     ]
    }
   ],
   "source": [
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059537d9",
   "metadata": {},
   "source": [
    "Since in the input_fn we declared that the incoming requests are json-encoded, we need to use a json serializer, to encode the incoming data into a json string. Also, we declared the return content type to be json string, we Need to use a json deserializer to parse the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e82f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d006ea03",
   "metadata": {},
   "source": [
    "Using a list of sentences, now SageMaker endpoint is invoked to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "325a87f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT says that \"Never allow the same bug to bite you twice.\" and \"The best part of Amazon SageMaker is that it makes machine learning easy.\" are not paraphrase\n",
      "CPU times: user 9.5 ms, sys: 310 µs, total: 9.81 ms\n",
      "Wall time: 143 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = predictor.predict(\n",
    "    [\n",
    "        \"Never allow the same bug to bite you twice.\",\n",
    "        \"The best part of Amazon SageMaker is that it makes machine learning easy.\",\n",
    "    ]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a12410d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT says that \"The company HuggingFace is based in New York City\" and \"HuggingFace's headquarters are situated in Manhattan\" are paraphrase\n",
      "CPU times: user 2.27 ms, sys: 540 µs, total: 2.81 ms\n",
      "Wall time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = predictor.predict(\n",
    "    [\n",
    "        \"The company HuggingFace is based in New York City\",\n",
    "        \"HuggingFace's headquarters are situated in Manhattan\",\n",
    "    ]\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72dfd16",
   "metadata": {},
   "source": [
    "## Benchmarking your endpoint\n",
    "\n",
    "The following cells create a load test for your endpoint. You first define some helper functions: `inference_latency` runs the endpoint request, collects cliend side latency and any errors, `random_sentence` builds random to be sent to the endpoint.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "088d0e75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import boto3   \n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038d9953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_latency(model,*inputs):\n",
    "    \"\"\"\n",
    "    infetence_time is a simple method to return the latency of a model inference.\n",
    "\n",
    "        Parameters:\n",
    "            model: torch model onbject loaded using torch.jit.load\n",
    "            inputs: model() args\n",
    "\n",
    "        Returns:\n",
    "            latency in seconds\n",
    "    \"\"\"\n",
    "    error = False\n",
    "    start = time.time()\n",
    "    try:\n",
    "        results = model(*inputs)\n",
    "    except:\n",
    "        error = True\n",
    "        results = []\n",
    "    return {'latency':time.time() - start, 'error': error, 'result': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6b200ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A sloth spies on superman', 'My mom meets with some guy']\n"
     ]
    }
   ],
   "source": [
    "def random_sentence():\n",
    "    \n",
    "    s_nouns = [\"A dude\", \"My mom\", \"The king\", \"Some guy\", \"A cat with rabies\", \"A sloth\", \"Your homie\", \"This cool guy my gardener met yesterday\", \"Superman\"]\n",
    "    p_nouns = [\"These dudes\", \"Both of my moms\", \"All the kings of the world\", \"Some guys\", \"All of a cattery's cats\", \"The multitude of sloths living under your bed\", \"Your homies\", \"Like, these, like, all these people\", \"Supermen\"]\n",
    "    s_verbs = [\"eats\", \"kicks\", \"gives\", \"treats\", \"meets with\", \"creates\", \"hacks\", \"configures\", \"spies on\", \"retards\", \"meows on\", \"flees from\", \"tries to automate\", \"explodes\"]\n",
    "    p_verbs = [\"eat\", \"kick\", \"give\", \"treat\", \"meet with\", \"create\", \"hack\", \"configure\", \"spy on\", \"retard\", \"meow on\", \"flee from\", \"try to automate\", \"explode\"]\n",
    "    infinitives = [\"to make a pie.\", \"for no apparent reason.\", \"because the sky is green.\", \"for a disease.\", \"to be able to make toast explode.\", \"to know more about archeology.\"]\n",
    "    \n",
    "    return (random.choice(s_nouns) + ' ' + random.choice(s_verbs) + ' ' + random.choice(s_nouns).lower() or random.choice(p_nouns).lower() + ' ' + random.choice(infinitives))\n",
    "\n",
    "print([random_sentence(), random_sentence()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2945dde",
   "metadata": {},
   "source": [
    "The following cell creates `number_of_clients` concurrent threads to run `number_of_runs` requests. Once completed, a `boto3` CloudWatch client will query for the server side latency metrics for comparison.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69c047e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 105.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Throughput: :105.0\n",
      "\n",
      "50th Percentile Latency:18.6 ms\n",
      "90th Percentile Latency:20.1 ms\n",
      "95th Percentile Latency:24.1 ms\n",
      "\n",
      "Errors percentage: 0.0 %\n",
      "\n",
      "Getting Cloudwatch:\n",
      "Time elapsed: 309.520107 seconds\n",
      "Using period of 360 seconds\n",
      "\n",
      "Waiting 30 seconds ...\n",
      "502.0 latency datapoints ready\n",
      "50th Percentile Latency:13.0 ms\n",
      "90th Percentile Latency:13.7 ms\n",
      "95th Percentile Latency:13.8 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining Auxiliary variables\n",
    "number_of_clients = 2\n",
    "number_of_runs = 1000\n",
    "t = tqdm(range(number_of_runs),position=0, leave=True)\n",
    "\n",
    "# Starting parallel clients\n",
    "cw_start = datetime.datetime.utcnow()\n",
    "\n",
    "results = Parallel(n_jobs=number_of_clients,prefer=\"threads\")(delayed(inference_latency)(predictor.predict,[random_sentence(), random_sentence()]) for mod in t)\n",
    "avg_throughput = t.total/t.format_dict['elapsed']\n",
    "\n",
    "cw_end = datetime.datetime.utcnow() \n",
    "\n",
    "# Computing metrics and print\n",
    "latencies = [res['latency'] for res in results]\n",
    "errors = [res['error'] for res in results]\n",
    "error_p = sum(errors)/len(errors) *100\n",
    "p50 = np.quantile(latencies[-1000:],0.50) * 1000\n",
    "p90 = np.quantile(latencies[-1000:],0.95) * 1000\n",
    "p95 = np.quantile(latencies[-1000:],0.99) * 1000\n",
    "\n",
    "print(f'Avg Throughput: :{avg_throughput:.1f}\\n')\n",
    "print(f'50th Percentile Latency:{p50:.1f} ms')\n",
    "print(f'90th Percentile Latency:{p90:.1f} ms')\n",
    "print(f'95th Percentile Latency:{p95:.1f} ms\\n')\n",
    "print(f'Errors percentage: {error_p:.1f} %\\n')\n",
    "\n",
    "# Querying CloudWatch\n",
    "print('Getting Cloudwatch:')\n",
    "cloudwatch = boto3.client('cloudwatch')\n",
    "statistics=['SampleCount', 'Average', 'Minimum', 'Maximum']\n",
    "extended=['p50', 'p90', 'p95', 'p100']\n",
    "\n",
    "# Give 5 minute buffer to end\n",
    "cw_end += datetime.timedelta(minutes=5)\n",
    "\n",
    "# Period must be 1, 5, 10, 30, or multiple of 60\n",
    "# Calculate closest multiple of 60 to the total elapsed time\n",
    "factor = math.ceil((cw_end - cw_start).total_seconds() / 60)\n",
    "period = factor * 60\n",
    "print('Time elapsed: {} seconds'.format((cw_end - cw_start).total_seconds()))\n",
    "print('Using period of {} seconds\\n'.format(period))\n",
    "\n",
    "cloudwatch_ready = False\n",
    "# Keep polling CloudWatch metrics until datapoints are available\n",
    "while not cloudwatch_ready:\n",
    "  time.sleep(30)\n",
    "  print('Waiting 30 seconds ...')\n",
    "  # Must use default units of microseconds\n",
    "  model_latency_metrics = cloudwatch.get_metric_statistics(MetricName='ModelLatency',\n",
    "                                             Dimensions=[{'Name': 'EndpointName',\n",
    "                                                          'Value': predictor.endpoint_name},\n",
    "                                                         {'Name': 'VariantName',\n",
    "                                                          'Value': \"AllTraffic\"}],\n",
    "                                             Namespace=\"AWS/SageMaker\",\n",
    "                                             StartTime=cw_start,\n",
    "                                             EndTime=cw_end,\n",
    "                                             Period=period,\n",
    "                                             Statistics=statistics,\n",
    "                                             ExtendedStatistics=extended\n",
    "                                             )\n",
    "  # Should be 1000\n",
    "  if len(model_latency_metrics['Datapoints']) > 0:\n",
    "    print('{} latency datapoints ready'.format(model_latency_metrics['Datapoints'][0]['SampleCount']))\n",
    "    side_avg = model_latency_metrics['Datapoints'][0]['Average'] / number_of_runs\n",
    "    side_p50 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p50'] / number_of_runs\n",
    "    side_p90 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p90'] / number_of_runs\n",
    "    side_p95 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p95'] / number_of_runs\n",
    "    side_p100 = model_latency_metrics['Datapoints'][0]['ExtendedStatistics']['p100'] / number_of_runs\n",
    "    \n",
    "    print(f'50th Percentile Latency:{side_p50:.1f} ms')\n",
    "    print(f'90th Percentile Latency:{side_p90:.1f} ms')\n",
    "    print(f'95th Percentile Latency:{side_p95:.1f} ms\\n')\n",
    "\n",
    "    cloudwatch_ready = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9035e681",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Endpoints should be deleted when no longer in use, to avoid costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1284ef3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af53873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
