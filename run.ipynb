{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4674f667",
   "metadata": {},
   "source": [
    "# TAPAS deployment via Sagemaker-Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39838",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c454f",
   "metadata": {},
   "source": [
    "This notebook creates an instance of ```TAPAS_Deployer``` and calls all neccessary actions to build, deploy, and test a mini variant of TAPAS for tabular question answering. For details, please refer to the source files included in ```./source``` and ```./entrypoint``` which were refactored to be easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92460bb-f922-43f9-a435-8ddb062cbffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to use this notebook..\n",
    "- Create an AWS account.\n",
    "- Create an IAM role with the following access permissions: ```AmazonSageMakerFullAccess, EC2InstanceProfileForImageBuilderECRContainerBuilds, AWSAppRunnerServicePolicyForECRAccess```\n",
    "- Start a new Notebook instance in Sagemaker using the role created above.\n",
    "- Clone this repository and run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3092c",
   "metadata": {},
   "source": [
    "## Some notes for Scrub..\n",
    "- ```Deployer``` is a generic class template from which many models can be built and deployed directly.\n",
    "- ```TAPAS_Deployer``` inherits Deployer and any other model can be similarly created with minimum effort.\n",
    "- To avoid timeouts and and random kernel restarts, the running code is separated from the noteboook running it. \n",
    "- Everything in ```./source``` can be easily imported as an API.\n",
    "- Some integration pytest samples are included in ```./tests```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1f0bf-6516-420c-9193-bf6c6380dcf0",
   "metadata": {},
   "source": [
    "### Install local dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066c3731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch-neuron in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1.2.7.1.0)\n",
      "Requirement already satisfied: neuron-cc[tensorflow] in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.15.0.0+eec0c3604)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (0.14.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: torch-scatter in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (2.1.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: inferentia-hwm==1.14.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.14.1.0+a9fb5c73a)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.7.3)\n",
      "Requirement already satisfied: dmlc-tvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: networkx<=2.6.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2.6.3)\n",
      "Requirement already satisfied: dmlc-nnvm==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: islpy<=2022.1.1,>2021.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (2022.1.1)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (3.20.1)\n",
      "Requirement already satisfied: numpy<2,>=1.13.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.18.5)\n",
      "Requirement already satisfied: dmlc-topi==1.15.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.0.0+0)\n",
      "Requirement already satisfied: tensorflow<2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from neuron-cc[tensorflow]) (1.15.5)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-topi==1.15.0.0->neuron-cc[tensorflow]) (5.1.1)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dmlc-tvm==1.15.0.0->neuron-cc[tensorflow]) (22.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: pytest>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (7.3.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.54.2)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.4.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: h5py<=2.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorflow<2->neuron-cc[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (1.1.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (4.11.4)\n",
      "Requirement already satisfied: iniconfig in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (2.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (3.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow<2->neuron-cc[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->pytest>=2->islpy<=2022.1.1,>2021.1->neuron-cc[tensorflow]) (3.0.9)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers==4.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (4.6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2022.10.31)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.11.4)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.8)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (1.18.5)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (3.9.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers==4.6.0) (0.0.53)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging->transformers==4.6.0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers==4.6.0) (2022.12.7)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers==4.6.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch torch-scatter --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "!pip install --upgrade --no-cache-dir 'transformers==4.6.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4796d3a",
   "metadata": {},
   "source": [
    "### Prepare deployer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe85f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from source.tapas import TAPAS_Deployer\n",
    "tapas_deployer = TAPAS_Deployer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9222-f669-4fed-aafe-8d5bb4170ad6",
   "metadata": {},
   "source": [
    "### Retrieve model from Huggingface Hub and prepare its respective tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189b83ed-7abe-4219-bcc5-f70d38023d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.get_model_and_tokeniser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa89ef-fc6a-49c2-b923-a7a54c60ea33",
   "metadata": {},
   "source": [
    "### Trace the model to be deployed into a Neuron instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df5a2f0-4af5-4c34-9e19-3a2390bb0c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1511: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.indices = torch.as_tensor(indices)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1512: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  self.num_segments = torch.as_tensor(num_segments, device=indices.device)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1617: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  batch_size = torch.prod(torch.tensor(list(index.batch_shape())))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1617: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  batch_size = torch.prod(torch.tensor(list(index.batch_shape())))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1693: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  [torch.as_tensor([-1], dtype=torch.long), torch.as_tensor(vector_shape, dtype=torch.long)], dim=0\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1696: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  flat_values = values.reshape(flattened_shape.tolist())\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1709: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.as_tensor(index.batch_shape(), dtype=torch.long),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1709: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  torch.as_tensor(index.batch_shape(), dtype=torch.long),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1710: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.as_tensor([index.num_segments], dtype=torch.long),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1710: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  torch.as_tensor([index.num_segments], dtype=torch.long),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1711: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.as_tensor(vector_shape, dtype=torch.long),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1716: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  output_values = segment_means.view(new_shape.tolist())\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1645: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  batch_shape, dtype=torch.long\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1645: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  batch_shape, dtype=torch.long\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1648: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  num_segments = torch.as_tensor(num_segments)  # create a rank 0 tensor (scalar) containing num_segments (e.g. 64)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1659: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  new_shape = [int(x) for x in new_tensor.tolist()]\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1662: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  multiples = torch.cat([batch_shape, torch.as_tensor([1])], dim=0)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1663: TracerWarning: Converting a tensor to a Python list might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  indices = indices.repeat(multiples.tolist())\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:309: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.as_tensor(self.config.max_position_embeddings - 1, device=device), position - first_position\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/modeling_utils.py:1968: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1190: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  indices=torch.min(row_ids, torch.as_tensor(self.config.max_num_rows - 1, device=row_ids.device)),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1195: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  indices=torch.min(column_ids, torch.as_tensor(self.config.max_num_columns - 1, device=column_ids.device)),\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1875: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  is_padding, dtype=torch.float32, device=is_padding.device\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1880: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.eq(out_index.indices, 0), dtype=torch.float32, device=out_index.indices.device\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1915: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  labels_per_column, _ = reduce_sum(torch.as_tensor(labels, dtype=torch.float32, device=labels.device), col_index)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1938: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.as_tensor(labels, dtype=torch.long, device=labels.device), cell_index\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1948: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  device=cell_mask.device,\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1971: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.argmax(column_logits, dim=-1), dtype=torch.long, device=column_logits.device\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/transformers/models/tapas/modeling_tapas.py:1978: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  device=selected_column_id.device,\n",
      "INFO:Neuron:There are 33 ops of 8 different types in the TorchScript that are not compiled by neuron-cc: aten::gather, aten::fmod, torch_scatter::scatter_max, aten::prod, aten::index_put_, aten::scatter_add_, aten::embedding, torch_scatter::scatter_min, (For more information see https://awsdocs-neuron.readthedocs-hosted.com/en/latest/release-notes/compiler/neuron-cc/neuron-cc-ops/neuron-cc-ops-pytorch.html)\n",
      "INFO:Neuron:Number of arithmetic operators (pre-compilation) before = 582, fused = 548, percent fused = 94.16%\n",
      "INFO:Neuron:Compiling function _NeuronGraph$293 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_to_1/Const:0\", \"TapasModel_7/TapasEmbeddings_27/aten_reshape/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:15 PM INFO 32612 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_to_1/Const:0\", \"TapasModel_7/TapasEmbeddings_27/aten_reshape/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:15 PM INFO 32612 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0\n",
      "06/11/2023 03:06:15 PM INFO 32612 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:15 PM INFO 32612 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:15 PM INFO 32612 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:15 PM INFO 32612 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:15 PM INFO 32612 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_to_1/Const:0\", \"TapasModel_7/TapasEmbeddings_27/aten_reshape/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:16 PM INFO 32612 [job.Frontend.4]: IR signature: af4a632d4b5015081688d72daaa45b31aa0636c8b283d598e8e69e6671782c33 for graph_def.pb\n",
      "06/11/2023 03:06:16 PM INFO 32612 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:16 PM INFO 32612 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:16 PM INFO 32612 [job.Frontend.4]: Start tensorization\n",
      "[15:06:16] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:16] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=97\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:16] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        97           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:16] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_reshape/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_to_1/Const:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:16 PM INFO 32612 [job.Frontend.4]: IR signature: b8a099c110d2dd3ad7d2577fc5efdc265d491e25c54966648f1e34828f32c073 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:16 PM INFO 32612 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.028s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:16 PM INFO 32612 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Statistics]: Weights total number of bytes: 12296\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Statistics]: RelayIF total number of bytes: 0.0\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Statistics]: RelayOF total number of bytes: 12296.0\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Statistics]: Weights total number of bytes: 12296.0\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [MutateDataType]: Finished (changed=True #instances=6148)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Simplifier]: Finished (changed=True #instances=6146)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [DelinearIndices]: Finished (changed=True #instances=6146)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:16 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:16 PM INFO 32612 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ResolveAccessConflict]: Finished (changed=True #instances=12294)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TransformLayout]: Finished (changed=True #instances=12294)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaSizeTiling]: Finished (changed=True #instances=40)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [InferTongaTensor]: Finished (changed=True #instances=40)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [DataLocalityOpt]: Finished (changed=True #instances=54)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [RewriteWeights]: Finished (changed=True #instances=54)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ReshapeWeights]: Finished (changed=True #instances=54)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [InferInitValue]: Finished (changed=True #instances=54)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SimplifyTongaTensor]: Finished (changed=True #instances=54)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaISel]: Finished (changed=True #instances=78)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaLoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaInstComb]: Finished (changed=True #instances=66)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.013s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizeTongaType]: Finished (changed=True #instances=66)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [PartialLoopFusion]: Finished (changed=True #instances=66)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.013s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ShortenLifeInterval]: Finished (changed=True #instances=66)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizeTongaType]: Finished (changed=True #instances=66)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LowerPartitionTile]: Finished (changed=True #instances=114)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LinearizeFreeDim]: Finished (changed=True #instances=114)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [ILPOpt]: Finished (changed=True #instances=26)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.015s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LowerAPIndices]: Finished (changed=True #instances=26)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:17 PM INFO 32612 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Tensorizer]: IR signature: 6a36e7f281ab6ddab21704ca0fe3d85596d1ad1150ae116334ff388460b069a4 for sg00/Tensorizer\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Tensorizer]: Weights total number of bytes: 6144\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                2  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                3  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                4  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            24592  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                3  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            12288  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                2  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                2  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            12296  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           0.1249  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           0.1249  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:          10.8571  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:           8.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:          89.5970  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            18440  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:             6144  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               48  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            18440  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               14  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               13  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                8  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               52  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:          90.0781  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:               40  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                3  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:            12288  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:17 PM INFO 32612 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:17 PM INFO 32612 [root/Tensorizer/All]: Exit time region: delta=1.072s\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:17 PM INFO 32612 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:17 PM INFO 32612 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:17 PM INFO 32612 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:17 PM INFO 32612 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:17 PM INFO 32612 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.WalrusDriver.3]: IR signature: 286f8cf4010acba03ecfeea19080572c6fc505a2a7560860fe66eec170908ef9 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: IR signature: 7b11850a91ece1da69c5935456bd43dd3ce4fefa8595a3f33cdef5d56953c367 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: IR signature: 6ac1b065213242d430ffca2217f83f2488bc34f97748cbdd5b2dd6edd41b3071 for sg00/def.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: IR signature: cc075505f49e6e50dcb409c9fcf08a5f4f9d5e923d0cf065d5c80301ef8a4197 for sg00/pool.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:18 PM WARNING 32612 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:18 PM WARNING 32612 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:18 PM INFO 32612 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/graph_def.neff\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:18 PM INFO 32612 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:18 PM INFO 32612 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=8 blocks=1 instructions=8\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Total count: 26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Save: 13\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: TensorCopy: 8\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Memset: 2\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Load: 1\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 1 loads, 13 saves, 0 copies.\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:17 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18440\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 11 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         size = 7\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 48 bytes/partition\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         bit-matrix size = 4 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           SB high-water mark = 336 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             336 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             336 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             336 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             336 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         found 12 edges\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         adjacency vectors require 96 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:               safe = 7\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:              total = 7\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: 48 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: pinning saved approximately 1114 cycles\n",
      "06/11/2023 03:06:17 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18440, 33.3189% input load, 66.6811% output write, 0% spill/reload \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18440, 33.3189% input load, 66.6811% output write, 0% spill/reload \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 48 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12296\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 48 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12296\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:18 2023\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:17 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=10 blocks=1 instructions=26\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/0/sg00\"\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18440\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 11 bytes\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Loads in Func = 1\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Saves in Func = 13\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Input Loads in Func= 1\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Output Saves in Func= 13\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:17 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: Virtual memory peak = 4358792 K bytes\n",
      "06/11/2023 03:06:18 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:18 PM INFO [WalrusDriver.0]: ru_maxrss:  849mb (delta=0mb)\n",
      "06/11/2023 03:06:18 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 10 memory location(s), 1 block(s), and 26 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$294 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:18 PM INFO 32742 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:19 PM INFO 32742 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1\n",
      "06/11/2023 03:06:19 PM INFO 32742 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:19 PM INFO 32742 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:19 PM INFO 32742 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:19 PM INFO 32742 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:19 PM INFO 32742 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:20 PM INFO 32742 [job.Frontend.4]: IR signature: 88651c212b3e50ec2ff160b47b05dc39959c12b50eb0255b777f867710d1e2ae for graph_def.pb\n",
      "06/11/2023 03:06:20 PM INFO 32742 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:20 PM INFO 32742 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:20 PM INFO 32742 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Version information:\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: \n",
      "06/11/2023 03:06:20 PM ERROR 32742 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$294; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/1/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/prim_Constant/Const:0\"]}' --verbose 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/ops/aten.py:2387: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$295 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:21 PM INFO 349 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:21 PM INFO 349 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18\n",
      "06/11/2023 03:06:21 PM INFO 349 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:21 PM INFO 349 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:21 PM INFO 349 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:21 PM INFO 349 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:21 PM INFO 349 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}'\n",
      "06/11/2023 03:06:23 PM INFO 349 [job.Frontend.4]: IR signature: 77a476764cbe14613a47b7e3e4a65c998f5b897b53c0bbd9cef03c9f058050fa for graph_def.pb\n",
      "06/11/2023 03:06:23 PM INFO 349 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:23 PM INFO 349 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:23 PM INFO 349 [job.Frontend.4]: Start tensorization\n",
      "[15:06:23] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:23] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:23] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:23] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:23 PM INFO 349 [job.Frontend.4]: IR signature: bc8aae3231c2fd8794282cbc1d3fe71f516e14c632eac01bc1c2af1dad0efdfa for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:23 PM INFO 349 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:23 PM INFO 349 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:23 PM INFO 349 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:23 PM INFO 349 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:23 PM INFO 349 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:24 PM INFO 349 [root/Tensorizer/All]: Exit time region: delta=1.125s\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: IR signature: 5605ec0acd2b0dee4e91250df38f0a005746d57a0187ad4aeedf9f4dea999a26 for cpu.so\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:24 PM WARNING 349 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:24 PM WARNING 349 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:24 PM INFO 349 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/graph_def.neff\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:24 PM INFO 349 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:24 PM INFO 349 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:24 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:24 2023\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/18/sg00\"\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: Virtual memory peak = 4358228 K bytes\n",
      "06/11/2023 03:06:24 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:24 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$296 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:25 PM INFO 479 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:25 PM INFO 479 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24\n",
      "06/11/2023 03:06:25 PM INFO 479 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:25 PM INFO 479 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:25 PM INFO 479 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:25 PM INFO 479 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:25 PM INFO 479 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:27 PM INFO 479 [job.Frontend.4]: IR signature: b89532fbde70fc7ec206b92d609f215834b9894ce26d55236cddda4c116bfe35 for graph_def.pb\n",
      "06/11/2023 03:06:27 PM INFO 479 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:27 PM INFO 479 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:27 PM INFO 479 [job.Frontend.4]: Start tensorization\n",
      "[15:06:27] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:27] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:27] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:27] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:27 PM INFO 479 [job.Frontend.4]: IR signature: e5a2388776ab2696bece6286a55e9524acab2dbf36152da8b531eff21de4d48f for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:27 PM INFO 479 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:27 PM INFO 479 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:27 PM INFO 479 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:27 PM INFO 479 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:27 PM INFO 479 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:27 PM INFO 479 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:27 PM INFO 479 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:27 PM INFO 479 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:28 PM INFO 479 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:28 PM INFO 479 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:28 PM INFO 479 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:28 PM INFO 479 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:28 PM INFO 479 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:28 PM INFO 479 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:28 PM INFO 479 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:28 PM INFO 479 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:28 PM INFO 479 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:28 PM INFO 479 [root/Tensorizer/All]: Exit time region: delta=1.075s\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: IR signature: 96764d0e72ca55fb1dfe7d954cd5639951a1e1c897f8c39d841f78e45a09d42d for cpu.so\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:28 PM WARNING 479 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:28 PM WARNING 479 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:28 PM INFO 479 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/graph_def.neff\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:28 PM INFO 479 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:28 PM INFO 479 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:28 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:28 2023\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/24/sg00\"\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: Virtual memory peak = 4358232 K bytes\n",
      "06/11/2023 03:06:28 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:28 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$297 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:29 PM INFO 610 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:29 PM INFO 610 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30\n",
      "06/11/2023 03:06:29 PM INFO 610 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:29 PM INFO 610 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:29 PM INFO 610 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:29 PM INFO 610 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:29 PM INFO 610 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:31 PM INFO 610 [job.Frontend.4]: IR signature: 26055eb3319fc5dc0b2fbc1ba3cc76f772dafbe6373841d6ad4d2b440ca85d8a for graph_def.pb\n",
      "06/11/2023 03:06:31 PM INFO 610 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:31 PM INFO 610 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:31 PM INFO 610 [job.Frontend.4]: Start tensorization\n",
      "[15:06:31] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:31] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:31] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:31] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:31 PM INFO 610 [job.Frontend.4]: IR signature: 55a583f6a4063f5b1d12bd410999d85cf92fb2c891f396b2c47e2bc6f917e29b for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:31 PM INFO 610 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:31 PM INFO 610 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:31 PM INFO 610 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:31 PM INFO 610 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:31 PM INFO 610 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:31 PM INFO 610 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:31 PM INFO 610 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:31 PM INFO 610 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:31 PM INFO 610 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:32 PM INFO 610 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:32 PM INFO 610 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:32 PM INFO 610 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:32 PM INFO 610 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:32 PM INFO 610 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:32 PM INFO 610 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:32 PM INFO 610 [root/Tensorizer/All]: Exit time region: delta=1.200s\n",
      "06/11/2023 03:06:32 PM INFO 610 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: IR signature: da4a645043934b613b6d86c605bac7798db5e08aea0a792e9324fca05a5ee447 for cpu.so\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:33 PM WARNING 610 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:33 PM WARNING 610 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:33 PM INFO 610 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/graph_def.neff\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:33 PM INFO 610 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:33 PM INFO 610 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:33 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:33 2023\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/30/sg00\"\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: Virtual memory peak = 4358224 K bytes\n",
      "06/11/2023 03:06:33 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: ru_maxrss:  881mb (delta=0mb)\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$298 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:33 PM INFO 742 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:34 PM INFO 742 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36\n",
      "06/11/2023 03:06:34 PM INFO 742 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:34 PM INFO 742 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:34 PM INFO 742 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:34 PM INFO 742 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:34 PM INFO 742 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:35 PM INFO 742 [job.Frontend.4]: IR signature: cbd452d674009dadbdecb7a2302875d2e367f9c2a8b744ebb0b5ea4fd0708019 for graph_def.pb\n",
      "06/11/2023 03:06:35 PM INFO 742 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:35 PM INFO 742 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:35 PM INFO 742 [job.Frontend.4]: Start tensorization\n",
      "[15:06:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:36 PM INFO 742 [job.Frontend.4]: IR signature: 4eb63743b0129ecc9a19bfedc3254f7779b364443d53ddc4fb7f4c4fe7a4906e for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:36 PM INFO 742 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:36 PM INFO 742 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:36 PM INFO 742 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:36 PM INFO 742 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:36 PM INFO 742 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:37 PM INFO 742 [root/Tensorizer/All]: Exit time region: delta=1.161s\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: IR signature: a3e95e8eda06bd9f84a0b59e827d0ad7d8fa37da9ca5d422d62651f01ab8ac2f for cpu.so\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:37 PM WARNING 742 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:37 PM WARNING 742 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:37 PM INFO 742 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/graph_def.neff\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:37 PM INFO 742 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:37 PM INFO 742 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:37 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:37 2023\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/36/sg00\"\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: Virtual memory peak = 4358236 K bytes\n",
      "06/11/2023 03:06:37 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:37 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$299 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:38 PM INFO 877 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:38 PM INFO 877 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42\n",
      "06/11/2023 03:06:38 PM INFO 877 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:38 PM INFO 877 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:38 PM INFO 877 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:38 PM INFO 877 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:38 PM INFO 877 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}'\n",
      "06/11/2023 03:06:40 PM INFO 877 [job.Frontend.4]: IR signature: 323337482352f8c8d5b2e6d0d50c06c4a073f577ff6388a81a950542db9cf6ca for graph_def.pb\n",
      "06/11/2023 03:06:40 PM INFO 877 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:40 PM INFO 877 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:40 PM INFO 877 [job.Frontend.4]: Start tensorization\n",
      "[15:06:40] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:40] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:40] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:40] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:40 PM INFO 877 [job.Frontend.4]: IR signature: 0be308e9aa6bac0242314947930b857836d39f9ff1516ee016a8275ee32db3ad for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:40 PM INFO 877 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.012s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.015s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.024s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:40 PM INFO 877 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:40 PM INFO 877 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:40 PM INFO 877 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:40 PM INFO 877 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:41 PM INFO 877 [root/Tensorizer/All]: Exit time region: delta=1.185s\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: IR signature: 7fd15593e85197944ab1e44017b559a383c19b4adb586ced465d7b1f86e33a8c for cpu.so\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:41 PM WARNING 877 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:41 PM WARNING 877 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:41 PM INFO 877 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/graph_def.neff\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:41 PM INFO 877 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:41 PM INFO 877 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:41 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:41 2023\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/42/sg00\"\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: Virtual memory peak = 4358232 K bytes\n",
      "06/11/2023 03:06:41 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:41 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$300 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:42 PM INFO 1009 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:42 PM INFO 1009 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48\n",
      "06/11/2023 03:06:42 PM INFO 1009 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:42 PM INFO 1009 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:42 PM INFO 1009 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:42 PM INFO 1009 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:42 PM INFO 1009 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:44 PM INFO 1009 [job.Frontend.4]: IR signature: 556c168322eafdd5fd2e69a6df81c260e35b1c4d660e54cf080f36dd1521e93c for graph_def.pb\n",
      "06/11/2023 03:06:44 PM INFO 1009 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:44 PM INFO 1009 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:44 PM INFO 1009 [job.Frontend.4]: Start tensorization\n",
      "[15:06:44] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:44] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:44] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:44] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:44 PM INFO 1009 [job.Frontend.4]: IR signature: bf327453e916dbf076bf284d90929567c1f91e318e43b86df33e449dba0787cf for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:44 PM INFO 1009 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:44 PM INFO 1009 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:44 PM INFO 1009 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:44 PM INFO 1009 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:45 PM INFO 1009 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:45 PM INFO 1009 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:45 PM INFO 1009 [root/Tensorizer/All]: Exit time region: delta=1.213s\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: IR signature: 6f8d5eb176e078f75ce54c9503d869f93abc063c4dc8f642c4a23d70a8539d2b for cpu.so\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:45 PM WARNING 1009 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:45 PM WARNING 1009 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:45 PM INFO 1009 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/graph_def.neff\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:45 PM INFO 1009 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:46 PM INFO 1009 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:46 PM INFO 1009 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:45 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:45 2023\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/48/sg00\"\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: Virtual memory peak = 4358232 K bytes\n",
      "06/11/2023 03:06:45 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:45 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$301 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:46 PM INFO 1142 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:47 PM INFO 1142 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54\n",
      "06/11/2023 03:06:47 PM INFO 1142 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:47 PM INFO 1142 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:47 PM INFO 1142 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:47 PM INFO 1142 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:47 PM INFO 1142 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\"]}'\n",
      "06/11/2023 03:06:48 PM INFO 1142 [job.Frontend.4]: IR signature: 93a5ead0cb83cd28421fbb58331a4bf424025dfcb6bb0ec3f7b55c22c2026d30 for graph_def.pb\n",
      "06/11/2023 03:06:48 PM INFO 1142 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:48 PM INFO 1142 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:48 PM INFO 1142 [job.Frontend.4]: Start tensorization\n",
      "[15:06:48] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:06:48] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:06:48] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           2\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:06:48] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "        cpu0:cpu  copy12:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:06:48 PM INFO 1142 [job.Frontend.4]: IR signature: b22357f215ca913bf12ce41989934ecbf86d5388d17b46281f2465b9967a2fed for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:06:48 PM INFO 1142 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:06:48 PM INFO 1142 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [MutateDataType]: Finished (changed=True #instances=15360)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:48 PM INFO 1142 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:48 PM INFO 1142 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LoopFusion]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DelinearIndices]: Finished (changed=True #instances=6144)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ResolveAccessConflict]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TransformLayout]: Finished (changed=True #instances=12288)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DataLocalityOpt]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.027s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [InferInitValue]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.014s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SimplifyTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaISel]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaLoopFusion]: Finished (changed=True #instances=84)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaInstComb]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [PartialLoopFusion]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizeTongaType]: Finished (changed=True #instances=72)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LowerPartitionTile]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LinearizeFreeDim]: Finished (changed=True #instances=120)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [ILPOpt]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LowerAPIndices]: Finished (changed=True #instances=32)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:06:49 PM INFO 1142 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Tensorizer]: IR signature: 0bcf05cf4594984abeec971f31103e8ee3d1311f4c144d79ae2305c88d369277 for sg00/Tensorizer\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Tensorizer]: Finalize\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                4  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                3  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                3  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                5  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:            49152  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:            18432  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:            18432  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                6  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:               80  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:06:49 PM INFO 1142 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:06:50 PM INFO 1142 [root/Tensorizer/All]: Exit time region: delta=1.123s\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: IR signature: a7bdcf8ad97a3125a832c70d8f39894a92be0e302edda79eaf9583311c6533f2 for cpu.so\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.WalrusDriver.3]: IR signature: e8dcf23fb56f85807fb17204658ea5b58a4101fdef9ddd89a9c12902fd6f65ff for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: IR signature: d433b862ba67f9bf6f64445a4903880babb3addc69659ed2c5f788b44fc15eb7 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: IR signature: 57c44f5ae59cbe085716084b396355238b1a6aa2484525071eaaaf8f6c427016 for sg00/def.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: IR signature: 43e9cf7f7dd69ccc9e64067907fbbe1ad7a47daf13209b1115b000124d04dd96 for sg00/pool.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:06:50 PM WARNING 1142 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:06:50 PM WARNING 1142 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:06:50 PM INFO 1142 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/graph_def.neff\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:06:50 PM INFO 1142 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:06:50 PM INFO 1142 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=4\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Total count: 32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Load: 12\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: TensorCopy: 6\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 12 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         size = 4\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         bit-matrix size = 1 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           SB high-water mark = 288 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             288 bytes in partitions [0, 31]\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             288 bytes in partitions [32, 63]\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             288 bytes in partitions [64, 95]\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             288 bytes in partitions [96, 127]\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         found 5 edges\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         adjacency vectors require 40 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:               safe = 4\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:              total = 4\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:06:50 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 18432, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 6144\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:06:50 2023\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=6 blocks=1 instructions=32\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/54/sg00\"\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 18432\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Loads in Func = 12\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Input Loads in Func= 12\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: Virtual memory peak = 4358228 K bytes\n",
      "06/11/2023 03:06:50 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:06:50 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 6 memory location(s), 1 block(s), and 32 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$302 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:51 PM INFO 1270 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:51 PM INFO 1270 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60\n",
      "06/11/2023 03:06:51 PM INFO 1270 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:51 PM INFO 1270 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:51 PM INFO 1270 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:51 PM INFO 1270 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:51 PM INFO 1270 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:06:52 PM INFO 1270 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:06:52 PM INFO 1270 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:52 PM INFO 1270 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:52 PM INFO 1270 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Version information:\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: \n",
      "06/11/2023 03:06:52 PM ERROR 1270 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$302; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/60/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$303 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:53 PM INFO 1344 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:53 PM INFO 1344 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68\n",
      "06/11/2023 03:06:53 PM INFO 1344 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:53 PM INFO 1344 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:53 PM INFO 1344 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:53 PM INFO 1344 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:53 PM INFO 1344 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}'\n",
      "06/11/2023 03:06:54 PM INFO 1344 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:06:54 PM INFO 1344 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:54 PM INFO 1344 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:54 PM INFO 1344 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Version information:\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: \n",
      "06/11/2023 03:06:54 PM ERROR 1344 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$303; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/68/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$304 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:55 PM INFO 1427 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:55 PM INFO 1427 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76\n",
      "06/11/2023 03:06:55 PM INFO 1427 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:55 PM INFO 1427 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:55 PM INFO 1427 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:55 PM INFO 1427 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:55 PM INFO 1427 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}'\n",
      "06/11/2023 03:06:56 PM INFO 1427 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:06:56 PM INFO 1427 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:56 PM INFO 1427 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:56 PM INFO 1427 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Version information:\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: \n",
      "06/11/2023 03:06:56 PM ERROR 1427 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$304; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/76/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$305 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:57 PM INFO 1501 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:57 PM INFO 1501 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80\n",
      "06/11/2023 03:06:57 PM INFO 1501 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:06:57 PM INFO 1501 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:06:57 PM INFO 1501 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:06:57 PM INFO 1501 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:06:57 PM INFO 1501 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}'\n",
      "06/11/2023 03:06:59 PM INFO 1501 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:06:59 PM INFO 1501 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:06:59 PM INFO 1501 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:06:59 PM INFO 1501 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Version information:\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: \n",
      "06/11/2023 03:06:59 PM ERROR 1501 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$305; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/80/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$306 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:06:59 PM INFO 1575 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:00 PM INFO 1575 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84\n",
      "06/11/2023 03:07:00 PM INFO 1575 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:00 PM INFO 1575 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:00 PM INFO 1575 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:00 PM INFO 1575 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:00 PM INFO 1575 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:01 PM INFO 1575 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:07:01 PM INFO 1575 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:01 PM INFO 1575 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:01 PM INFO 1575 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Version information:\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: \n",
      "06/11/2023 03:07:01 PM ERROR 1575 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$306; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/84/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$307 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.neff --io-config {\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:01 PM INFO 1649 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:02 PM INFO 1649 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92\n",
      "06/11/2023 03:07:02 PM INFO 1649 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:02 PM INFO 1649 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:02 PM INFO 1649 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:02 PM INFO 1649 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:02 PM INFO 1649 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:03 PM INFO 1649 [job.Frontend.4]: IR signature: ab875240dd5fb2be32ba8d257cbc116697d30fba7f99310b78527f4dca000680 for graph_def.pb\n",
      "06/11/2023 03:07:03 PM INFO 1649 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:03 PM INFO 1649 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:03 PM INFO 1649 [job.Frontend.4]: Start tensorization\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Error message:  \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 747, in build_graph\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     func = ir_pass.add_copy_to_primary_outputs(func, tensor_names)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2078, in add_copy_to_primary_outputs\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     return name_collector.visit(expr)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 27, in visit\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     res = self.visit_function(expr)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 120, in visit_function\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     new_body = self.visit(fn.body)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/expr_functor.py\", line 43, in visit\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     res = self.visit_constant(expr)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 2065, in visit_constant\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:     assert len(self.output_tensor_names)\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Version information:\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: \n",
      "06/11/2023 03:07:03 PM ERROR 1649 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$307; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/92/graph_def.neff --io-config '{\"inputs\": {}, \"outputs\": [\"prim_Constant/Const:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$308 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"], \"tensor.15:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_add/add:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:04 PM INFO 1726 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"], \"tensor.15:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_add/add:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:04 PM INFO 1726 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100\n",
      "06/11/2023 03:07:04 PM INFO 1726 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:04 PM INFO 1726 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:04 PM INFO 1726 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:04 PM INFO 1726 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:04 PM INFO 1726 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512, 7], \"int64\"], \"tensor.15:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_add/add:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:06 PM INFO 1726 [job.Frontend.4]: IR signature: 25995ee5c2ecbbd4d168072a3833d256ee38f68c2876c929d0dc16f61cc259d5 for graph_def.pb\n",
      "06/11/2023 03:07:06 PM INFO 1726 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:06 PM INFO 1726 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:06 PM INFO 1726 [job.Frontend.4]: Start tensorization\n",
      "[15:07:06] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:06] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=97\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:06] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        97           0         0         0           8\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:06] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_1/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_mul/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select/Slice:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_select_1/Reshape:0\n",
      "        cpu0:cpu  TapasModel_7/TapasEmbeddings_27/aten_select_1/Slice:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  add0:0\n",
      "        cpu0:cpu  copy24:0\n",
      "        cpu0:cpu  copy25:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice10:0\n",
      "        cpu0:cpu  strided_slice11:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice2:0\n",
      "        cpu0:cpu  strided_slice3:0\n",
      "        cpu0:cpu  strided_slice4:0\n",
      "        cpu0:cpu  strided_slice5:0\n",
      "        cpu0:cpu  strided_slice6:0\n",
      "        cpu0:cpu  strided_slice7:0\n",
      "        cpu0:cpu  strided_slice8:0\n",
      "        cpu0:cpu  strided_slice9:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:06 PM INFO 1726 [job.Frontend.4]: IR signature: 206d560ae63fe2c950e0e0ede3503325b445cab37d8b0b392bbbc659f747c63a for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:06 PM INFO 1726 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:06 PM INFO 1726 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:06 PM INFO 1726 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:06 PM INFO 1726 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:06 PM INFO 1726 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:06 PM INFO 1726 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Statistics]: Weights total number of bytes: 12296\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Statistics]: RelayIF total number of bytes: 24576.0\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Statistics]: RelayOF total number of bytes: 24576.0\n",
      "06/11/2023 03:07:06 PM INFO 1726 [Statistics]: Weights total number of bytes: 12296.0\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [MutateDataType]: Finished (changed=True #instances=55296)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=True #instances=53760)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LoopFusion]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.013s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DelinearIndices]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ResolveAccessConflict]: Finished (changed=True #instances=30720)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TransformLayout]: Finished (changed=True #instances=30720)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaSizeTiling]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.016s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [InferTongaTensor]: Finished (changed=True #instances=60)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DataLocalityOpt]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.067s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FlattenMacroLoop]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [RewriteWeights]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ReshapeWeights]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [InferInitValue]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.030s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SimplifyTongaTensor]: Finished (changed=True #instances=109)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaISel]: Finished (changed=True #instances=181)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaLoopFusion]: Finished (changed=True #instances=181)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaInstComb]: Finished (changed=True #instances=181)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.021s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizeTongaType]: Finished (changed=True #instances=193)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [PartialLoopFusion]: Finished (changed=True #instances=193)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.046s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizeTongaType]: Finished (changed=True #instances=193)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LowerPartitionTile]: Finished (changed=True #instances=337)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.015s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LinearizeFreeDim]: Finished (changed=True #instances=337)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [ILPOpt]: Finished (changed=True #instances=117)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.092s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LowerAPIndices]: Finished (changed=True #instances=117)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.015s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:07 PM INFO 1726 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Tensorizer]: IR signature: ceb3bed73548a3c7eaeb9d6b02fabeab80a88e211bf0d867cb58def13f20582f for sg00/Tensorizer\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Tensorizer]: Weights total number of bytes: 6144\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:             6144  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                1  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                3  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                9  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                4  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:            49152  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               48  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               12  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               10  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                7  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                8  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           184328  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                3  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                3  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           0.1786  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           0.1389  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           0.1562  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           0.1786  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           0.2083  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           6.8571  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:             7680  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:             4608  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:             3072  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:            43008  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:             6144  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               48  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:            43008  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               49  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               48  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               14  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:              215  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:         128.5714  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:         128.5714  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               60  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                2  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:               16  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:            12288  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:07 PM INFO 1726 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:08 PM INFO 1726 [root/Tensorizer/All]: Exit time region: delta=1.465s\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: INFO: NN has cpu nodes, writing cpu.so\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: IR signature: c0d83bcecc4fb2f7b213b953cdb335b0ee44915db8851917bd567e5ef8789b4c for cpu.so\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for cpu.params\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.WalrusDriver.3]: IR signature: a4b1cd8fd268be95191102734e3951c191c924e87caec6ac7949ff90ba68e7de for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: IR signature: 9b0df812db6539c7ff8104e5639c65f917e995120478819cb8917bd804a75eb6 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: IR signature: d713bb4d255334b8677c9296bb3b4b7b968b9bdfe8e23bc1ab0d3fc365870276 for sg00/def.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: IR signature: 131ca2d96d3c020838a9e071c8a82f3273390aa612a3555c71389cc60a97eef1 for sg00/pool.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=16 blocks=1 instructions=11\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Total count: 117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: TensorScalarPtr: 48\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Load: 25\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Save: 24\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: TensorCopy: 14\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: TensorScalar: 6\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 25 loads, 24 saves, 0 copies.\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 43008\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         size = 13\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 48 bytes/partition\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         bit-matrix size = 11 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           SB high-water mark = 528 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             528 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             528 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             528 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             528 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         found 37 edges\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         adjacency vectors require 296 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:               safe = 13\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:              total = 13\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: 48 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: pinning saved approximately 1114 cycles\n",
      "06/11/2023 03:07:08 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 43008, 42.8571% input load, 57.1429% output write, 0% spill/reload \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 43008, 42.8571% input load, 57.1429% output write, 0% spill/reload \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 18432\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 5 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 24576\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 18432\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 5 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 24576\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:08 2023\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=18 blocks=1 instructions=117\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/sg00\"\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 43008\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Loads in Func = 25\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Saves in Func = 24\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Input Loads in Func= 25\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Output Saves in Func= 24\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Transitive reduction removed 1 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: Virtual memory peak = 4363696 K bytes\n",
      "06/11/2023 03:07:08 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:08 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 18 memory location(s), 1 block(s), and 117 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:08 PM WARNING 1726 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:08 PM WARNING 1726 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:08 PM INFO 1726 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/100/graph_def.neff\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:08 PM INFO 1726 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:08 PM INFO 1726 [root]: Compiler status PASS\n",
      "INFO:Neuron:Compiling function _NeuronGraph$309 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[196608], \"int64\"], \"1:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_view/Reshape:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:09 PM INFO 1873 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[196608], \"int64\"], \"1:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_view/Reshape:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:09 PM INFO 1873 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102\n",
      "06/11/2023 03:07:09 PM INFO 1873 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:09 PM INFO 1873 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:09 PM INFO 1873 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:09 PM INFO 1873 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:09 PM INFO 1873 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[196608], \"int64\"], \"1:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_view/Reshape:0\", \"TapasModel_7/TapasEmbeddings_27/aten_view_1/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:11 PM INFO 1873 [job.Frontend.4]: IR signature: 4cd4b7f63c00269e46af72e38fcc86e4f501fd1e1b469546acb659e65120ad33 for graph_def.pb\n",
      "06/11/2023 03:07:11 PM INFO 1873 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:11 PM INFO 1873 [job.Frontend.4]: Start tensorization\n",
      "[15:07:11] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:11] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=0\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:11] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         0           0         0         0           4\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:11] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_view/Reshape:0\n",
      "     tonga0:tpb0  copy0:0\n",
      "     tonga0:tpb0  copy1:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:11 PM INFO 1873 [job.Frontend.4]: IR signature: 8716f530fa77b65efaeeb1f2791e1625ebf288effb9a762b0c834b1f03078d61 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:11 PM INFO 1873 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]: Weights total number of bytes: 0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]: RelayIF total number of bytes: 1585152.0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]: RelayOF total number of bytes: 1585152.0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]: Weights total number of bytes: 0.0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [MutateDataType]: Finished (changed=True #instances=2368512)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LoopFusion]: Finished (changed=True #instances=1185792)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DelinearIndices]: Finished (changed=True #instances=1185792)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.012s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LoopFusion]: Finished (changed=True #instances=792576)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ResolveAccessConflict]: Finished (changed=True #instances=1585152)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TransformLayout]: Finished (changed=True #instances=1585152)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaSizeTiling]: Finished (changed=True #instances=4644)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.016s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [InferTongaTensor]: Finished (changed=True #instances=4644)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DataLocalityOpt]: Finished (changed=True #instances=7740)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.054s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [RewriteWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ReshapeWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [InferInitValue]: Finished (changed=True #instances=7740)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.028s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SimplifyTongaTensor]: Finished (changed=True #instances=7740)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaISel]: Finished (changed=True #instances=10836)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaLoopFusion]: Finished (changed=True #instances=10836)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.016s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaInstComb]: Finished (changed=True #instances=9288)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.021s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizeTongaType]: Finished (changed=True #instances=9288)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [PartialLoopFusion]: Finished (changed=True #instances=9288)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.034s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizeTongaType]: Finished (changed=True #instances=9288)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LowerPartitionTile]: Finished (changed=True #instances=15480)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LinearizeFreeDim]: Finished (changed=True #instances=15480)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [ILPOpt]: Finished (changed=True #instances=3872)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.045s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LowerAPIndices]: Finished (changed=True #instances=3872)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:11 PM INFO 1873 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: IR signature: 35b09bc12faab467098638c70b88d2838d11c6cb2a69e3815b1c138663902206 for sg00/Tensorizer\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Weights total number of bytes: 0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:               15  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                4  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:          3170304  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                5  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                6  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                3  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                9  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                8  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:          7888896  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           0.0625  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           0.0833  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:              128  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           198144  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:           198144  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:          2377728  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:          2377728  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:             3096  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:             3096  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:              582  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:            10064  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:         133.3333  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:             4644  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                4  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                2  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                9  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:11 PM INFO 1873 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:12 PM INFO 1873 [root/Tensorizer/All]: Exit time region: delta=1.380s\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:12 PM INFO 1873 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:12 PM INFO 1873 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:12 PM INFO 1873 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:12 PM INFO 1873 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:12 PM INFO 1873 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=10 blocks=1 instructions=5\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Total count: 3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Save: 1548\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Load: 1548\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: TensorCopy: 582\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: TensorScalar: 194\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0.001 seconds\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0.001 seconds\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 1548 loads, 1548 saves, 0 copies.\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:12 2023\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 2377728\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 6 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         size = 388\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         0 pin count\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         bit-matrix size = 9409 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: 12% SB demand before allocation\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           SB high-water mark = 12544 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             12544 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             12544 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             12544 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             12544 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         found 18725 edges\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         adjacency vectors require 149800 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:               safe = 388\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:              total = 388\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: 0 bytes/partition (0%) successfully pinned\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: pinning saved approximately 0 cycles\n",
      "06/11/2023 03:07:12 PM WARNING [WalrusDriver.0]: 12% SB utilization after allocation\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 2377728, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 2377728, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 792576\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 4 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 1585152\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 792576\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 4 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 1585152\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:12 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:13 2023\n",
      "06/11/2023 03:07:13 PM WARNING [TheScheduler.0]: Warning 2: scheduling level for block downgraded to 1.\n",
      "06/11/2023 03:07:13 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:13 2023\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:13 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=392 blocks=1 instructions=3872\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/sg00\"\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 2377728\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 6 bytes\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Loads in Func = 1548\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Saves in Func = 1548\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Input Loads in Func= 1548\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Output Saves in Func= 1548\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Transitive reduction removed 2 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:13 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:14 PM INFO [Stargazer.0]: Virtual memory peak = 4390720 K bytes\n",
      "06/11/2023 03:07:14 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:14 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:14 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:14 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 392 memory location(s), 1 block(s), and 3872 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:14 PM INFO 1873 [job.WalrusDriver.3]: IR signature: 8d028021dc438232e84a544fcb9dfb70718ec7f96cacb52227c22bdcc522c7c5 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: IR signature: d3e22f255d64f61ffe33bd3120563e42813212320cf53dd03be5769db436d39e for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: IR signature: cbe142473098e8f92fdcbd54c7f6067fecd6b35ddb202d4ea6edca2ed56071f8 for sg00/def.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: IR signature: a477e2f1d5e95260b8c9d59fb10ea370a187dbaee9d0391baf3922ac1898fe3f for sg00/pool.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:14 PM WARNING 1873 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:14 PM WARNING 1873 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:14 PM INFO 1873 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/102/graph_def.neff\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:14 PM INFO 1873 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:14 PM INFO 1873 [root]: Compiler status PASS\n",
      "INFO:Neuron:Compiling function _NeuronGraph$310 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[], \"int64\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_min/Minimum:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:15 PM INFO 2087 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[], \"int64\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_min/Minimum:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:15 PM INFO 2087 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104\n",
      "06/11/2023 03:07:15 PM INFO 2087 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:15 PM INFO 2087 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:15 PM INFO 2087 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:15 PM INFO 2087 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:15 PM INFO 2087 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"tensor.1:0\": [[], \"int64\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasEmbeddings_27/aten_min/Minimum:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:17 PM INFO 2087 [job.Frontend.4]: IR signature: 11734f48b98a3fcb4746e1f4103c52bdaf547d729d509293d893e11431653f1b for graph_def.pb\n",
      "06/11/2023 03:07:17 PM INFO 2087 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:17 PM INFO 2087 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:17 PM INFO 2087 [job.Frontend.4]: Start tensorization\n",
      "[15:07:17] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:17] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=98\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:17] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        98           0         0         0           5\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:17] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_min/Minimum:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_sub/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_sub/sub:0\n",
      "     tonga0:tpb0  copy3:0\n",
      "     tonga0:tpb0  minimum0:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:17 PM INFO 2087 [job.Frontend.4]: IR signature: 7ed3e1e242f4ac8fc7a024387d64588765dbffe75304cab769ba5f01f47d7314 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:17 PM INFO 2087 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:17 PM INFO 2087 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Statistics]: Weights total number of bytes: 12304\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Statistics]: RelayIF total number of bytes: 12288.0\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Statistics]: RelayOF total number of bytes: 12288.0\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Statistics]: Weights total number of bytes: 12304.0\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [MutateDataType]: Finished (changed=True #instances=30720)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=True #instances=26112)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LoopFusion]: Finished (changed=True #instances=10752)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DelinearIndices]: Finished (changed=True #instances=10752)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [AutoCastFP32]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ResolveAccessConflict]: Finished (changed=True #instances=16896)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TransformLayout]: Finished (changed=True #instances=16896)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaSizeTiling]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [InferTongaTensor]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DataLocalityOpt]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.041s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FlattenMacroLoop]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [RewriteWeights]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ReshapeWeights]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [InferInitValue]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SimplifyTongaTensor]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaISel]: Finished (changed=True #instances=97)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaLoopFusion]: Finished (changed=True #instances=97)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaInstComb]: Finished (changed=True #instances=86)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.012s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LowerTranspose]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizeTongaType]: Finished (changed=True #instances=87)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [PartialLoopFusion]: Finished (changed=True #instances=87)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.020s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizeTongaType]: Finished (changed=True #instances=87)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LowerPartitionTile]: Finished (changed=True #instances=149)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [LinearizeFreeDim]: Finished (changed=True #instances=149)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [ILPOpt]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.033s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:17 PM INFO 2087 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:17 PM INFO 2087 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:18 PM INFO 2087 [LowerAPIndices]: Finished (changed=True #instances=61)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:18 PM INFO 2087 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:18 PM INFO 2087 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:18 PM INFO 2087 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:18 PM INFO 2087 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Tensorizer]: IR signature: c8ea2edfb18cedf289b4c922a9c8759390c6592a63619ddee0db34dc898201a0 for sg00/Tensorizer\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Tensorizer]: Weights total number of bytes: 6144\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:             6144  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                5  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:            24576  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                4  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                4  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                5  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                6  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                6  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                4  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:            86032  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                2  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           0.1875  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           0.1500  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           0.1875  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           0.1875  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           0.2500  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           7.6800  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:           6.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:         100.0000  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:               96  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:             4608  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:             1536  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:             3072  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:            18944  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:             6144  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:               48  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:            24576  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:               25  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:               24  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                8  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:              109  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:         125.0000  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:         125.0000  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:               36  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                6  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:            12288  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:18 PM INFO 2087 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:18 PM INFO 2087 [root/Tensorizer/All]: Exit time region: delta=1.230s\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.WalrusDriver.3]: IR signature: 0b0507ac9b5712cdd9292e689d9c4d0b6027a1dc6cff19e32b38dcd2b193f9b3 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: IR signature: 24ef55c3029cf1699ddf9e4160666713e8a070075c518cf13c2d3de65b21357b for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: IR signature: 383b6d4250c41b7ee59649da1b8b88d11a5321959725d283c84155e5cfae71b9 for sg00/def.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: IR signature: adb39a73be92d940f06f1239225ea09616fdcd2c66a74f5d9c751ae396749d2b for sg00/pool.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:18 PM WARNING 2087 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:18 PM WARNING 2087 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:18 PM INFO 2087 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/graph_def.neff\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:18 PM INFO 2087 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:18 PM INFO 2087 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=10 blocks=1 instructions=6\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Total count: 61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: TensorScalarPtr: 24\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Load: 13\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Save: 12\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: TensorCopy: 8\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: TensorScalar: 2\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Memset: 2\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 13 loads, 12 saves, 0 copies.\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 24576\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 7 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         size = 19\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 48 bytes/partition\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         bit-matrix size = 23 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: 0% SB demand before allocation\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           SB high-water mark = 336 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             336 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             336 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             336 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             336 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         found 127 edges\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         adjacency vectors require 1016 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:               safe = 19\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:              total = 19\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: 48 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: pinning saved approximately 1114 cycles\n",
      "06/11/2023 03:07:18 PM WARNING [WalrusDriver.0]: 0% SB utilization after allocation\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 24576, 50% input load, 50% output write, 0% spill/reload \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 24576, 50% input load, 50% output write, 0% spill/reload \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 7 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 12288\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 7 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 12288\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 8 bytes\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:18 2023\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=22 blocks=1 instructions=61\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/104/sg00\"\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 24576\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 7 bytes\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Loads in Func = 13\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Saves in Func = 12\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Input Loads in Func= 13\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Output Saves in Func= 12\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: Virtual memory peak = 4356696 K bytes\n",
      "06/11/2023 03:07:18 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: ru_maxrss:  882mb (delta=0mb)\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:18 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 22 memory location(s), 1 block(s), and 61 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$311 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.neff --io-config {\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:20 PM INFO 2246 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:21 PM INFO 2246 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106\n",
      "06/11/2023 03:07:21 PM INFO 2246 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:21 PM INFO 2246 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:21 PM INFO 2246 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:21 PM INFO 2246 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:21 PM INFO 2246 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106\", \"state_id\": \"root\"}' --pipeline Frontend --framework TENSORFLOW --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]}'\n",
      "06/11/2023 03:07:24 PM INFO 2246 [job.Frontend.4]: IR signature: 7f6ee6688d2d840a485db1a77c1278c9b9b4c26ea4c0acbc1767e788f85c9c86 for graph_def.pb\n",
      "06/11/2023 03:07:24 PM INFO 2246 [job.Frontend.4]: total padded opcount is 6444417024\n",
      "06/11/2023 03:07:24 PM INFO 2246 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:24 PM INFO 2246 [job.Frontend.4]: Start tensorization\n",
      "[15:07:26] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:26] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=3222208512\n",
      "Coloring: Total const bytes per part=51423\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:26] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 3,222,208,512. Average number of cycles per partition: 3,222,208,512\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0   3,222,208,512    50,822           0         0         3         383\n",
      "Coloring: Total nubmer of cycles = 3,222,208,512\n",
      "Coloring: Largest number of cycles in part = 3,222,208,512, Ratio worst/best avg = 1\n",
      "\n",
      "\n",
      "\n",
      "[15:07:26] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/LayerNorm_306/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_1/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_2/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_3/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_4/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_5/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_6/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEmbeddings_27/aten_add_7/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_10/TapasOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_11/TapasOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_8/TapasOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_24/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_4/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/Linear_5/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_div/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_matmul_1/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_1/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_2/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_permute_3/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_softmax/Softmax:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_transpose/transpose:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfAttention_2/aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasAttention_3/TapasSelfOutput_3/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/Linear_1/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/Erf:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasIntermediate_4/aten_gelu/truediv:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/Rsqrt:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/add_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_1:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/mul_2:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/batchnorm/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/SquaredDifference:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/StopGradient:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/mean:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/LayerNorm_7/aten_layer_norm/moments/variance:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/Linear_3/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasEncoder_28/TapasLayer_9/TapasOutput_5/aten_add/add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasPooler_29/Linear_10/aten_linear/Add:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasPooler_29/Linear_10/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasPooler_29/aten_select/Reshape:0\n",
      "     tonga0:tpb0  TapasModel_7/TapasPooler_29/aten_select/Slice:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_mul/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_rsub/mul:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_rsub/sub:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_to/Cast:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_unsqueeze/ExpandDims:0\n",
      "     tonga0:tpb0  TapasModel_7/aten_unsqueeze_1/ExpandDims:0\n",
      "     tonga0:tpb0  add0:0\n",
      "     tonga0:tpb0  aten_add/add:0\n",
      "     tonga0:tpb0  aten_add_1/add:0\n",
      "     tonga0:tpb0  aten_add_2/add:0\n",
      "     tonga0:tpb0  aten_add_3/add:0\n",
      "     tonga0:tpb0  aten_add_4/add:0\n",
      "     tonga0:tpb0  aten_add_5/add:0\n",
      "     tonga0:tpb0  aten_add_6/add:0\n",
      "     tonga0:tpb0  aten_div/truediv:0\n",
      "     tonga0:tpb0  aten_einsum/einsum/MatMul:0\n",
      "     tonga0:tpb0  aten_einsum/einsum/Reshape:0\n",
      "     tonga0:tpb0  aten_einsum/einsum/Reshape_2:0\n",
      "     tonga0:tpb0  aten_einsum_1/einsum/MatMul:0\n",
      "     tonga0:tpb0  aten_einsum_1/einsum/Reshape:0\n",
      "     tonga0:tpb0  aten_einsum_1/einsum/Reshape_2:0\n",
      "     tonga0:tpb0  aten_expand/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand/Cast:0\n",
      "     tonga0:tpb0  aten_expand/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_1/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_1/Cast:0\n",
      "     tonga0:tpb0  aten_expand_1/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_2/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_2/Cast:0\n",
      "     tonga0:tpb0  aten_expand_2/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_3/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_3/Cast:0\n",
      "     tonga0:tpb0  aten_expand_3/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_4/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_4/Cast:0\n",
      "        cpu0:cpu  aten_expand_4/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_5/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_5/Cast:0\n",
      "     tonga0:tpb0  aten_min/Minimum:0\n",
      "     tonga0:tpb0  aten_min_1/Minimum:0\n",
      "     tonga0:tpb0  aten_mul/mul:0\n",
      "        cpu0:cpu  aten_ones/ones:0\n",
      "        cpu0:cpu  aten_ones_1/ones:0\n",
      "     tonga0:tpb0  aten_reshape/Reshape:0\n",
      "     tonga0:tpb0  aten_reshape_1/Reshape:0\n",
      "     tonga0:tpb0  aten_reshape_2/Reshape:0\n",
      "     tonga0:tpb0  aten_select/Reshape:0\n",
      "        cpu0:cpu  aten_select/Slice:0\n",
      "     tonga0:tpb0  aten_select_1/Reshape:0\n",
      "        cpu0:cpu  aten_select_1/Slice:0\n",
      "     tonga0:tpb0  aten_to_18/Cast:0\n",
      "        cpu0:cpu  aten_to_5/Const:0\n",
      "     tonga0:tpb0  aten_to_8/Cast:0\n",
      "     tonga0:tpb0  aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  aten_view_6/Reshape:0\n",
      "        cpu0:cpu  aten_zeros/zeros:0\n",
      "     tonga0:tpb0  aten_zeros_1/zeros:0\n",
      "     tonga0:tpb0  aten_zeros_2/zeros:0\n",
      "     tonga0:tpb0  cast0:0\n",
      "     tonga0:tpb0  cast1:0\n",
      "     tonga0:tpb0  cast2:0\n",
      "     tonga0:tpb0  cast3:0\n",
      "     tonga0:tpb0  cast4:0\n",
      "     tonga0:tpb0  cast5:0\n",
      "        cpu0:cpu  copy42:0\n",
      "        cpu0:cpu  copy43:0\n",
      "        cpu0:cpu  copy44:0\n",
      "        cpu0:cpu  copy45:0\n",
      "        cpu0:cpu  copy46:0\n",
      "        cpu0:cpu  copy47:0\n",
      "        cpu0:cpu  copy48:0\n",
      "        cpu0:cpu  copy49:0\n",
      "        cpu0:cpu  copy50:0\n",
      "        cpu0:cpu  copy51:0\n",
      "        cpu0:cpu  copy52:0\n",
      "        cpu0:cpu  copy53:0\n",
      "        cpu0:cpu  copy54:0\n",
      "     tonga0:tpb0  nn.batch_matmul0:0\n",
      "     tonga0:tpb0  nn.batch_matmul10:0\n",
      "     tonga0:tpb0  nn.batch_matmul11:0\n",
      "     tonga0:tpb0  nn.batch_matmul12:0\n",
      "     tonga0:tpb0  nn.batch_matmul13:0\n",
      "     tonga0:tpb0  nn.batch_matmul14:0\n",
      "     tonga0:tpb0  nn.batch_matmul15:0\n",
      "     tonga0:tpb0  nn.batch_matmul16:0\n",
      "     tonga0:tpb0  nn.batch_matmul17:0\n",
      "     tonga0:tpb0  nn.batch_matmul18:0\n",
      "     tonga0:tpb0  nn.batch_matmul19:0\n",
      "     tonga0:tpb0  nn.batch_matmul1:0\n",
      "     tonga0:tpb0  nn.batch_matmul20:0\n",
      "     tonga0:tpb0  nn.batch_matmul21:0\n",
      "     tonga0:tpb0  nn.batch_matmul22:0\n",
      "     tonga0:tpb0  nn.batch_matmul23:0\n",
      "     tonga0:tpb0  nn.batch_matmul24:0\n",
      "     tonga0:tpb0  nn.batch_matmul25:0\n",
      "     tonga0:tpb0  nn.batch_matmul26:0\n",
      "     tonga0:tpb0  nn.batch_matmul27:0\n",
      "     tonga0:tpb0  nn.batch_matmul28:0\n",
      "     tonga0:tpb0  nn.batch_matmul29:0\n",
      "     tonga0:tpb0  nn.batch_matmul2:0\n",
      "     tonga0:tpb0  nn.batch_matmul30:0\n",
      "     tonga0:tpb0  nn.batch_matmul31:0\n",
      "     tonga0:tpb0  nn.batch_matmul3:0\n",
      "     tonga0:tpb0  nn.batch_matmul4:0\n",
      "     tonga0:tpb0  nn.batch_matmul5:0\n",
      "     tonga0:tpb0  nn.batch_matmul6:0\n",
      "     tonga0:tpb0  nn.batch_matmul7:0\n",
      "     tonga0:tpb0  nn.batch_matmul8:0\n",
      "     tonga0:tpb0  nn.batch_matmul9:0\n",
      "     tonga0:tpb0  reshape18:0\n",
      "     tonga0:tpb0  reshape21:0\n",
      "     tonga0:tpb0  reshape22:0\n",
      "     tonga0:tpb0  reshape25:0\n",
      "     tonga0:tpb0  reshape2:0\n",
      "     tonga0:tpb0  reshape34:0\n",
      "     tonga0:tpb0  reshape37:0\n",
      "     tonga0:tpb0  reshape38:0\n",
      "     tonga0:tpb0  reshape41:0\n",
      "     tonga0:tpb0  reshape50:0\n",
      "     tonga0:tpb0  reshape53:0\n",
      "     tonga0:tpb0  reshape54:0\n",
      "     tonga0:tpb0  reshape57:0\n",
      "     tonga0:tpb0  reshape5:0\n",
      "     tonga0:tpb0  reshape64:0\n",
      "     tonga0:tpb0  reshape65:0\n",
      "     tonga0:tpb0  reshape66:0\n",
      "     tonga0:tpb0  reshape67:0\n",
      "     tonga0:tpb0  reshape6:0\n",
      "     tonga0:tpb0  reshape9:0\n",
      "     tonga0:tpb0  sqrt0:0\n",
      "     tonga0:tpb0  sqrt1:0\n",
      "     tonga0:tpb0  sqrt2:0\n",
      "     tonga0:tpb0  sqrt3:0\n",
      "     tonga0:tpb0  sqrt4:0\n",
      "     tonga0:tpb0  sqrt5:0\n",
      "     tonga0:tpb0  sqrt6:0\n",
      "     tonga0:tpb0  sqrt7:0\n",
      "     tonga0:tpb0  sqrt8:0\n",
      "        cpu0:cpu  strided_slice0:0\n",
      "        cpu0:cpu  strided_slice10:0\n",
      "        cpu0:cpu  strided_slice11:0\n",
      "        cpu0:cpu  strided_slice12:0\n",
      "        cpu0:cpu  strided_slice13:0\n",
      "        cpu0:cpu  strided_slice14:0\n",
      "        cpu0:cpu  strided_slice15:0\n",
      "        cpu0:cpu  strided_slice16:0\n",
      "        cpu0:cpu  strided_slice17:0\n",
      "        cpu0:cpu  strided_slice18:0\n",
      "        cpu0:cpu  strided_slice19:0\n",
      "        cpu0:cpu  strided_slice1:0\n",
      "        cpu0:cpu  strided_slice20:0\n",
      "     tonga0:tpb0  strided_slice2:0\n",
      "     tonga0:tpb0  strided_slice3:0\n",
      "     tonga0:tpb0  strided_slice4:0\n",
      "     tonga0:tpb0  strided_slice5:0\n",
      "     tonga0:tpb0  strided_slice6:0\n",
      "     tonga0:tpb0  strided_slice7:0\n",
      "     tonga0:tpb0  strided_slice8:0\n",
      "        cpu0:cpu  strided_slice9:0\n",
      "     tonga0:tpb0  subtract0:0\n",
      "     tonga0:tpb0  subtract1:0\n",
      "     tonga0:tpb0  subtract2:0\n",
      "     tonga0:tpb0  subtract3:0\n",
      "     tonga0:tpb0  subtract4:0\n",
      "     tonga0:tpb0  subtract5:0\n",
      "     tonga0:tpb0  subtract6:0\n",
      "     tonga0:tpb0  subtract7:0\n",
      "     tonga0:tpb0  subtract8:0\n",
      "     tonga0:tpb0  sum0:0\n",
      "     tonga0:tpb0  sum10:0\n",
      "     tonga0:tpb0  sum11:0\n",
      "     tonga0:tpb0  sum12:0\n",
      "     tonga0:tpb0  sum13:0\n",
      "     tonga0:tpb0  sum14:0\n",
      "     tonga0:tpb0  sum15:0\n",
      "     tonga0:tpb0  sum16:0\n",
      "     tonga0:tpb0  sum17:0\n",
      "     tonga0:tpb0  sum1:0\n",
      "     tonga0:tpb0  sum2:0\n",
      "     tonga0:tpb0  sum3:0\n",
      "     tonga0:tpb0  sum4:0\n",
      "     tonga0:tpb0  sum5:0\n",
      "     tonga0:tpb0  sum6:0\n",
      "     tonga0:tpb0  sum7:0\n",
      "     tonga0:tpb0  sum8:0\n",
      "     tonga0:tpb0  sum9:0\n",
      "     tonga0:tpb0  tanh0:0\n",
      "     tonga0:tpb0  transpose10:0\n",
      "     tonga0:tpb0  transpose12:0\n",
      "     tonga0:tpb0  transpose18:0\n",
      "     tonga0:tpb0  transpose20:0\n",
      "     tonga0:tpb0  transpose26:0\n",
      "     tonga0:tpb0  transpose28:0\n",
      "     tonga0:tpb0  transpose2:0\n",
      "     tonga0:tpb0  transpose4:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Error message:  Traceback (most recent call last):\n",
      "  [bt] (5) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(TVMFuncCall+0x52) [0x7f080af71442]\n",
      "  [bt] (4) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(+0xb456f4) [0x7f080acf26f4]\n",
      "  [bt] (3) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(+0xb44155) [0x7f080acf1155]\n",
      "  [bt] (2) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(+0xba3d3b) [0x7f080ad50d3b]\n",
      "  [bt] (1) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(+0xba1e40) [0x7f080ad4ee40]\n",
      "  [bt] (0) /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/libtvm.so(+0x5edf75) [0x7f080a79af75]\n",
      "  File \"/opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/partition_graph.cc\", line 850\n",
      "TVMError: Check failed: found: Could not find primary output\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Error class:    TVMError\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 765, in build_graph\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:     coloring_map, color_to_target_map)\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/ir_pass.py\", line 1261, in color_graph\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:     pre_color_map_internal, pre_target_map_internal)\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/_ffi/_ctypes/function.py\", line 190, in __call__\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:     raise get_last_ffi_error()\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Version information:\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: \n",
      "06/11/2023 03:07:26 PM ERROR 2246 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$311; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/106/graph_def.neff --io-config '{\"inputs\": {\"tensor.1:0\": [[3, 512], \"int64\"], \"1:0\": [[3, 512, 256], \"float32\"], \"2:0\": [[3, 512, 256], \"float32\"], \"3:0\": [[3, 512, 256], \"float32\"], \"4:0\": [[3, 512, 256], \"float32\"], \"5:0\": [[3, 512, 256], \"float32\"], \"6:0\": [[3, 512, 256], \"float32\"], \"7:0\": [[3, 512, 256], \"float32\"], \"8:0\": [[3, 512, 256], \"float32\"], \"9:0\": [[3, 512, 256], \"float32\"], \"tensor.9:0\": [[3, 512, 7], \"int64\"], \"tensor.25:0\": [[], \"int64\"], \"tensor.39:0\": [[], \"int64\"], \"tensor.59:0\": [[], \"int64\"], \"tensor.75:0\": [[], \"int64\"]}, \"outputs\": [\"TapasModel_7/TapasPooler_29/Tanh_11/aten_tanh/Tanh:0\", \"aten_to_5/Const:0\", \"aten_add/add:0\", \"aten_reshape/Reshape:0\", \"aten_expand/Cast_1:0\", \"aten_zeros/zeros:0\", \"aten_ones/ones:0\", \"aten_expand_1/Cast_1:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros_1/zeros:0\", \"aten_ones_1/ones:0\", \"aten_expand_3/Cast_1:0\", \"aten_to_18/Cast:0\", \"aten_reshape_2/Reshape:0\", \"aten_expand_4/Cast_1:0\", \"aten_zeros_2/zeros:0\", \"aten_ones_2/ones:0\", \"aten_expand_5/Cast_1:0\", \"aten_reshape_3/Reshape:0\", \"aten_view_8/Reshape:0\", \"aten_to_28/Cast:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$312 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:27 PM INFO 2371 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:27 PM INFO 2371 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108\n",
      "06/11/2023 03:07:27 PM INFO 2371 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:27 PM INFO 2371 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:27 PM INFO 2371 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:27 PM INFO 2371 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:27 PM INFO 2371 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:28 PM INFO 2371 [job.Frontend.4]: IR signature: 0b515f9f87a0903af8d4079f4fd42747c6ecd70943f0f3dab429b35a2dd0a528 for graph_def.pb\n",
      "06/11/2023 03:07:28 PM INFO 2371 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:28 PM INFO 2371 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:28 PM INFO 2371 [job.Frontend.4]: Start tensorization\n",
      "[15:07:28] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:28] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=96\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:28] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        96           0         0         0           1\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:28] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  aten_zeros/zeros:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:28 PM INFO 2371 [job.Frontend.4]: IR signature: 84f86cfc5e14e725a13cb10b76d04cc32e6e88acf050fbc24f4b0dec3c71f304 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:28 PM INFO 2371 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.015s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:28 PM INFO 2371 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Statistics]: Weights total number of bytes: 24576\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Statistics]: RelayIF total number of bytes: 0.0\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Statistics]: RelayOF total number of bytes: 24576.0\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Statistics]: Weights total number of bytes: 24576.0\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [MutateDataType]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [AutoCastFP32]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [ResolveAccessConflict]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TransformLayout]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TongaSizeTiling]: Finished (changed=True #instances=48)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [InferTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:28 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:28 PM INFO 2371 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [DataLocalityOpt]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.017s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [FlattenMacroLoop]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [RewriteWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [ReshapeWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [InferInitValue]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SimplifyTongaTensor]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaISel]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [FactorizeBlkDims]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaInstComb]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LowerTranspose]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizeTongaType]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [PartialLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizeTongaType]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LowerPartitionTile]: Finished (changed=True #instances=151)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LinearizeFreeDim]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [ILPOpt]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LowerAPIndices]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:29 PM INFO 2371 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Tensorizer]: IR signature: 764a9bb30378bfc831f12bbadedb3692aa253378d19ea5a832127238f392229e for sg00/Tensorizer\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Tensorizer]: Weights total number of bytes: 12288\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                3  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                2  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                2  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            49152  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            24576  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                3  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            24576  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:        3651.5556  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:        4096.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:           2.4405  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:             4096  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            49152  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            12288  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:               96  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            45056  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:               64  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:              219  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:               48  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:            24576  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:29 PM INFO 2371 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:29 PM INFO 2371 [root/Tensorizer/All]: Exit time region: delta=0.947s\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.WalrusDriver.3]: IR signature: ee01729779cd2a9104ad46eb0c5b35ae9b4186218eaa68297837823ef0a2e0e9 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: IR signature: 00e9b4c23da36e9fc666e01d0388d5cddb0dc6fd363ec8d07983bcdf2bf6d724 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: IR signature: de82acf6a13e3d12d1cfdfd58f65b27fb1ce3c4a32295bdd22565850d43ddfd5 for sg00/def.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: IR signature: bd90bab37ff910c020f08cc50c4889b31921c40070b3dd9b6194435ed83cd150 for sg00/pool.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:29 PM WARNING 2371 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:29 PM WARNING 2371 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:29 PM INFO 2371 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/graph_def.neff\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:29 PM INFO 2371 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:29 PM INFO 2371 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=2\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Total count: 151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Shuffle: 96\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: TensorCopy: 48\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Save: 6\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Load: 1\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 1 loads, 6 saves, 0 copies.\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 275 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         size = 55\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 96 bytes/partition\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         bit-matrix size = 190 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: 13% SB demand before allocation\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           SB high-water mark = 13280 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         found 853 edges\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         adjacency vectors require 6824 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:               safe = 52\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             unsafe = 3\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:              total = 55\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: 96 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: pinning saved approximately 1728 cycles\n",
      "06/11/2023 03:07:29 PM WARNING [WalrusDriver.0]: 13% SB utilization after allocation\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 24576\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 24576\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:29 2023\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/108/sg00\"\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 275 bytes\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Loads in Func = 1\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Saves in Func = 6\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Input Loads in Func= 1\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Output Saves in Func= 6\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: Virtual memory peak = 4356048 K bytes\n",
      "06/11/2023 03:07:29 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:29 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$313 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:30 PM INFO 2490 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:30 PM INFO 2490 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114\n",
      "06/11/2023 03:07:30 PM INFO 2490 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:30 PM INFO 2490 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:30 PM INFO 2490 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:30 PM INFO 2490 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:30 PM INFO 2490 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:32 PM INFO 2490 [job.Frontend.4]: IR signature: 4a137b05e642d3173539ff6772ed2c11b198a909f11cf1e270bb4a7338ee6c23 for graph_def.pb\n",
      "06/11/2023 03:07:32 PM INFO 2490 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:32 PM INFO 2490 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:32 PM INFO 2490 [job.Frontend.4]: Start tensorization\n",
      "[15:07:32] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:32] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=96\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:32] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        96           0         0         0           1\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:32] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  aten_zeros/zeros:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:32 PM INFO 2490 [job.Frontend.4]: IR signature: 84f86cfc5e14e725a13cb10b76d04cc32e6e88acf050fbc24f4b0dec3c71f304 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:32 PM INFO 2490 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.016s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]: Weights total number of bytes: 24576\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]: RelayIF total number of bytes: 0.0\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]: RelayOF total number of bytes: 24576.0\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]: Weights total number of bytes: 24576.0\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [MutateDataType]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [AutoCastFP32]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ResolveAccessConflict]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TransformLayout]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaSizeTiling]: Finished (changed=True #instances=48)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [InferTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DataLocalityOpt]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.019s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FlattenMacroLoop]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [RewriteWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ReshapeWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [InferInitValue]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SimplifyTongaTensor]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaISel]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [FactorizeBlkDims]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaInstComb]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LowerTranspose]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizeTongaType]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [PartialLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizeTongaType]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LowerPartitionTile]: Finished (changed=True #instances=151)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LinearizeFreeDim]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [ILPOpt]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LowerAPIndices]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:32 PM INFO 2490 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: IR signature: 764a9bb30378bfc831f12bbadedb3692aa253378d19ea5a832127238f392229e for sg00/Tensorizer\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Weights total number of bytes: 12288\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                3  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                2  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                2  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            49152  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            24576  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                3  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            24576  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:        3651.5556  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:        4096.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:           2.4405  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:             4096  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            49152  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            12288  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:               96  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            45056  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:               64  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:              219  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:               48  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:            24576  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:32 PM INFO 2490 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:33 PM INFO 2490 [root/Tensorizer/All]: Exit time region: delta=1.029s\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.WalrusDriver.3]: IR signature: ee01729779cd2a9104ad46eb0c5b35ae9b4186218eaa68297837823ef0a2e0e9 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: IR signature: 00e9b4c23da36e9fc666e01d0388d5cddb0dc6fd363ec8d07983bcdf2bf6d724 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: IR signature: de82acf6a13e3d12d1cfdfd58f65b27fb1ce3c4a32295bdd22565850d43ddfd5 for sg00/def.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: IR signature: bd90bab37ff910c020f08cc50c4889b31921c40070b3dd9b6194435ed83cd150 for sg00/pool.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:33 PM WARNING 2490 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:33 PM WARNING 2490 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:33 PM INFO 2490 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/graph_def.neff\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:33 PM INFO 2490 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:33 PM INFO 2490 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=2\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Total count: 151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Shuffle: 96\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: TensorCopy: 48\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Save: 6\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Load: 1\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 1 loads, 6 saves, 0 copies.\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 275 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         size = 55\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 96 bytes/partition\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         bit-matrix size = 190 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: 13% SB demand before allocation\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           SB high-water mark = 13280 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         found 853 edges\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         adjacency vectors require 6824 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:               safe = 52\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             unsafe = 3\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:              total = 55\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: 96 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: pinning saved approximately 1728 cycles\n",
      "06/11/2023 03:07:33 PM WARNING [WalrusDriver.0]: 13% SB utilization after allocation\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 24576\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 24576\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:33 2023\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/114/sg00\"\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 275 bytes\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Loads in Func = 1\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Saves in Func = 6\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Input Loads in Func= 1\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Output Saves in Func= 6\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: Virtual memory peak = 4356052 K bytes\n",
      "06/11/2023 03:07:33 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:33 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$314 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:34 PM INFO 2605 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:34 PM INFO 2605 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121\n",
      "06/11/2023 03:07:34 PM INFO 2605 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:34 PM INFO 2605 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:34 PM INFO 2605 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:34 PM INFO 2605 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:34 PM INFO 2605 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"]}, \"outputs\": [\"aten_zeros/zeros:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:35 PM INFO 2605 [job.Frontend.4]: IR signature: 82cf9182519a1d9a9a9957f6d6b45ea5186cf5d6cce37a1cb26feac9d286e262 for graph_def.pb\n",
      "06/11/2023 03:07:35 PM INFO 2605 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:35 PM INFO 2605 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:35 PM INFO 2605 [job.Frontend.4]: Start tensorization\n",
      "[15:07:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=96\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0        96           0         0         0           1\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:35] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  aten_zeros/zeros:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:35 PM INFO 2605 [job.Frontend.4]: IR signature: 84f86cfc5e14e725a13cb10b76d04cc32e6e88acf050fbc24f4b0dec3c71f304 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:35 PM INFO 2605 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.016s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:35 PM INFO 2605 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Statistics]: Weights total number of bytes: 24576\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Statistics]: RelayIF total number of bytes: 0.0\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Statistics]: RelayOF total number of bytes: 24576.0\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Statistics]: Weights total number of bytes: 24576.0\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [MutateDataType]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [AutoCastFP32]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ResolveAccessConflict]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TransformLayout]: Finished (changed=True #instances=18432)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TongaSizeTiling]: Finished (changed=True #instances=48)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [InferTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.000s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [DataLocalityOpt]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.019s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [LegalizeTongaMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [FlattenMacroLoop]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [RewriteWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [ReshapeWeights]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [InferInitValue]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:35 PM INFO 2605 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:35 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [SimplifyTongaTensor]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaISel]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [FactorizeBlkDims]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaInstComb]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LowerTranspose]: Finished (changed=True #instances=55)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LegalizeTongaType]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [PartialLoopFusion]: Finished (changed=True #instances=103)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [ShortenLifeInterval]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [SpillPSum]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LegalizeTongaType]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LowerPartitionTile]: Finished (changed=True #instances=151)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LegalizeTongaAccess]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LinearizeFreeDim]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [ILPOpt]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LowerAPIndices]: Finished (changed=True #instances=201)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:36 PM INFO 2605 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Tensorizer]: IR signature: 764a9bb30378bfc831f12bbadedb3692aa253378d19ea5a832127238f392229e for sg00/Tensorizer\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Tensorizer]: Weights total number of bytes: 12288\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                3  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                2  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                2  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                2  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            49152  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            12288  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            24576  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                3  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            24576  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           0.0000  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:        3651.5556  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:        4096.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:           2.4405  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:             4096  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            49152  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            12288  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:               96  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            45056  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:               64  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:              219  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:          81.8182  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:         100.0000  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:               48  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                1  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:            24576  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:36 PM INFO 2605 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:36 PM INFO 2605 [root/Tensorizer/All]: Exit time region: delta=0.986s\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.WalrusDriver.3]: IR signature: ee01729779cd2a9104ad46eb0c5b35ae9b4186218eaa68297837823ef0a2e0e9 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: IR signature: 00e9b4c23da36e9fc666e01d0388d5cddb0dc6fd363ec8d07983bcdf2bf6d724 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: IR signature: de82acf6a13e3d12d1cfdfd58f65b27fb1ce3c4a32295bdd22565850d43ddfd5 for sg00/def.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: IR signature: bd90bab37ff910c020f08cc50c4889b31921c40070b3dd9b6194435ed83cd150 for sg00/pool.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:36 PM WARNING 2605 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:36 PM WARNING 2605 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:36 PM INFO 2605 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/graph_def.neff\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:36 PM INFO 2605 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:36 PM INFO 2605 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=5 blocks=1 instructions=2\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Total count: 151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Shuffle: 96\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: TensorCopy: 48\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Save: 6\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Load: 1\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 1 loads, 6 saves, 0 copies.\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 275 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         size = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 0 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: 0% PSUM demand before spilling\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 0 tensors\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             lo = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             total = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: 0% PSUM utilization after allocation\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         size = 55\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         found 0 accumulation groups\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         1 pin count\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         1 pinned tensors will require about 96 bytes/partition\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         bit-matrix size = 190 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: 13% SB demand before allocation\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           SB high-water mark = 13280 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             13280 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         found 853 edges\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         adjacency vectors require 6824 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:               safe = 52\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             unsafe = 3\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:              total = 55\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: 96 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: pinning saved approximately 1728 cycles\n",
      "06/11/2023 03:07:36 PM WARNING [WalrusDriver.0]: 13% SB utilization after allocation\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 36864, 33.3333% input load, 66.6667% output write, 0% spill/reload \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 24576\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 12288\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 96 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 24576\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 4096 bytes\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:36 2023\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=57 blocks=1 instructions=151\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/121/sg00\"\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 36864\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 275 bytes\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Loads in Func = 1\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Saves in Func = 6\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Input Loads in Func= 1\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Output Saves in Func= 6\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: Virtual memory peak = 4356044 K bytes\n",
      "06/11/2023 03:07:36 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: ru_maxrss:  1604mb (delta=0mb)\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:36 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 57 memory location(s), 1 block(s), and 151 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Compiling function _NeuronGraph$315 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:37 PM INFO 2728 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:38 PM INFO 2728 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127\n",
      "06/11/2023 03:07:38 PM INFO 2728 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:38 PM INFO 2728 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:38 PM INFO 2728 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:38 PM INFO 2728 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:38 PM INFO 2728 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:39 PM INFO 2728 [job.Frontend.4]: IR signature: 30a9baccda12047ade655045d9b2c4cff2bc3f16309ba9179b3e7e2a11b2d466 for graph_def.pb\n",
      "06/11/2023 03:07:39 PM INFO 2728 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:39 PM INFO 2728 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:39 PM INFO 2728 [job.Frontend.4]: Start tensorization\n",
      "[15:07:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=4\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0         4           0         0         0          46\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:39] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  Identity:0\n",
      "     tonga0:tpb0  aten_add/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_add/add:0\n",
      "     tonga0:tpb0  aten_add_1/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_add_1/add:0\n",
      "     tonga0:tpb0  aten_div/truediv:0\n",
      "     tonga0:tpb0  aten_div_1/truediv:0\n",
      "     tonga0:tpb0  aten_expand/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_1/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_2/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_2/Cast:0\n",
      "     tonga0:tpb0  aten_expand_2/Cast_1:0\n",
      "     tonga0:tpb0  aten_expand_3/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_expand_3/Cast:0\n",
      "     tonga0:tpb0  aten_expand_3/Cast_1:0\n",
      "     tonga0:tpb0  aten_floor/Floor:0\n",
      "     tonga0:tpb0  aten_mul/mul:0\n",
      "     tonga0:tpb0  aten_mul_1/mul:0\n",
      "     tonga0:tpb0  aten_mul_2/mul:0\n",
      "     tonga0:tpb0  aten_reshape/Reshape:0\n",
      "     tonga0:tpb0  aten_reshape_1/Reshape:0\n",
      "     tonga0:tpb0  aten_to/Cast:0\n",
      "     tonga0:tpb0  aten_to_1/Cast:0\n",
      "     tonga0:tpb0  aten_unsqueeze/ExpandDims:0\n",
      "     tonga0:tpb0  aten_unsqueeze_1/ExpandDims:0\n",
      "     tonga0:tpb0  aten_view/Reshape:0\n",
      "     tonga0:tpb0  aten_view_1/Reshape:0\n",
      "     tonga0:tpb0  aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  aten_view_5/Reshape:0\n",
      "     tonga0:tpb0  aten_zeros/zeros:0\n",
      "     tonga0:tpb0  cast0:0\n",
      "     tonga0:tpb0  cast1:0\n",
      "     tonga0:tpb0  copy0:0\n",
      "     tonga0:tpb0  copy1:0\n",
      "     tonga0:tpb0  copy2:0\n",
      "     tonga0:tpb0  copy3:0\n",
      "     tonga0:tpb0  copy4:0\n",
      "     tonga0:tpb0  copy5:0\n",
      "     tonga0:tpb0  copy6:0\n",
      "     tonga0:tpb0  copy7:0\n",
      "     tonga0:tpb0  copy8:0\n",
      "     tonga0:tpb0  rdivide_scalar0:0\n",
      "     tonga0:tpb0  rdivide_scalar1:0\n",
      "     tonga0:tpb0  reshape0:0\n",
      "     tonga0:tpb0  reshape1:0\n",
      "     tonga0:tpb0  reshape2:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Error message:  'TongaOpNode' object has no attribute 'op_name'\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Error class:    AttributeError\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 384, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/build_module.py\", line 841, in build_graph\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:     graph_json = graph_gen.get_graph_json(func)\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/backend/graph_runtime_codegen.py\", line 815, in get_graph_json\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:     graph_json = self._get_json()\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/backend/graph_runtime_codegen.py\", line 516, in _get_json\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:     nodes.append(node.to_json())\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/tvm/relay/backend/graph_runtime_codegen.py\", line 184, in to_json\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:     \"The number of outputs mismatch for NeuronOpNode \" + self.op_name)\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Version information:\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: \n",
      "06/11/2023 03:07:39 PM ERROR 2728 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$315; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/127/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[6144], \"float32\"], \"1:0\": [[6144], \"float32\"], \"2:0\": [[6144], \"float32\"], \"3:0\": [[6144], \"float32\"], \"tensor.1:0\": [[3, 2048], \"int64\"], \"tensor.7:0\": [[], \"int64\"], \"tensor.9:0\": [[], \"int64\"], \"tensor.23:0\": [[], \"int64\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"aten_reshape/Reshape:0\", \"aten_expand_2/Cast_1:0\", \"aten_zeros/zeros:0\", \"Identity:0\", \"aten_reshape_1/Reshape:0\", \"aten_expand_3/Cast_1:0\", \"aten_zeros_1/zeros:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$316 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:40 PM INFO 2806 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:40 PM INFO 2806 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131\n",
      "06/11/2023 03:07:40 PM INFO 2806 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:40 PM INFO 2806 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:40 PM INFO 2806 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:40 PM INFO 2806 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:40 PM INFO 2806 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:41 PM INFO 2806 [job.Frontend.4]: IR signature: 3bde3d59912f45d36eb6105d223c96c290dd96b99169a310ae4edb4a9458336d for graph_def.pb\n",
      "06/11/2023 03:07:41 PM INFO 2806 [job.Frontend.4]: total padded opcount is 0\n",
      "06/11/2023 03:07:41 PM INFO 2806 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:41 PM INFO 2806 [job.Frontend.4]: Start tensorization\n",
      "[15:07:42] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:42] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=0\n",
      "Coloring: Total const bytes per part=106\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:42] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 0. Average number of cycles per partition: 0\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0               0       106           0         0         0          41\n",
      "Coloring: Total nubmer of cycles = 0\n",
      "Coloring: Largest number of cycles in part = 0, Ratio worst/best avg = -nan\n",
      "\n",
      "\n",
      "\n",
      "[15:07:42] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  add0:0\n",
      "     tonga0:tpb0  aten_add/add:0\n",
      "     tonga0:tpb0  aten_add_1/add:0\n",
      "     tonga0:tpb0  aten_add_2/add:0\n",
      "     tonga0:tpb0  aten_add_3/add:0\n",
      "     tonga0:tpb0  aten_argmax/ArgMax:0\n",
      "     tonga0:tpb0  aten_div/truediv:0\n",
      "     tonga0:tpb0  aten_div_1/truediv:0\n",
      "     tonga0:tpb0  aten_eq_2/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_eq_2/Equal:0\n",
      "     tonga0:tpb0  aten_eq_3/Equal:0\n",
      "     tonga0:tpb0  aten_expand/BroadcastTo:0\n",
      "     tonga0:tpb0  aten_floor/Floor:0\n",
      "     tonga0:tpb0  aten_logical_and/LogicalAnd:0\n",
      "     tonga0:tpb0  aten_lt/Less:0\n",
      "     tonga0:tpb0  aten_mul/mul:0\n",
      "     tonga0:tpb0  aten_mul_2/mul:0\n",
      "     tonga0:tpb0  aten_mul_3/mul:0\n",
      "     tonga0:tpb0  aten_reshape/Reshape:0\n",
      "     tonga0:tpb0  aten_rsub/mul:0\n",
      "     tonga0:tpb0  aten_rsub/sub:0\n",
      "     tonga0:tpb0  aten_to_1/Cast:0\n",
      "     tonga0:tpb0  aten_to_3/Cast:0\n",
      "     tonga0:tpb0  aten_to_4/Cast:0\n",
      "     tonga0:tpb0  aten_to_7/Cast:0\n",
      "     tonga0:tpb0  aten_to_8/Cast:0\n",
      "     tonga0:tpb0  aten_unsqueeze/ExpandDims:0\n",
      "     tonga0:tpb0  aten_view/Reshape:0\n",
      "     tonga0:tpb0  aten_view_2/Reshape:0\n",
      "     tonga0:tpb0  aten_view_3/Reshape:0\n",
      "     tonga0:tpb0  aten_view_4/Reshape:0\n",
      "     tonga0:tpb0  aten_where/Select:0\n",
      "     tonga0:tpb0  copy0:0\n",
      "     tonga0:tpb0  copy1:0\n",
      "     tonga0:tpb0  copy2:0\n",
      "     tonga0:tpb0  copy3:0\n",
      "     tonga0:tpb0  copy4:0\n",
      "     tonga0:tpb0  copy5:0\n",
      "     tonga0:tpb0  copy6:0\n",
      "     tonga0:tpb0  rdivide_scalar0:0\n",
      "     tonga0:tpb0  rdivide_scalar1:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:42 PM INFO 2806 [job.Frontend.4]: IR signature: 6babbc1651c45db3e3babde1826174673f8298ef5453cfcb102723d989fd4d6c for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:42 PM INFO 2806 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.032s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.056s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:42 PM INFO 2806 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]: Weights total number of bytes: 25120\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]: RelayIF total number of bytes: 135936.0\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]: RelayOF total number of bytes: 36864.0\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]: Weights total number of bytes: 25120.0\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [MutateDataType]: Finished (changed=True #instances=556638)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.012s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.025s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Simplifier]: Finished (changed=True #instances=525630)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.025s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LoopFusion]: Finished (changed=True #instances=217728)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.063s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DelinearIndices]: Finished (changed=True #instances=217728)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.044s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LICM]: Finished (changed=True #instances=211122)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LoopFusion]: Finished (changed=True #instances=198834)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [ValueNumbering]: Finished (changed=True #instances=192690)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [MemcpyElimination]: Finished (changed=True #instances=192498)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:42 PM INFO 2806 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:42 PM ERROR 2806 [IRVerifier]: type mismatch between result and operand       |V2 $51[i0_7,i1_7] = floor(float32 $47[i0_7,i1_7]) # dl = aten_floor/Floor\n",
      "06/11/2023 03:07:42 PM INFO 2806 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:42 PM ERROR 2806 [Tensorizer]: Transformation error on operator: copy6\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:               10  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:               51  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:               16  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:               96  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:               96  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                1  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                1  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:           943054  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                1  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:42 PM INFO 2806 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:43 PM INFO 2806 [root/Tensorizer/All]: Exit time region: delta=1.096s\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: ***************************************************************\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Error message:  Incorrect IR by <class 'neuroncc.starfish.penguin.targets.tonga.passes.AutoCastFP32.AutoCastFP32'>\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Error class:    AssertionError\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Error location: Unknown\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Command line:   /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Internal details:\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/CommandDriver.py\", line 224, in neuroncc.driver.CommandDriver.CommandDriver.run\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 580, in neuroncc.driver.commands.CompileCommand.CompileCommand.run\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 558, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/commands/CompileCommand.py\", line 562, in neuroncc.driver.commands.CompileCommand.CompileCommand.runPipeline\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/Pipeline.py\", line 30, in neuroncc.driver.Pipeline.Pipeline.runSingleInput\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 289, in neuroncc.driver.Job.SingleInputJob.run\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 429, in neuroncc.driver.jobs.Frontend.Frontend.runSingleInput\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 379, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 380, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 390, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/driver/jobs/Frontend.py\", line 360, in neuroncc.driver.jobs.Frontend.Frontend.runTVMFrontend.tensorize\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/Frontend.py\", line 47, in neuroncc.starfish.penguin.Frontend.tensorizeRelay\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/Frontend.py\", line 48, in neuroncc.starfish.penguin.Frontend.tensorizeRelay\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/Frontend.py\", line 69, in neuroncc.starfish.penguin.Frontend.tensorizeRelay\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/Compile.py\", line 247, in neuroncc.starfish.penguin.Compile.compile_cu\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 378, in neuroncc.starfish.penguin.DotTransform.PassManager.transformFunction\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 124, in neuroncc.starfish.penguin.DotTransform.DotTransform.runOnFunction\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 178, in neuroncc.starfish.penguin.DotTransform.DotTransform.run_with_exception_handling\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 160, in neuroncc.starfish.penguin.DotTransform.DotTransform.run_with_exception_handling\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 186, in neuroncc.starfish.penguin.DotTransform.DotTransform.timed_run_\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 188, in neuroncc.starfish.penguin.DotTransform.DotTransform.timed_run_\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 189, in neuroncc.starfish.penguin.DotTransform.DotTransform.timed_run_\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 206, in neuroncc.starfish.penguin.DotTransform.DotTransform.run_\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 207, in neuroncc.starfish.penguin.DotTransform.DotTransform.run_\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 289, in neuroncc.starfish.penguin.DotTransform.DotTransform.transformFunction\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/targets/tonga/Tonga.py\", line 373, in neuroncc.starfish.penguin.targets.tonga.Tonga.TongaLowering.verify\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   File \"neuroncc/starfish/penguin/DotTransform.py\", line 275, in neuroncc.starfish.penguin.DotTransform.DotTransform.verify\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Version information:\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   Neuron Compiler version 1.15.0.0+eec0c3604\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   HWM version 1.14.1.0-a9fb5c73a\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   NEFF version Dynamic\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   TVM version 1.15.0.0+0\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   NumPy version 1.18.5\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   MXNet not available\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]:   TF not available\n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: \n",
      "06/11/2023 03:07:43 PM ERROR 2806 [neuron-cc]: Artifacts stored in: /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131\n",
      "INFO:Neuron:Compile command returned: 1\n",
      "WARNING:Neuron:torch.neuron.trace failed on _NeuronGraph$316; falling back to native python function call\n",
      "ERROR:Neuron:neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]}' --verbose 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/convert.py\", line 414, in op_converter\n",
      "    item, inputs, compiler_workdir=sg_workdir, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/decorators.py\", line 264, in trace\n",
      "    'neuron-cc failed with the following command line call:\\n{}'.format(command))\n",
      "subprocess.SubprocessError: neuron-cc failed with the following command line call:\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/131/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[96], \"float32\"], \"tensor.1:0\": [[], \"int64\"], \"2:0\": [[96], \"float32\"], \"3:0\": [[6144], \"float32\"], \"4:0\": [[6144], \"float32\"], \"5:0\": [[6144], \"int64\"], \"tensor.11:0\": [[3, 2048], \"int64\"], \"7:0\": [[3, 2048], \"float32\"], \"8:0\": [[3, 512], \"int64\"]}, \"outputs\": [\"aten_add_3/add:0\", \"aten_view_7/Reshape:0\"]}' --verbose 1\n",
      "INFO:Neuron:Compiling function _NeuronGraph$317 with neuron-cc\n",
      "INFO:Neuron:Compiling with command line: '/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.neff --io-config {\"inputs\": {\"0:0\": [[3, 256], \"float32\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"float32\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"Linear_648/aten_linear/Add:0\"]} --verbose 1'\n",
      "06/11/2023 03:07:44 PM INFO 2907 [root]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.neff --io-config '{\"inputs\": {\"0:0\": [[3, 256], \"float32\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"float32\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"Linear_648/aten_linear/Add:0\"]}' --verbose 1\n",
      "06/11/2023 03:07:44 PM INFO 2907 [root]: Intermediate files stored in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133, output in /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133\n",
      "06/11/2023 03:07:44 PM INFO 2907 [pipeline.custom.0]: Running pipeline custom.0\n",
      "06/11/2023 03:07:44 PM INFO 2907 [pipeline.custom.0]: Starting job pipeline.compile.0 state state 0\n",
      "06/11/2023 03:07:44 PM INFO 2907 [pipeline.compile.0]: Running pipeline compile.0\n",
      "06/11/2023 03:07:44 PM INFO 2907 [pipeline.compile.0]: Starting job job.Frontend.4 state state 0\n",
      "06/11/2023 03:07:44 PM INFO 2907 [job.Frontend.4]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb\"], \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133\", \"state_id\": \"root\"}' --pipeline Frontend --io-config '{\"inputs\": {\"0:0\": [[3, 256], \"float32\"], \"1:0\": [[3, 512], \"int64\"], \"2:0\": [[3, 512], \"float32\"]}, \"outputs\": [\"aten_view/Reshape:0\", \"Linear_648/aten_linear/Add:0\"]}' --framework TENSORFLOW\n",
      "06/11/2023 03:07:45 PM INFO 2907 [job.Frontend.4]: IR signature: 64bed1e90f7d744a94a39ac35418660a346500c96ca13d4e327e519c11afe143 for graph_def.pb\n",
      "06/11/2023 03:07:45 PM INFO 2907 [job.Frontend.4]: total padded opcount is 6144\n",
      "06/11/2023 03:07:45 PM INFO 2907 [job.Frontend.4]: Finished Jellyfish import\n",
      "06/11/2023 03:07:45 PM INFO 2907 [job.Frontend.4]: Start tensorization\n",
      "[15:07:45] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:82: \n",
      "Coloring: number graph parts=1\n",
      "Coloring: number sbuf rows=128\n",
      "Coloring: number sbuf bytes=76800\n",
      "Coloring: static weights=0\n",
      "\n",
      "[15:07:45] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:192: \n",
      "Coloring: Total cycles=3072\n",
      "Coloring: Total const bytes per part=17\n",
      "Coloring: Byte threshold = 72960\n",
      "\n",
      "[15:07:45] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_stats.cc:157: \n",
      "\n",
      "Coloring: Total number of cycles: 3,072. Average number of cycles per partition: 3,072\n",
      " Color         #Clocks   Weights    MaxIfmap   #Conv2D    #Dense   #OtherOps\n",
      "     0           3,072        17           0         0         1           4\n",
      "Coloring: Total nubmer of cycles = 3,072\n",
      "Coloring: Largest number of cycles in part = 3,072, Ratio worst/best avg = 1\n",
      "\n",
      "\n",
      "\n",
      "[15:07:45] /opt/brazil-pkg-cache/packages/DmlcTvm/DmlcTvm-1.15.0.0/AL2_x86_64/generic-flavor/src/src/relay/pass/coloring/cgraph_painter.cc:757: \n",
      "           Color  Hash\n",
      "     tonga0:tpb0  Linear_648/aten_linear/MatMul:0\n",
      "     tonga0:tpb0  add0:0\n",
      "     tonga0:tpb0  aten_view/Reshape:0\n",
      "     tonga0:tpb0  copy0:0\n",
      "     tonga0:tpb0  copy1:0\n",
      "\n",
      "           Color  Target\n",
      "     tonga0:tpb0  tonga\n",
      "        cpu0:cpu  llvm -mcpu=skylake-avx512\n",
      "     cpu1000:cpu  llvm\n",
      "\n",
      "\n",
      "06/11/2023 03:07:45 PM INFO 2907 [job.Frontend.4]: IR signature: f7ae1aa0c900a455b63e5224e87896f24e2173afde637deccb20af98287c5a78 for relay_graph_post_opt_unit_level.txt\n",
      "06/11/2023 03:07:45 PM INFO 2907 [root/Tensorizer/All]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RelayPasses]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RelayPasses]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/IRBuilder]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/IRBuilder]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Tensorizer]: Tensorizer options:  --fp32-cast=all  --disable-bitcasted-transpose  --disable-expensive-checks  --disable-max-stride-tiling  --enable-replication  --max-local-tensor-tile-size-in-bytes=16384  --tensor-layout-p-order=0  --tensor-layout-b-order=1  --enable-advanced-delinearization  --weight-coalescing-threshold=512  --disable-shifted-fusion  --enable-bir-converter=enable \n",
      "06/11/2023 03:07:45 PM INFO 2907 [Tensorizer]: Generate: 1 statements from relay. Start optimizations ...\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Statistics]: Weights total number of bytes: 4112\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Statistics]: RelayIF total number of bytes: 9216.0\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Statistics]: RelayOF total number of bytes: 6192.0\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Statistics]: Weights total number of bytes: 4112.0\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DoNothing]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DoNothing]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DoNothing]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/MutateDataType]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [MutateDataType]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/MutateDataType]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ResolveEqualPredicates]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ResolveEqualPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ResolveEqualPredicates]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/EliminateDivs]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [EliminateDivs]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/EliminateDivs]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TCTransform]: Finished (changed=True #instances=20064)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LoopFusion]: Finished (changed=True #instances=21504)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DeadStoreElimination]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DeadStoreElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DeadStoreElimination]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LICM]: Finished (changed=True #instances=12324)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/MemcpyElimination]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [MemcpyElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/MemcpyElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PadElimination]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [PadElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PadElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DelinearIndices]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DelinearIndices]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TCTransform]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TCTransform]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TCTransform]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/CommuteConcat]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [CommuteConcat]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/CommuteConcat]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ValueNumbering]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RecognizeOpIdiom]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [RecognizeOpIdiom]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RecognizeOpIdiom]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DeadCodeElimination]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DeadCodeElimination]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DeadCodeElimination]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Tensorizer]: After optimization: 1 statements\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/AutoCastFP32]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [AutoCastFP32]: Finished (changed=True #instances=18480)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/AutoCastFP32]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LoopFusion]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Simplifier]: Finished (changed=True #instances=15408)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Simplifier]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Delinearization]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/Delinearization]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ResolveAccessConflict]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ResolveAccessConflict]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ResolveAccessConflict]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TransformLayout]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TransformLayout]: Finished (changed=True #instances=20808)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TransformLayout]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PartitionLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [PartitionLocalityOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PartitionLocalityOpt]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenPartitionAxes]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [FlattenPartitionAxes]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenPartitionAxes]: Exit time region: delta=0.001s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSizeTiling]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TongaSizeTiling]: Finished (changed=True #instances=18)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSizeTiling]: Exit time region: delta=0.020s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TilingProfiler]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TilingProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TilingProfiler]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [Tensorizer]: Default layout and tiling instruction count within range.\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RetileSIMDMacro]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [RetileSIMDMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RetileSIMDMacro]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/InferTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [InferTongaTensor]: Finished (changed=True #instances=18)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/InferTongaTensor]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LICM]: Finished (changed=True #instances=18)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RewriteReplicationMatmul]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [RewriteReplicationMatmul]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RewriteReplicationMatmul]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.002s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DataLocalityOpt]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [DataLocalityOpt]: Finished (changed=True #instances=23)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/DataLocalityOpt]: Exit time region: delta=0.051s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaMacro]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [LegalizeTongaMacro]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaMacro]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PerfectLoopNest]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [PerfectLoopNest]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/PerfectLoopNest]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [FlattenMacroLoop]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RewriteWeights]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [RewriteWeights]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/RewriteWeights]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ReshapeWeights]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [ReshapeWeights]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/ReshapeWeights]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Enter time region\n",
      "06/11/2023 03:07:45 PM INFO 2907 [FlattenMacroLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/FlattenMacroLoop]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:45 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [SimplifyPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SimplifyPredicates]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/InferInitValue]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [InferInitValue]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/InferInitValue]: Exit time region: delta=0.026s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SplitUnionSets]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [SplitUnionSets]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SplitUnionSets]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaSimplifier]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaSimplifier]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [SimplifyTongaTensor]: Finished (changed=True #instances=24)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaStore]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LegalizeTongaStore]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaStore]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LICM]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaISel]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaISel]: Finished (changed=True #instances=25)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaISel]: Exit time region: delta=0.008s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaLoopFusion]: Finished (changed=True #instances=25)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaLoopFusion]: Exit time region: delta=0.011s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaLICM]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaLICM]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaLICM]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/FactorizeBlkDims]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [FactorizeBlkDims]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/FactorizeBlkDims]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaInstComb]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaInstComb]: Finished (changed=True #instances=20)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaInstComb]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaValueNumbering]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaValueNumbering]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaValueNumbering]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerTranspose]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LowerTranspose]: Finished (changed=True #instances=34)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerTranspose]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LegalizeTongaType]: Finished (changed=True #instances=34)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/PartialLoopFusion]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [PartialLoopFusion]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/PartialLoopFusion]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ShortenLifeInterval]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [ShortenLifeInterval]: Finished (changed=True #instances=34)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ShortenLifeInterval]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/GlobalBatchOpt]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [GlobalBatchOpt]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/GlobalBatchOpt]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SpillPSum]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [SpillPSum]: Finished (changed=True #instances=38)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SpillPSum]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaType]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LegalizeTongaType]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaType]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/InferPSumTensor]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [InferPSumTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/InferPSumTensor]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/VectorizeMatMult]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [VectorizeMatMult]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/VectorizeMatMult]: Exit time region: delta=0.004s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/WeightCoalescing]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [WeightCoalescing]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/WeightCoalescing]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerPartitionTile]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LowerPartitionTile]: Finished (changed=True #instances=50)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerPartitionTile]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/BroadcastWeights]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [BroadcastWeights]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/BroadcastWeights]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaAccess]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LegalizeTongaAccess]: Finished (changed=True #instances=51)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizeTongaAccess]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaAffineLoopXform]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TongaAffineLoopXform]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TongaAffineLoopXform]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/RelaxPredicates]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [RelaxPredicates]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/RelaxPredicates]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TensorInitialization]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [TensorInitialization]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/TensorInitialization]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ExpandISAMacro]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [ExpandISAMacro]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ExpandISAMacro]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizePartitionTile]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LegalizePartitionTile]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LegalizePartitionTile]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SimplifyTongaTensor]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [SimplifyTongaTensor]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/SimplifyTongaTensor]: Exit time region: delta=0.010s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LinearizeFreeDim]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LinearizeFreeDim]: Finished (changed=True #instances=51)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LinearizeFreeDim]: Exit time region: delta=0.006s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/DataStreaming]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [DataStreaming]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/DataStreaming]: Exit time region: delta=0.005s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ILPOpt]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [ILPOpt]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/ILPOpt]: Exit time region: delta=0.036s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/StaticProfiler]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [StaticProfiler]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/StaticProfiler]: Exit time region: delta=0.009s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerAPIndices]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LowerAPIndices]: Finished (changed=True #instances=36)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerAPIndices]: Exit time region: delta=0.012s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerMisc]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [LowerMisc]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/LowerMisc]: Exit time region: delta=0.003s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/BirCodeGenLoop]: Enter time region\n",
      "06/11/2023 03:07:46 PM INFO 2907 [BirCodeGenLoop]: Finished (changed=False)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [sg00/Tensorizer/BirCodeGenLoop]: Exit time region: delta=0.007s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Tensorizer]: IR signature: 6138c182415c06cc09bceea59192af0b57f4f8349950256b0b680d726886dfe8 for sg00/Tensorizer\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Tensorizer]: Weights total number of bytes: 133136\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Tensorizer]: Finalize\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]: --- Penguin Statistics ---\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  AffinePredicateResolution  Number of const tensor evaluated from predicate values\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  AutoCastTCInputs  Tensor shrink for matmult down-cast (in bytes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  BroadcastWeights  Number of matmults inserted to broadcast weights\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  CommuteConcat     Number of concat operand commuted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  CommuteConcat     Number of concat operand distributed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ConcatLoopFusion  Number of concat loops fused\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                8  DTypeMutator      Number of bytes statically casted in weight tensor\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  DTypeMutator      Number of load whose tensor type mutated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  DTypeMutator      Number of operator whose dst type is mutated for legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  DataLocalityOpt   Number of deferred flush inserted for DMA write\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  DataLocalityOpt   Number of delinearized weight by rewriting\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DataLocalityOpt   Number of prefetch failed due to isl codegen\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  DataLocalityOpt   Number of prefetch inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DataLocalityOpt   Number of tranposes skipped because of illegal partition address\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DataLocalityOpt   Number of transpose inserted for DMA write\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeConcat          Number of concat operand distributed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeadStoreElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeadStoreElimination  Number of iteration eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeadStoreElimination  Number of loops eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeadStoreElimination  Number of strided axes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DeadStoreElimination  Number of tensors eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DelinearizationBase  Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                6  DelinearizationBase  Number of tensors delinearized\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  DotTransform      Number of times a transformation rollback due to transformation crash\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  EliminateDivs     Number of axes tiled to eliminate div/mod\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  EliminateDivs     Number of div/mod with offset\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ExpandISAMacro    Number of per-partition bytes copy for tensor-tensor legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ExpandISAMacro    Number of sbatomload/sbatomstore expand\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ExpandISAMacro    Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                8  FlattenMacroLoop  Number of axes coalesced\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                8  FlattenMacroLoop  Number of tensors reshaped\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  GlobalLayoutOpt   Number of BFTransposes inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  GlobalLayoutOpt   Number of PFTransposes inserted for IO tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  GlobalLayoutOpt   Number of dmas needed for transpose\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferNonLocalTensor  num of non-local tensors infered\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferPSumTensor   Number of bytes copied to psum per-partition\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferPSumTensor   Number of instructions whose result inferred into PSUM\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferPSumTensor   Number of psum copy instructions inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferPSumTensor   Number of total bytes inferred into PSUM\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferStaticWeight  Number of bytes allocated as static allocation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                6  InferTongaTensor  Number of local tensor inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferTongaTensor  Number of tensors that can not be inferred as local because of the non-compatible access pattern\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferTongaTensor  Number of tensors that cannot be inferred as local because their size cannot fit in\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferTongaTensor  Total Number of bytes of non-compatible tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  InferTongaTensor  Total Number of bytes of tensors with large tile size\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:            20016  InferTongaTensor  Total number of bytes of local tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  IntegerSetWrapper  Number of times compute_quota exceed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  IslSimplifier     Number of iteration eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  IslSimplifier     Number of loops eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  IslSimplifier     Number of predicate eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  IslSimplifier     Number of strided axes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  LayoutAnalysis    Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for Activation legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for MatMul legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad SB address legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomLoad legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave SB address legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for SBAtomSave legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorScalarPtr legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of per-partition bytes copy for TensorTensor legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of tensor reshaped to legalize the ptr operand of the tensorscalarptr\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaAccess  Number of total per-partition bytes copy/cast for legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaMacro  Explicit psum copy because of too many partitions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast at the producer instructions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LegalizeTongaType  Number of bytes copy/cast for legalization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in psumbuffer\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LinearScanAllocator  Number of bytes allocated in statebuffer\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LinearScanAllocator  PSumbuffer utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LinearScanAllocator  Statebuffer utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                5  LoopFusion        Number of loops fused\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  LoopFusion        Number of trivial copy eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LowerPartitionTile  Number of broadcast buffer shrink\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  LowerPartitionTile  Number of matmult instruction lowered\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  LowerPartitionTile  Number of tonga instruction (except matmult) lowered\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  LowerTranspose    Number of lossless transpose generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  LowerTranspose    Number of lossless transpose with bitcast generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                3  LowerTranspose    Number of lossy transpose generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MPDLoopFusion     Missed loop fusions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of matmul fused among contract axes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of matmul fused among rows\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of matmul operand copy\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of matmul operand extend inplace\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MatMultCombiner   Number of weight fused for matmul fusion\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:             6144  MemcpyElimination  Number of bytes copied by memcpy\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of bytes eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of cast inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of failure in access folding\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of memcopy eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of quasi affine expr generated during addr rewrite\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemcpyElimination  Number of simple dag moved\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemoryProfiler    Estimated peak psum utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  MemoryProfiler    Estimated peak statebuffer utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                3  ModDivDelinear    Number of loops tiled by delinearization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ModDivDelinear    Number of tensors delinearized\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ModuloAllocation  Number of dma for prefetch buffer moved\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  ModuloAllocation  Number of parallel loops generated by modulo buffer allocation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PadElimination    Number of padding eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PartialLoopFusion  Number of instruction rematerialized\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PartialLoopFusion  Number of loops fused\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PartialLoopFusion  Number of loops fused with loop-carried dependencies\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PolyhedralInterfereGraph  Number of inplace replacement pairs identified\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  PreScheduler      Number of instruction moved to shorten live-interval\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  PrefetchAllocation  Number of inputs/weights prefetched\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of channel-wise prelu inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of gelu (tanh approximated) inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of gelu inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of mish inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of prelu inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of rsqrt inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RecognizeOpIdiom  Number of softplus inferred\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  Recompute         Number of bytes recomputed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  Recompute         Number of flops recomputed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RelaxPredicates   Number of predicates dropped\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:             3072  RelayFE           Number of MAC count in relay\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:            22688  RelayFE           Number of total read bytes of FMAP and weight in relay\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  ReshapeWeights    Number of weights being reshaped into 2-D array\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ResolveAccessConflict  Number of dag splitted to resolve access conflict\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ResolvePredicates  Number of subdomain generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RetileSIMDMacro   Number of SIMD macro retiled to match size of psum\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RewriteReplicationMatmul  Number of replication access generated for matmul\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  RewriteReplicationMatmul  Number of software replication generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  SimplifyTensorBase  Number of dead stores deleted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                3  SimplifyTensorBase  Number of tensors simplified\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  SimplifyTensorBase  Number of tensors splitted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                3  SimplifyTensorBase  Number of tensors squeezed\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:             6144  SpillPSum         Number of total per-partition bytes spilled from psum to sb\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  SplitAccGrp       Number of accumulation groups splitted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  SplitFreeDim      Number of tensors whose blocks are further split\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  SplitUnionSets    Number of subdomain generated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           4.9789  StaticProfiler    Arithmetic intensity\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           4.9789  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding gather weight tensor)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:          26.8232  StaticProfiler    Arithmetic intensity upper bound if we only load/store I/O tensors once (excluding weights)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           4.9789  StaticProfiler    Arithmetic intensity without non-local tensor loads\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:          26.8232  StaticProfiler    Arithmetic intensity without weights and non-local loads\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:         708.5000  StaticProfiler    Average dma length per-partition\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:        1284.0000  StaticProfiler    Average dma length per-partition (exclude weights)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:          36.7063  StaticProfiler    Average partition utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           3.1327  StaticProfiler    Average pe (systolic array) utilization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:             2048  StaticProfiler    Biggest tensor tile size in StateBuffer/PSum\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           0.0003  StaticProfiler    Matmul compute efficiency: (Relay MAC counts/128/64/2) / (Total elements per partition)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               17  StaticProfiler    Num of matmul transpose instructions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           413292  StaticProfiler    Number of arithmetic computation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by activation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by gettensorptr\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           413280  StaticProfiler    Number of arithmetic computation by matmul\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by reciprocal\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorreduce\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensorscalar\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               12  StaticProfiler    Number of arithmetic computation by tensorscalarptr\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of arithmetic computation by tensortensor\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:            15408  StaticProfiler    Number of bytes moved by tensor copy and shuffle\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:            67600  StaticProfiler    Number of bytes of weights loaded\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:              532  StaticProfiler    Number of bytes of weights loaded in partition 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:            83008  StaticProfiler    Number of bytes transfer between ddr and local memory\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                5  StaticProfiler    Number of dma whose length is smaller than 512 bytes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  StaticProfiler    Number of dma whose length is smaller than 512 bytes (exclude weights)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               19  StaticProfiler    Number of matmul instructions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                6  StaticProfiler    Number of tensorcopy after transpose\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                6  StaticProfiler    Number of tensorcopy from psum\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                8  StaticProfiler    Number of tensorcopy instructions\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  StaticProfiler    Number of tensorcopy to psum\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               52  StaticProfiler    Number of total dynamic instances of tonga instructions (number of instructions after unroll)\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           2.3584  StaticProfiler    Utilized psum size / Max psum size\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:         100.0000  StaticProfiler    io tensor size / ddr transfer size ignoring nonlocal/gather tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TensorInitialization  Number of explicit initialization inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingForNewLayout  Number of inherit tiles\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingForNewLayout  Number of instructions after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingForNewLayout  Number of places global layout clobbered\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:          56.6840  TilingProfiler    Average partition utilization calculated after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:           6.2500  TilingProfiler    Average pe (systolic array) utilization calculated after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of insts from dmas after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of insts from gather/scatter after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  TilingProfiler    Number of insts from matmults after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               11  TilingProfiler    Number of insts from pf transposes after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               11  TilingProfiler    Number of insts from pf transposes for IO tensors after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for local tensors after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of insts from pf transposes for nonlocal tensors after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of insts from reduce macros after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of non-IO DRAM tensor after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  TilingProfiler    Number of pf transposes\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  TilingProfiler    Number of pf transposes for IO tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of pf transposes for local tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TilingProfiler    Number of pf transposes for nonlocal tensors\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:               18  TilingProfiler    Number of total insts after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaCpyElim      Number of failure in access folding\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  TongaCpyElim      Number of tensor copy/cast eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of bias_add combined to activation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of result of boolean computation shrink\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of scale combined to activation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of tensorscalar fold into tensorscalarptr\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of tensortensor add replace by psum accumulation\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaInstComb     Number of transpose pairs folded\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                5  TongaInstComb     Number of trivial access pattern eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaLICM         Number of instruction hoisted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaLICM         Number of instruction sunk\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaLayoutGroupAnalysis  Number of loopnests (DAGs) whose tensors layout are not propagated but re-calculated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                2  TongaLoopFusion   Number of loops fused\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaLoopFusion   Number of matmul fused for psum locality\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  TongaSizeTiling   Number of inherit tiles\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaSizeTiling   Number of instructions after tiling\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                1  TongaSizeTiling   Number of places global layout clobbered\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaValueNumbering  Number of instructions deleted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TongaValueNumbering  Number of tensors deleted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TransformLayoutPass  Number of static layout transforms on input/outputs\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                4  TransformLayoutPass  Number of transpose inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TransformLayoutPass  Number of transpose insertions failed because of predicates\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  TransformLayoutPass  Number of unknown transpose inserted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  VDNSPrep          Number of tensor rewritten for virtual node splitting\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ValueNumbering    Number of instructions deleted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  ValueNumbering    Number of tensors deleted\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                5  Vectorizer        Number of instruction vectorized\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  WeightCoalescing  Number of empty loopnest eliminated\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  WeightCoalescing  Number of load instruction merged\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:             4104  WeightRewriter    Number of bytes re-written for weights\n",
      "06/11/2023 03:07:46 PM INFO 2907 [Statistics]:                0  WeightRewriter    Number of bytes reused for weight rewrite\n",
      "06/11/2023 03:07:46 PM INFO 2907 [root/Tensorizer/All]: Exit time region: delta=1.290s\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Frontend.4]: wrote bir.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Frontend.4]: wrote tensor_map.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Frontend.4]: End tensorization\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Frontend.4]: Job finished\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Finished job job.Frontend.4 with state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Starting job job.HHChecker.0 state state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.HHChecker.0]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/sg00\", \"state_id\": \"sg00\"}' --pipeline HHChecker\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.HHChecker.0]: Job finished\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Finished job job.HHChecker.0 with state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Starting job job.WalrusDriver.3 state state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.WalrusDriver.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"bir.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/sg00\", \"state_id\": \"sg00\"}' --pipeline WalrusDriver\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.WalrusDriver.3]: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/starfish/bin/walrus_driver --state-numerical-id=0 --optlevel 2 --allocator coloring --verbose 20 -o walrus_bir.out.json -i bir.json --min_split_size 10240 --skip_split_vns  --no_split_dram --max-partitions 1 --policy 2 --auxflag 0 --interleave none --internal-hyper-parameters /opt/ml/input/config/hyperparameters.json --tuning 2 --numcores 1 --unified-walrus-and-stargazer --tensor-map tensor_map.json --act-root-json /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/neuroncc/pwp/pwp_bin_with_ln/act_info.json\n",
      "Analyzing dependencies of sg00/Block1\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.WalrusDriver.3]: IR signature: bf646ed1b53f8ccd0f21efac6365cd9a5982f8058f8246d2c430b857442b57e2 for sg00/walrus_bir.out.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.WalrusDriver.3]: Job finished\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Finished job job.WalrusDriver.3 with state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Starting job job.Backend.3 state state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/sg00\", \"state_id\": \"sg00\"}' --pipeline Backend --enable-experimental-bir-backend\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: b524189dfa7033a52ff9ab1f0b00255031a38ca8c517df8086aa8e2642b92168 for sg00/wavegraph-bin.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: cb2e561f353b967c9cec6e6af07eab09717dae01ab90d293dd80652e794e9f48 for sg00/def.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: 7d955c5c3a9adb8e1c4f5eddf55976919efd7483195df11f0430972f2a8cbbcd for sg00/TrivNet-pe.bin\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: 5ead06b7d7042f96493f731be818e73408f6e3de3debecb2cb78b76fd997ef9f for sg00/pe.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: 64afda9d41f1e294f5aa607f15b052920abf5b5931b6e281208991e730265805 for sg00/TrivNet-pool.bin\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: 7b691461cf671c98b023f65568cf4b49083b8eda35042fe187dc9ae37426de7b for sg00/pool.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 for sg00/TrivNet-act.bin\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: IR signature: c31126b76a65f91aba902e4daa3cebc9524160936a995076a7bea8f841599aa6 for sg00/act.json\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Backend.3]: Job finished\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Finished job job.Backend.3 with state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [pipeline.compile.0]: Starting job job.Kelper.2 state state 0\n",
      "06/11/2023 03:07:46 PM INFO 2907 [job.Kelper.2]: Replay this job by calling: /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/bin/neuron-cc compile --framework TENSORFLOW --state '{\"model\": [\"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.pb\"], \"tensormap\": \"tensor_map.json\", \"bir\": \"walrus_bir.out.json\", \"wavegraph\": \"wavegraph-bin.json\", \"state_dir\": \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/sg00\", \"state_id\": \"sg00\"}' --pipeline Kelper\n",
      "06/11/2023 03:07:46 PM WARNING 2907 [job.Kelper.2]: writeKelp missing file sg00/nn_def.json\n",
      "06/11/2023 03:07:47 PM WARNING 2907 [job.Kelper.2]: writeKelp missing file sg00/kelf.json\n",
      "06/11/2023 03:07:47 PM INFO 2907 [job.Kelper.2]: neuroncc version is 1.15.0.0+eec0c3604, neff version is 1.0 (features 0)\n",
      "06/11/2023 03:07:47 PM INFO 2907 [job.Kelper.2]: wrote /home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/graph_def.neff\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.compile.0]: Finished job job.Kelper.2 with state 0\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.compile.0]: Finished pipeline compile\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.compile.0]: Job finished\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.custom.0]: Finished job pipeline.compile.0 with state 0\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.custom.0]: Starting job job.SaveTemps.0 state state 0\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.custom.0]: Finished job job.SaveTemps.0 with state 0\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.custom.0]: Finished pipeline custom\n",
      "06/11/2023 03:07:47 PM INFO 2907 [pipeline.custom.0]: Job finished\n",
      "06/11/2023 03:07:47 PM INFO 2907 [root]: Compiler status PASS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: max_allowed_parallelism=24\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: unroll\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to unroll: modules=1 functions=1 allocs=26 blocks=1 instructions=20\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (Unroll) Start unrolling at Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (Unroll) DONE unrolling Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Instruction count after Unroll: \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Total count: 36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Matmult: 19\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: TensorCopy: 8\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Load: 6\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Save: 2\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: TensorScalarPtr: 1\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: unroll succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: vn_splitter\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to vn_splitter: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Collected all the internal vnodes: size = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Done with analyze and splitting: total dead nodes = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (ShrinkDN): shrinkDN identity_local_148\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (ShrinkDN): Shrunk 1 nodes. Total savings 248 bytes/partition\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused reload left 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: number of penguin non-local-tensor caused spill left 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (VNSplitter) Time: 0 seconds\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (VerticalFusion) Time: 0 seconds\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (ShrinkDN) Time: 0 seconds\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (LowerAC) Time: -0.001 seconds\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: vn_splitter succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: lower_ac\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to lower_ac: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO (LowerAC) Lowered 6 loads, 2 saves, 0 copies.\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: lower_ac succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: pre_sched\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to pre_sched: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start PRE scheduling 2 cores:  1 at: Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start split live ranges Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End split live ranges Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Strt remove redundncies Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End remove redundncies Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start DCE Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End DCE Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start build flow dependencies Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End build flow dependencies Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start remove useless insts Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End remove useless insts Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Preserving incoming order, level goes down to 1.\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: Start Load Cloning Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: End Load Cloning Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheWalrusPreScheduler.0]: DONE PRE scheduling Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: pre_sched succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: coloring_allocator\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to coloring_allocator: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: GCA DRAM bytes loaded or saved 50272\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: GCA average DMA size 182 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Allocating functions\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:   linearize and check\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:   allocating PSUM\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:     renumber locations\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         size = 5\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         bit-matrix size = 2 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: 25% PSUM demand before spilling\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           PSUM high-water mark = 1 tensors\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         found 0 edges\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         adjacency vectors require 0 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           initialize low and high\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             lo = 5\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             hi = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             inf = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             total = 5\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           no more spills\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         PSUM score = 0 (lower is better)\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: spilling from PSUM cost about 0 cycles\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: 25% PSUM utilization after allocation\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:   allocating SB\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:     main loop\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       renumber locations\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         size = 13\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       find partners\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         found 5 accumulation groups\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           largest = 2:0_t138\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             tensors = 2\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             requires 1280 bytes/partition\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       expanding partners\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       find first defs\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       find loads\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         4 pin count\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         0 remat count\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         4 pinned tensors will require about 280 bytes/partition\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       build interference graph\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         bit-matrix size = 11 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         pass 1\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: 1% SB demand before allocation\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           SB high-water mark = 1320 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             1320 bytes in partitions [0, 31]\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             1320 bytes in partitions [32, 63]\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             1320 bytes in partitions [64, 95]\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             1320 bytes in partitions [96, 127]\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         pass 2\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         found 48 edges\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         adjacency vectors require 384 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       find costs\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       best-of-n loop, heuristic = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         simplify interference graph\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           initialize safe & unsafe\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:               safe = 13\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             unsafe = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:                inf = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:       preallocated = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:              total = 13\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           simplify\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:             new candidates = 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         select ranges\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:           success\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]:         SB score = 0\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: spilling from SB cost about 0 cycles\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: 280 bytes/partition (100%) successfully pinned\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: pinning saved approximately 5486 cycles\n",
      "06/11/2023 03:07:46 PM WARNING [WalrusDriver.0]: 1% SB utilization after allocation\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: coloring_allocator succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: dma_optimization\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to dma_optimization: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 5 PSUM Banks, reduced 1 consecutive Matmul Accumulation group dst PSUM Allocation \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive Activation source PSUM Allocation \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: PSUM Rotation rotated 0 PSUM Banks, reduced 0 consecutive DVE engine source/dst PSUM Allocation \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: DMA optimization In bytes loaded or saved 50272, 87.683% input load, 12.317% output write, 0% spill/reload \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Load Merging]: removed 0 GCA remat/cloned instructions\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Load Merging] reduced input/const loading DMA traffic 0, 0% out of total input/const loading dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Allocation optimization]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Re-allocation Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload instructions\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [spill optimization round 0]: removed 0 spill/reload memory locations\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Spill Optimization] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [DMA optimization] reduced DMA traffic 0, 0% out of total dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: DMA optimization Out bytes loaded or saved 50272, 87.683% input load, 12.317% output write, 0% spill/reload \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes loaded 44080\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average loaded DMA size 163 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes saved 6192\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average saved DMA size 1032 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization DRAM bytes DMAcopyed 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA optimization average DMAcopyed DMA size 0 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: [Experiment partial DMA access] reduced DMA traffic 0, -nan% out of total spill/reload dma traffic\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: DMA SpillSave Coalescing Round 0 combined 0 SpillSaves and Reloads\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes loaded 44080\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average loaded DMA size 163 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing DRAM bytes saved 6192\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: INFO: Post DMA coalescing average saved DMA size 1032 bytes\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive SpillSave overlapping address \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Load overlapping address \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: SB Rotation rotated 0 Sb address, reduced 0 consecutive Any overlapping address \n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Reload number 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Spill number 0\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: DMA optimization enable optimization\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: dma_optimization succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: build_fdeps\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to build_fdeps: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: build_fdeps succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: remove_redundancies\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to remove_redundancies: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: remove_redundancies succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: anti_dependency_analyzer\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to anti_dependency_analyzer: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: anti_dependency_analyzer succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: post_sched\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to post_sched: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [TheScheduler.0]: Start PosT ScheD 2 inferentia Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [TheScheduler.0]: Done  PosT ScheD Sun Jun 11 15:07:46 2023\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: post_sched succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: tensorcopy_accel\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to tensorcopy_accel: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running peephole optimization pass\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: tensorcopy_accel succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: birverifier\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to birverifier: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: birverifier succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Running walrus pass: run_stargazer\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Input to run_stargazer: modules=1 functions=1 allocs=26 blocks=1 instructions=36\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Stargazer starts [in memory BIR module]\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Current working directory: \"/home/ec2-user/SageMaker/ssh/scrub/compilation_artifacts/133/sg00\"\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Generating Arch 'Inferentia-1.0'\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: INFO: Pre SG DRAM bytes loaded or saved 50272\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: INFO: Pre SG average DMA size 182 bytes\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Loads in Func = 6\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Saves in Func = 2\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Input Loads in Func= 6\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Output Saves in Func= 2\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Spill Loads in Func= 0\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Num Spill Saves in Func= 0\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Wavegraph code generation for Inferentia:\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]:     Engine              File\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]:     ------              ----\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]:     PE-Array            pe.bin\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]:     Pool-Eng            pool.bin\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]:     Act-Eng             act.bin\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: \n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Fixing data race is 0\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: [Sailfish] Data race analysis initially\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: [Sailfish] Data race analysis found no races, run time: 0:00:00\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: [Sailfish] Remove redundant edges\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Data race checker engines\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Transitive reduction start \n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Transitive reduction removed 0 redundant edges, time: 0:00:00\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Sync Critical Load Chains Start\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Sync Critical Load Chains added 0 new Load-2-Load syncs\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Sync Critical Load Chains Done.0:00:00\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Out wavegraph bin file is wavegraph-bin.json\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Writing NN JSON to file 'wavegraph-bin.json'\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: Virtual memory peak = 4356384 K bytes\n",
      "06/11/2023 03:07:46 PM INFO [Stargazer.0]: PASSED - Total time: 0:00:00\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: ru_maxrss:  1605mb (delta=0mb)\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Walrus pass: run_stargazer succeeded!\n",
      "06/11/2023 03:07:46 PM INFO [WalrusDriver.0]: Output has 1 module(s), 1 function(s), 26 memory location(s), 1 block(s), and 36 instruction(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Neuron:Number of arithmetic operators (post-compilation) before = 582, compiled = 86, percent compiled = 14.78%\n",
      "INFO:Neuron:The neuron partitioner created 25 sub-graphs\n",
      "INFO:Neuron:Neuron successfully compiled 15 sub-graphs, Total fused subgraphs = 25, Percent of model sub-graphs successfully compiled = 60.0%\n",
      "INFO:Neuron:Compiled these operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 11\n",
      "INFO:Neuron: => aten::ScalarImplicit: 3\n",
      "INFO:Neuron: => aten::add: 2\n",
      "INFO:Neuron: => aten::arange: 3\n",
      "INFO:Neuron: => aten::expand: 1\n",
      "INFO:Neuron: => aten::linear: 1\n",
      "INFO:Neuron: => aten::min: 1\n",
      "INFO:Neuron: => aten::mul: 3\n",
      "INFO:Neuron: => aten::reshape: 1\n",
      "INFO:Neuron: => aten::select: 9\n",
      "INFO:Neuron: => aten::size: 11\n",
      "INFO:Neuron: => aten::slice: 18\n",
      "INFO:Neuron: => aten::sub: 1\n",
      "INFO:Neuron: => aten::to: 9\n",
      "INFO:Neuron: => aten::unsqueeze: 3\n",
      "INFO:Neuron: => aten::view: 6\n",
      "INFO:Neuron: => aten::zeros: 3\n",
      "INFO:Neuron:Not compiled operators (and operator counts) to Neuron:\n",
      "INFO:Neuron: => aten::Int: 60 [supported]\n",
      "INFO:Neuron: => aten::ScalarImplicit: 9 [supported]\n",
      "INFO:Neuron: => aten::add: 24 [supported]\n",
      "INFO:Neuron: => aten::add_: 9 [supported]\n",
      "INFO:Neuron: => aten::arange: 9 [supported]\n",
      "INFO:Neuron: => aten::argmax: 1 [supported]\n",
      "INFO:Neuron: => aten::bitwise_not: 1 [supported]\n",
      "INFO:Neuron: => aten::broadcast_tensors: 2 [supported]\n",
      "INFO:Neuron: => aten::contiguous: 4 [supported]\n",
      "INFO:Neuron: => aten::detach: 7 [supported]\n",
      "INFO:Neuron: => aten::div: 5 [supported]\n",
      "INFO:Neuron: => aten::div_: 4 [supported]\n",
      "INFO:Neuron: => aten::dropout: 14 [supported]\n",
      "INFO:Neuron: => aten::einsum: 2 [supported]\n",
      "INFO:Neuron: => aten::embedding: 9 [not supported]\n",
      "INFO:Neuron: => aten::eq: 4 [supported]\n",
      "INFO:Neuron: => aten::expand: 11 [supported]\n",
      "INFO:Neuron: => aten::floor: 2 [supported]\n",
      "INFO:Neuron: => aten::fmod: 2 [not supported]\n",
      "INFO:Neuron: => aten::gather: 2 [not supported]\n",
      "INFO:Neuron: => aten::gelu: 4 [supported]\n",
      "INFO:Neuron: => aten::index_put_: 3 [not supported]\n",
      "INFO:Neuron: => aten::layer_norm: 9 [supported]\n",
      "INFO:Neuron: => aten::linear: 25 [supported]\n",
      "INFO:Neuron: => aten::logical_and: 1 [supported]\n",
      "INFO:Neuron: => aten::lt: 4 [supported]\n",
      "INFO:Neuron: => aten::matmul: 8 [supported]\n",
      "INFO:Neuron: => aten::min: 2 [supported]\n",
      "INFO:Neuron: => aten::mul: 19 [supported]\n",
      "INFO:Neuron: => aten::ones: 3 [supported]\n",
      "INFO:Neuron: => aten::permute: 16 [supported]\n",
      "INFO:Neuron: => aten::prod: 7 [not supported]\n",
      "INFO:Neuron: => aten::repeat: 3 [supported]\n",
      "INFO:Neuron: => aten::reshape: 6 [supported]\n",
      "INFO:Neuron: => aten::rsub: 2 [supported]\n",
      "INFO:Neuron: => aten::scatter_add_: 8 [not supported]\n",
      "INFO:Neuron: => aten::select: 3 [supported]\n",
      "INFO:Neuron: => aten::size: 55 [supported]\n",
      "INFO:Neuron: => aten::slice: 7 [supported]\n",
      "INFO:Neuron: => aten::softmax: 4 [supported]\n",
      "INFO:Neuron: => aten::tanh: 1 [supported]\n",
      "INFO:Neuron: => aten::to: 65 [supported]\n",
      "INFO:Neuron: => aten::transpose: 4 [supported]\n",
      "INFO:Neuron: => aten::unsqueeze: 9 [supported]\n",
      "INFO:Neuron: => aten::view: 39 [supported]\n",
      "INFO:Neuron: => aten::where: 1 [not supported]\n",
      "INFO:Neuron: => aten::zeros: 5 [supported]\n",
      "INFO:Neuron: => aten::zeros_like: 2 [supported]\n",
      "WARNING:Neuron:torch.neuron.trace was unable to compile > 50% of the operators in the compiled model!\n",
      "WARNING:Neuron:Please review the torch.neuron.analyze_model output and if you believe you are seeing a failure\n",
      "WARNING:Neuron:Lodge an issue on https://github.com/aws/aws-neuron-sdk/issues if you believe the model is not compiling as expected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.torch_neuron.runtime.___torch_mangle_229.AwsNeuronGraphModule,\n",
      "      %63 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %tensor.1 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %tensor.9 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu)):\n",
      "  %_NeuronGraph#133 : __torch__.torch_neuron.decorators.___torch_mangle_228.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#133\"](%self.1)\n",
      "  %_NeuronGraph#121 : __torch__.torch_neuron.decorators.___torch_mangle_227.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#121\"](%self.1)\n",
      "  %_NeuronGraph#114 : __torch__.torch_neuron.decorators.___torch_mangle_226.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#114\"](%self.1)\n",
      "  %_NeuronGraph#108 : __torch__.torch_neuron.decorators.___torch_mangle_225.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#108\"](%self.1)\n",
      "  %_NeuronGraph#104 : __torch__.torch_neuron.decorators.___torch_mangle_224.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#104\"](%self.1)\n",
      "  %_NeuronGraph#102 : __torch__.torch_neuron.decorators.___torch_mangle_223.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#102\"](%self.1)\n",
      "  %_NeuronGraph#100 : __torch__.torch_neuron.decorators.___torch_mangle_222.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#100\"](%self.1)\n",
      "  %_NeuronGraph#54 : __torch__.torch_neuron.decorators.___torch_mangle_221.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#54\"](%self.1)\n",
      "  %_NeuronGraph#48 : __torch__.torch_neuron.decorators.___torch_mangle_220.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#48\"](%self.1)\n",
      "  %_NeuronGraph#42 : __torch__.torch_neuron.decorators.___torch_mangle_219.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#42\"](%self.1)\n",
      "  %_NeuronGraph#36 : __torch__.torch_neuron.decorators.___torch_mangle_218.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#36\"](%self.1)\n",
      "  %_NeuronGraph#30 : __torch__.torch_neuron.decorators.___torch_mangle_217.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#30\"](%self.1)\n",
      "  %_NeuronGraph#24 : __torch__.torch_neuron.decorators.___torch_mangle_216.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#24\"](%self.1)\n",
      "  %_NeuronGraph#18 : __torch__.torch_neuron.decorators.___torch_mangle_215.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#18\"](%self.1)\n",
      "  %_NeuronGraph#0 : __torch__.torch_neuron.decorators.NeuronModuleV2 = prim::GetAttr[name=\"_NeuronGraph#0\"](%self.1)\n",
      "  %model.1 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#0)\n",
      "  %2345 : Tensor[] = prim::ListConstruct(%63), scope: __module._NeuronGraph#0\n",
      "  %2346 : Long(requires_grad=0, device=cpu), %2347 : Long(1536, strides=[1], requires_grad=0, device=cpu) = neuron::forward_v2_2(%2345, %model.1), scope: __module._NeuronGraph#0 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %2348 : (Long(1536, strides=[1], requires_grad=0, device=cpu), Long(requires_grad=0, device=cpu)) = prim::TupleConstruct(%2347, %2346)\n",
      "  %2315 : Long(1536, strides=[1], requires_grad=0, device=cpu), %2316 : Long(requires_grad=0, device=cpu) = prim::TupleUnpack(%2348)\n",
      "  %69 : Long(1, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value={3}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %70 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %71 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %72 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %73 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %74 : NoneType = prim::Constant()\n",
      "  %75 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::to(%69, %70, %71, %72, %73, %74) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %76 : Long(1, strides=[1], requires_grad=0, device=cpu) = aten::detach(%75) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %77 : NoneType = prim::Constant()\n",
      "  %78 : Long(requires_grad=0, device=cpu) = aten::prod(%76, %77) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %79 : Float(30522, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %80 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %81 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %82 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %83 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%79, %63, %80, %81, %82) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.3 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#18)\n",
      "  %2350 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#18\n",
      "  %2351 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2350, %model.3), scope: __module._NeuronGraph#18 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %86 : Float(3, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %87 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %88 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %89 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %90 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%86, %2351, %87, %88, %89) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.5 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#24)\n",
      "  %2353 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#24\n",
      "  %2354 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2353, %model.5), scope: __module._NeuronGraph#24 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %93 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %94 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %95 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %96 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %97 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%93, %2354, %94, %95, %96) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.7 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#30)\n",
      "  %2356 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#30\n",
      "  %2357 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2356, %model.7), scope: __module._NeuronGraph#30 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %100 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %101 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %102 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %103 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %104 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%100, %2357, %101, %102, %103) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.9 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#36)\n",
      "  %2359 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#36\n",
      "  %2360 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2359, %model.9), scope: __module._NeuronGraph#36 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %107 : Float(2, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %108 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %109 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %110 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %111 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%107, %2360, %108, %109, %110) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.11 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#42)\n",
      "  %2362 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#42\n",
      "  %2363 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2362, %model.11), scope: __module._NeuronGraph#42 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %114 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %115 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %116 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %117 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %118 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%114, %2363, %115, %116, %117) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.13 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#48)\n",
      "  %2365 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#48\n",
      "  %2366 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2365, %model.13), scope: __module._NeuronGraph#48 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %121 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %122 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %123 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %124 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %125 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%121, %2366, %122, %123, %124) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.15 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#54)\n",
      "  %2368 : Tensor[] = prim::ListConstruct(%tensor.9), scope: __module._NeuronGraph#54\n",
      "  %2369 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2368, %model.15), scope: __module._NeuronGraph#54 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %128 : Float(10, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %129 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %130 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %131 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %132 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%128, %2369, %129, %130, %131) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.17 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#100)\n",
      "  %2371 : Tensor[] = prim::ListConstruct(%tensor.9, %78), scope: __module._NeuronGraph#100\n",
      "  %2372 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu), %2373 : Long(1536, strides=[1], requires_grad=0, device=cpu) = neuron::forward_v2_2(%2371, %model.17), scope: __module._NeuronGraph#100 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %2374 : (Long(1536, strides=[1], requires_grad=0, device=cpu), Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%2373, %2372)\n",
      "  %2319 : Long(1536, strides=[1], requires_grad=0, device=cpu), %2320 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%2374)\n",
      "  %196 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %197 : NoneType = prim::Constant()\n",
      "  %198 : int = prim::Constant[value=196608]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %199 : Long(196608, strides=[1], requires_grad=0, device=cpu), %200 : Long(196608, strides=[1], requires_grad=0, device=cpu) = torch_scatter::scatter_min(%2315, %2319, %196, %197, %198) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.19 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#102)\n",
      "  %2376 : Tensor[] = prim::ListConstruct(%199, %2320), scope: __module._NeuronGraph#102\n",
      "  %2377 : Long(3, 65536, strides=[65536, 1], requires_grad=0, device=cpu), %2378 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_2(%2376, %model.19), scope: __module._NeuronGraph#102 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %2379 : (Long(3, 65536, strides=[65536, 1], requires_grad=0, device=cpu), Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%2377, %2378)\n",
      "  %2323 : Long(3, 65536, strides=[65536, 1], requires_grad=0, device=cpu), %2324 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%2379)\n",
      "  %204 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %205 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %206 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::gather(%2323, %204, %2324, %205) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.21 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#104)\n",
      "  %2381 : Tensor[] = prim::ListConstruct(%2316, %2320, %206), scope: __module._NeuronGraph#104\n",
      "  %2382 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2381, %model.21), scope: __module._NeuronGraph#104 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %209 : Float(512, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %210 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %211 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %212 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %213 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::embedding(%209, %2382, %210, %211, %212) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %220 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %221 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %222 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %223 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %224 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.1, %220, %221, %222, %223) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %225 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %226 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %227 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %228 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %229 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::slice(%224, %225, %226, %227, %228) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %230 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %231 : Long(3, 1, 512, strides=[512, 512, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%229, %230) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %232 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.3 : Long(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%231, %232) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %246 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %247 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %248 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %249 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %250 : Long(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.3, %246, %247, %248, %249) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %251 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %252 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %253 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %254 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %255 : Long(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::slice(%250, %251, %252, %253, %254) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %256 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %257 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %258 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %259 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %260 : Long(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::slice(%255, %256, %257, %258, %259) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %261 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %262 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %263 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %264 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %tensor.5 : Long(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::slice(%260, %261, %262, %263, %264) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %266 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %267 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %268 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %269 : NoneType = prim::Constant()\n",
      "  %270 : Float(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.5, %266, %267, %268, %269) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %271 : float = prim::Constant[value=1.]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %272 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %273 : Float(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::rsub(%270, %271, %272) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %274 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %275 : Float(3, 1, 1, 512, strides=[512, 512, 512, 1], requires_grad=0, device=cpu) = aten::mul(%273, %274) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %276 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %277 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%83, %213, %276) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %278 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %279 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%277, %90, %278) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %280 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %281 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%279, %97, %280) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %282 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %283 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%281, %104, %282) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %284 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %285 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%283, %111, %284) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %286 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %287 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%285, %118, %286) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %288 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %289 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%287, %125, %288) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %290 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %291 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add_(%289, %132, %290) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %292 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %293 : int[] = prim::ListConstruct(%292)\n",
      "  %294 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %295 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %296 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %297 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %298 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%291, %293, %294, %295, %296, %297) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %299 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %300 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %301 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%298, %299, %300) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %302 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %303 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %304 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%301, %302, %303) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %305 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %306 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %307 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%301, %305, %306) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %324 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %325 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %326 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %327 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %328 : int[] = prim::ListConstruct(%324, %325, %326, %327)\n",
      "  %329 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%307, %328) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %330 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %331 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %332 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %333 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %334 : int[] = prim::ListConstruct(%330, %331, %332, %333)\n",
      "  %335 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%329, %334) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %336 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %337 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %338 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%301, %336, %337) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %355 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %356 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %357 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %358 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %359 : int[] = prim::ListConstruct(%355, %356, %357, %358)\n",
      "  %360 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%338, %359) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %361 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %362 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %363 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %364 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %365 : int[] = prim::ListConstruct(%361, %362, %363, %364)\n",
      "  %366 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%360, %365) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %383 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %384 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %385 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %386 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %387 : int[] = prim::ListConstruct(%383, %384, %385, %386)\n",
      "  %388 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%304, %387) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %389 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %390 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %391 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %392 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %393 : int[] = prim::ListConstruct(%389, %390, %391, %392)\n",
      "  %394 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%388, %393) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %395 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %396 : int = prim::Constant[value=-2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %397 : Float(3, 4, 64, 512, strides=[131072, 64, 1, 256], requires_grad=0, device=cpu) = aten::transpose(%335, %395, %396) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %398 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::matmul(%394, %397) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %399 : Double(requires_grad=0, device=cpu) = prim::Constant[value={8}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %400 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::div(%398, %399) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %401 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %402 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::add(%400, %275, %401) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %403 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %404 : NoneType = prim::Constant()\n",
      "  %405 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::softmax(%402, %403, %404) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %406 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %407 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %408 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::dropout(%405, %406, %407) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %409 : Float(3, 4, 512, 64, strides=[131072, 32768, 64, 1], requires_grad=0, device=cpu) = aten::matmul(%408, %366) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %410 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %411 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %412 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %413 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %414 : int[] = prim::ListConstruct(%410, %411, %412, %413)\n",
      "  %415 : Float(3, 512, 4, 64, strides=[131072, 64, 32768, 1], requires_grad=0, device=cpu) = aten::permute(%409, %414) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %416 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %417 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::contiguous(%415, %416) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %434 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %435 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %436 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %437 : int[] = prim::ListConstruct(%434, %435, %436)\n",
      "  %438 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::view(%417, %437) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %439 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %440 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %441 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%438, %439, %440) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %442 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %443 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %444 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%441, %442, %443) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %445 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %446 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%444, %301, %445) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %447 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %448 : int[] = prim::ListConstruct(%447)\n",
      "  %449 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %450 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %451 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %452 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %453 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%446, %448, %449, %450, %451, %452) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %454 : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %455 : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %456 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::linear(%453, %454, %455) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %457 : str = prim::Constant[value=\"none\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %458 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::gelu(%456, %457) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %459 : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %460 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %461 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%458, %459, %460) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %462 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %463 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %464 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%461, %462, %463) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %465 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %466 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%464, %453, %465) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %467 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %468 : int[] = prim::ListConstruct(%467)\n",
      "  %469 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %470 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %471 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %472 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %473 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%466, %468, %469, %470, %471, %472) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %474 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %475 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %476 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%473, %474, %475) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %477 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %478 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %479 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%473, %477, %478) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %496 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %497 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %498 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %499 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %500 : int[] = prim::ListConstruct(%496, %497, %498, %499)\n",
      "  %501 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%479, %500) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %502 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %503 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %504 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %505 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %506 : int[] = prim::ListConstruct(%502, %503, %504, %505)\n",
      "  %507 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%501, %506) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %508 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %509 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %510 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%473, %508, %509) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %527 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %528 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %529 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %530 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %531 : int[] = prim::ListConstruct(%527, %528, %529, %530)\n",
      "  %532 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%510, %531) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %533 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %534 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %535 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %536 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %537 : int[] = prim::ListConstruct(%533, %534, %535, %536)\n",
      "  %538 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%532, %537) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %555 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %556 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %557 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %558 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %559 : int[] = prim::ListConstruct(%555, %556, %557, %558)\n",
      "  %560 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%476, %559) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %561 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %562 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %563 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %564 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %565 : int[] = prim::ListConstruct(%561, %562, %563, %564)\n",
      "  %566 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%560, %565) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %567 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %568 : int = prim::Constant[value=-2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %569 : Float(3, 4, 64, 512, strides=[131072, 64, 1, 256], requires_grad=0, device=cpu) = aten::transpose(%507, %567, %568) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %570 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::matmul(%566, %569) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %571 : Double(requires_grad=0, device=cpu) = prim::Constant[value={8}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %572 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::div(%570, %571) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %573 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %574 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::add(%572, %275, %573) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %575 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %576 : NoneType = prim::Constant()\n",
      "  %577 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::softmax(%574, %575, %576) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %578 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %579 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %580 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::dropout(%577, %578, %579) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %581 : Float(3, 4, 512, 64, strides=[131072, 32768, 64, 1], requires_grad=0, device=cpu) = aten::matmul(%580, %538) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %582 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %583 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %584 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %585 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %586 : int[] = prim::ListConstruct(%582, %583, %584, %585)\n",
      "  %587 : Float(3, 512, 4, 64, strides=[131072, 64, 32768, 1], requires_grad=0, device=cpu) = aten::permute(%581, %586) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %588 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %589 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::contiguous(%587, %588) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %606 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %607 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %608 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %609 : int[] = prim::ListConstruct(%606, %607, %608)\n",
      "  %610 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::view(%589, %609) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %611 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %612 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %613 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%610, %611, %612) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %614 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %615 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %616 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%613, %614, %615) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %617 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %618 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%616, %473, %617) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %619 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %620 : int[] = prim::ListConstruct(%619)\n",
      "  %621 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %622 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %623 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %624 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %625 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%618, %620, %621, %622, %623, %624) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %626 : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %627 : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %628 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::linear(%625, %626, %627) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %629 : str = prim::Constant[value=\"none\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %630 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::gelu(%628, %629) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %631 : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %632 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %633 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%630, %631, %632) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %634 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %635 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %636 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%633, %634, %635) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %637 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %638 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%636, %625, %637) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %639 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %640 : int[] = prim::ListConstruct(%639)\n",
      "  %641 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %642 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %643 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %644 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %645 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%638, %640, %641, %642, %643, %644) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %646 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %647 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %648 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%645, %646, %647) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %649 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %650 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %651 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%645, %649, %650) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %668 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %669 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %670 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %671 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %672 : int[] = prim::ListConstruct(%668, %669, %670, %671)\n",
      "  %673 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%651, %672) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %674 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %675 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %676 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %677 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %678 : int[] = prim::ListConstruct(%674, %675, %676, %677)\n",
      "  %679 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%673, %678) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %680 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %681 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %682 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%645, %680, %681) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %699 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %700 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %701 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %702 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %703 : int[] = prim::ListConstruct(%699, %700, %701, %702)\n",
      "  %704 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%682, %703) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %705 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %706 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %707 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %708 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %709 : int[] = prim::ListConstruct(%705, %706, %707, %708)\n",
      "  %710 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%704, %709) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %727 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %728 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %729 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %730 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %731 : int[] = prim::ListConstruct(%727, %728, %729, %730)\n",
      "  %732 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%648, %731) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %733 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %734 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %735 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %736 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %737 : int[] = prim::ListConstruct(%733, %734, %735, %736)\n",
      "  %738 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%732, %737) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %739 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %740 : int = prim::Constant[value=-2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %741 : Float(3, 4, 64, 512, strides=[131072, 64, 1, 256], requires_grad=0, device=cpu) = aten::transpose(%679, %739, %740) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %742 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::matmul(%738, %741) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %743 : Double(requires_grad=0, device=cpu) = prim::Constant[value={8}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %744 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::div(%742, %743) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %745 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %746 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::add(%744, %275, %745) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %747 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %748 : NoneType = prim::Constant()\n",
      "  %749 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::softmax(%746, %747, %748) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %750 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %751 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %752 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::dropout(%749, %750, %751) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %753 : Float(3, 4, 512, 64, strides=[131072, 32768, 64, 1], requires_grad=0, device=cpu) = aten::matmul(%752, %710) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %754 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %755 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %756 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %757 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %758 : int[] = prim::ListConstruct(%754, %755, %756, %757)\n",
      "  %759 : Float(3, 512, 4, 64, strides=[131072, 64, 32768, 1], requires_grad=0, device=cpu) = aten::permute(%753, %758) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %760 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %761 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::contiguous(%759, %760) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %778 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %779 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %780 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %781 : int[] = prim::ListConstruct(%778, %779, %780)\n",
      "  %782 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::view(%761, %781) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %783 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %784 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %785 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%782, %783, %784) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %786 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %787 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %788 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%785, %786, %787) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %789 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %790 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%788, %645, %789) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %791 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %792 : int[] = prim::ListConstruct(%791)\n",
      "  %793 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %794 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %795 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %796 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %797 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%790, %792, %793, %794, %795, %796) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %798 : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %799 : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %800 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::linear(%797, %798, %799) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %801 : str = prim::Constant[value=\"none\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %802 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::gelu(%800, %801) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %803 : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %804 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %805 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%802, %803, %804) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %806 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %807 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %808 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%805, %806, %807) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %809 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %810 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%808, %797, %809) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %811 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %812 : int[] = prim::ListConstruct(%811)\n",
      "  %813 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %814 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %815 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %816 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %817 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%810, %812, %813, %814, %815, %816) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %818 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %819 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %820 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%817, %818, %819) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %821 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %822 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %823 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%817, %821, %822) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %840 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %841 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %842 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %843 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %844 : int[] = prim::ListConstruct(%840, %841, %842, %843)\n",
      "  %845 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%823, %844) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %846 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %847 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %848 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %849 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %850 : int[] = prim::ListConstruct(%846, %847, %848, %849)\n",
      "  %851 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%845, %850) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %852 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %853 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %854 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%817, %852, %853) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %871 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %872 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %873 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %874 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %875 : int[] = prim::ListConstruct(%871, %872, %873, %874)\n",
      "  %876 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%854, %875) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %877 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %878 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %879 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %880 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %881 : int[] = prim::ListConstruct(%877, %878, %879, %880)\n",
      "  %882 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%876, %881) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %899 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %900 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %901 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %902 : int = prim::Constant[value=64]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %903 : int[] = prim::ListConstruct(%899, %900, %901, %902)\n",
      "  %904 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::view(%820, %903) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %905 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %906 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %907 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %908 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %909 : int[] = prim::ListConstruct(%905, %906, %907, %908)\n",
      "  %910 : Float(3, 4, 512, 64, strides=[131072, 64, 256, 1], requires_grad=0, device=cpu) = aten::permute(%904, %909) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %911 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %912 : int = prim::Constant[value=-2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %913 : Float(3, 4, 64, 512, strides=[131072, 64, 1, 256], requires_grad=0, device=cpu) = aten::transpose(%851, %911, %912) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %914 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::matmul(%910, %913) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %915 : Double(requires_grad=0, device=cpu) = prim::Constant[value={8}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %916 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::div(%914, %915) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %917 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %918 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::add(%916, %275, %917) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %919 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %920 : NoneType = prim::Constant()\n",
      "  %921 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::softmax(%918, %919, %920) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %922 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %923 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %924 : Float(3, 4, 512, 512, strides=[1048576, 262144, 512, 1], requires_grad=0, device=cpu) = aten::dropout(%921, %922, %923) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %925 : Float(3, 4, 512, 64, strides=[131072, 32768, 64, 1], requires_grad=0, device=cpu) = aten::matmul(%924, %882) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %926 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %927 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %928 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %929 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %930 : int[] = prim::ListConstruct(%926, %927, %928, %929)\n",
      "  %931 : Float(3, 512, 4, 64, strides=[131072, 64, 32768, 1], requires_grad=0, device=cpu) = aten::permute(%925, %930) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %932 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %933 : Float(3, 512, 4, 64, strides=[131072, 256, 64, 1], requires_grad=0, device=cpu) = aten::contiguous(%931, %932) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %950 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %951 : int = prim::Constant[value=512]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %952 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %953 : int[] = prim::ListConstruct(%950, %951, %952)\n",
      "  %954 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::view(%933, %953) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %955 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %956 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %957 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%954, %955, %956) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %958 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %959 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %960 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%957, %958, %959) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %961 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %962 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%960, %817, %961) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %963 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %964 : int[] = prim::ListConstruct(%963)\n",
      "  %965 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %966 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %967 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %968 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %969 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%962, %964, %965, %966, %967, %968) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %970 : Float(1024, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %971 : Float(1024, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %972 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::linear(%969, %970, %971) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %973 : str = prim::Constant[value=\"none\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %974 : Float(3, 512, 1024, strides=[524288, 1024, 1], requires_grad=0, device=cpu) = aten::gelu(%972, %973) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %975 : Float(256, 1024, strides=[1024, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %976 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %977 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::linear(%974, %975, %976) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %978 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %979 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %980 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%977, %978, %979) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %981 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %982 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::add(%980, %969, %981) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %983 : int = prim::Constant[value=256]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %984 : int[] = prim::ListConstruct(%983)\n",
      "  %985 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %986 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %987 : float = prim::Constant[value=9.9999999999999998e-13]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %988 : bool = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.7 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::layer_norm(%982, %984, %985, %986, %987, %988) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %999 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1000 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1001 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1002 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1003 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.7, %999, %1000, %1001, %1002) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1004 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1005 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1006 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1007 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1008 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::slice(%1003, %1004, %1005, %1006, %1007) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1009 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1010 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1011 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1012 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1013 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::slice(%1008, %1009, %1010, %1011, %1012) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1014 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1015 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1016 : Float(3, 256, strides=[131072, 1], requires_grad=0, device=cpu) = aten::select(%1013, %1014, %1015) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1017 : Float(256, 256, strides=[256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1018 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1019 : Float(3, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::linear(%1016, %1017, %1018) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1020 : Float(3, 256, strides=[256, 1], requires_grad=0, device=cpu) = aten::tanh(%1019) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1021 : float = prim::Constant[value=0.10000000000000001]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1022 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1023 : Float(3, 512, 256, strides=[131072, 256, 1], requires_grad=0, device=cpu) = aten::dropout(%tensor.7, %1021, %1022) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1033 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1034 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1035 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1036 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1037 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.9, %1033, %1034, %1035, %1036) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1038 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1039 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1040 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1041 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1042 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1037, %1038, %1039, %1040, %1041) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1043 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1044 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1045 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1046 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %tensor.11 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1042, %1043, %1044, %1045, %1046) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1057 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1058 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1059 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1060 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1061 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.11, %1057, %1058, %1059, %1060) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1062 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1063 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1064 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1065 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1066 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1061, %1062, %1063, %1064, %1065) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1067 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1068 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1069 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1070 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1071 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1066, %1067, %1068, %1069, %1070) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1072 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1073 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1074 : Long(3, 512, strides=[3584, 7], requires_grad=0, device=cpu) = aten::select(%1071, %1072, %1073) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1084 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1085 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1086 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1087 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1088 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.9, %1084, %1085, %1086, %1087) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1089 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1090 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1091 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1092 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1093 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1088, %1089, %1090, %1091, %1092) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1094 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1095 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1096 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1097 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %tensor.13 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1093, %1094, %1095, %1096, %1097) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1108 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1109 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1110 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1111 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1112 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%tensor.13, %1108, %1109, %1110, %1111) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1113 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1114 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1115 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1116 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1117 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1112, %1113, %1114, %1115, %1116) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1118 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1119 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1120 : int = prim::Constant[value=9223372036854775807]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1121 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1122 : Long(3, 512, 7, strides=[3584, 7, 1], requires_grad=0, device=cpu) = aten::slice(%1117, %1118, %1119, %1120, %1121) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:30:0\n",
      "  %1123 : int = prim::Constant[value=2]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1124 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1125 : Long(3, 512, strides=[3584, 7], requires_grad=0, device=cpu) = aten::select(%1122, %1123, %1124) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1126 : Long(requires_grad=0, device=cpu) = prim::Constant[value={63}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1127 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1128 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1129 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1130 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1131 : NoneType = prim::Constant()\n",
      "  %1132 : Long(requires_grad=0, device=cpu) = aten::to(%1126, %1127, %1128, %1129, %1130, %1131) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %tensor.15 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::min(%1074, %1132) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1134 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1135 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1136 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1137 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1138 : NoneType = prim::Constant()\n",
      "  %1139 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.15, %1134, %1135, %1136, %1137, %1138) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1140 : Long(requires_grad=0, device=cpu) = prim::Constant[value={64}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1141 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1142 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1143 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1144 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1145 : NoneType = prim::Constant()\n",
      "  %1146 : Long(requires_grad=0, device=cpu) = aten::to(%1140, %1141, %1142, %1143, %1144, %1145) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1147 : Long(requires_grad=0, device=cpu) = prim::Constant[value={31}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1148 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1149 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1150 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1151 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1152 : NoneType = prim::Constant()\n",
      "  %1153 : Long(requires_grad=0, device=cpu) = aten::to(%1147, %1148, %1149, %1150, %1151, %1152) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %tensor.17 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::min(%1125, %1153) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1155 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1156 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1157 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1158 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1159 : NoneType = prim::Constant()\n",
      "  %1160 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.17, %1155, %1156, %1157, %1158, %1159) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1161 : Long(requires_grad=0, device=cpu) = prim::Constant[value={32}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1162 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1163 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1164 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1165 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1166 : NoneType = prim::Constant()\n",
      "  %tensor.97 : Long(requires_grad=0, device=cpu) = aten::to(%1161, %1162, %1163, %1164, %1165, %1166) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1168 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::mul(%1139, %tensor.97) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1169 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.19 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1160, %1168, %1169) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.21 : Long(requires_grad=0, device=cpu) = aten::mul(%tensor.97, %1146) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1172 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1173 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1174 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1175 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1176 : NoneType = prim::Constant()\n",
      "  %1177 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.19, %1172, %1173, %1174, %1175, %1176) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1178 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1179 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1180 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1181 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1182 : NoneType = prim::Constant()\n",
      "  %tensor.35 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.21, %1178, %1179, %1180, %1181, %1182) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1184 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1185 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1186 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1187 : NoneType = prim::Constant()\n",
      "  %tensor.23 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.1, %1184, %1185, %1186, %1187) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1189 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1190 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1191 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1192 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1193 : NoneType = prim::Constant()\n",
      "  %1194 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.23, %1189, %1190, %1191, %1192, %1193) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1211 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1212 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1213 : NoneType = prim::Constant()\n",
      "  %1214 : NoneType = prim::Constant()\n",
      "  %1215 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1216 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1217 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1211, %1212, %1213, %1214, %1215, %1216) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1218 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1217, %tensor.35) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1227 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1228 : int[] = prim::ListConstruct(%1227)\n",
      "  %1229 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1218, %1228) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1230 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1231 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1229, %1230) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1232 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1233 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1231, %1177, %1232) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1234 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1235 : int[] = prim::ListConstruct(%1234)\n",
      "  %tensor.29 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::view(%1233, %1235) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1238 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1239 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1240 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1241 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1242 : NoneType = prim::Constant()\n",
      "  %tensor.33 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.29, %1238, %1239, %1240, %1241, %1242) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1250 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1251 : int[] = prim::ListConstruct(%1250)\n",
      "  %1252 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1194, %1251) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1253 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1254 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1255 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1256 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1257 : NoneType = prim::Constant()\n",
      "  %1258 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.33, %1253, %1254, %1255, %1256, %1257) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1267 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1268 : int[] = prim::ListConstruct(%1267)\n",
      "  %1269 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1270 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1258, %1268, %1269) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1271 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1272 : int[] = prim::ListConstruct(%1271)\n",
      "  %1273 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1274 : NoneType = prim::Constant()\n",
      "  %1275 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1276 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1277 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%1272, %1273, %1274, %1275, %1276) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1286 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1287 : int[] = prim::ListConstruct(%1286)\n",
      "  %1288 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1289 : NoneType = prim::Constant()\n",
      "  %1290 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1291 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1292 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::ones(%1287, %1288, %1289, %1290, %1291) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1301 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1302 : int[] = prim::ListConstruct(%1301)\n",
      "  %1303 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1304 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1258, %1302, %1303) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1305 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1306 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1307 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1308 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1309 : NoneType = prim::Constant()\n",
      "  %tensor.37 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.35, %1305, %1306, %1307, %1308, %1309) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1311 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1312 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1313 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1314 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1315 : NoneType = prim::Constant()\n",
      "  %tensor.49 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.37, %1311, %1312, %1313, %1314, %1315) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1317 : str = prim::Constant[value=\"bsj,j->bs\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1318 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1319 : Tensor[] = prim::ListConstruct(%1023, %1318)\n",
      "  %1320 : NoneType = prim::Constant()\n",
      "  %1321 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::einsum(%1317, %1319, %1320) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1322 : Float(requires_grad=0, device=cpu) = prim::Constant[value={-0.00710079}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1323 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1324 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1321, %1322, %1323) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1325 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.0352513}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1326 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::div(%1324, %1325) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1327 : str = prim::Constant[value=\"bsj,j->bs\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1328 : Float(256, strides=[1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1329 : Tensor[] = prim::ListConstruct(%1023, %1328)\n",
      "  %1330 : NoneType = prim::Constant()\n",
      "  %1331 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::einsum(%1327, %1329, %1330) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1332 : Float(requires_grad=0, device=cpu) = prim::Constant[value={-0.0498342}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1333 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1334 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1331, %1332, %1333) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1351 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1352 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1353 : NoneType = prim::Constant()\n",
      "  %1354 : NoneType = prim::Constant()\n",
      "  %1355 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1356 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1357 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1351, %1352, %1353, %1354, %1355, %1356) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1358 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1357, %tensor.49) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1367 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1368 : int[] = prim::ListConstruct(%1367)\n",
      "  %1369 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1358, %1368) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1370 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1371 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1369, %1370) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1372 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1373 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1371, %1177, %1372) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1374 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1375 : int[] = prim::ListConstruct(%1374)\n",
      "  %tensor.43 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::view(%1373, %1375) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1378 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1379 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1380 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1381 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1382 : NoneType = prim::Constant()\n",
      "  %tensor.47 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.43, %1378, %1379, %1380, %1381, %1382) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1390 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1391 : int[] = prim::ListConstruct(%1390)\n",
      "  %1392 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1334, %1391) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1393 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1394 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1395 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1396 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1397 : NoneType = prim::Constant()\n",
      "  %1398 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.47, %1393, %1394, %1395, %1396, %1397) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1407 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1408 : int[] = prim::ListConstruct(%1407)\n",
      "  %1409 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1410 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1398, %1408, %1409) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1411 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1412 : int[] = prim::ListConstruct(%1411)\n",
      "  %1413 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1414 : NoneType = prim::Constant()\n",
      "  %1415 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1416 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1417 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%1412, %1413, %1414, %1415, %1416) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1426 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1427 : int[] = prim::ListConstruct(%1426)\n",
      "  %1428 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1429 : NoneType = prim::Constant()\n",
      "  %1430 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1431 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1432 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::ones(%1427, %1428, %1429, %1430, %1431) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1441 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1442 : int[] = prim::ListConstruct(%1441)\n",
      "  %1443 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1444 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1398, %1442, %1443) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1445 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1446 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1447 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1448 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1449 : NoneType = prim::Constant()\n",
      "  %tensor.51 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.49, %1445, %1446, %1447, %1448, %1449) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1451 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:51:0\n",
      "  %1452 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:51:0\n",
      "  %1453 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:51:0\n",
      "  %1454 : NoneType = prim::Constant()\n",
      "  %tensor.53 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.51, %1451, %1452, %1453, %1454) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:51:0\n",
      "  %1467 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1468 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1469 : NoneType = prim::Constant()\n",
      "  %1470 : NoneType = prim::Constant()\n",
      "  %1471 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1472 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1473 : Long(2048, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1467, %1468, %1469, %1470, %1471, %1472) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1474 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1475 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1476 : int[] = prim::ListConstruct(%1474, %1475)\n",
      "  %1477 : Long(1, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%1473, %1476) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1478 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1479 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1480 : int[] = prim::ListConstruct(%1478, %1479)\n",
      "  %tensor.55 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::repeat(%1477, %1480) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1482 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1483 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1484 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1485 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1486 : NoneType = prim::Constant()\n",
      "  %1487 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.55, %1482, %1483, %1484, %1485, %1486) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1488 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1489 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1490 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1491 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1492 : NoneType = prim::Constant()\n",
      "  %tensor.69 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.53, %1488, %1489, %1490, %1491, %1492) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1494 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1495 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1496 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1497 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1498 : NoneType = prim::Constant()\n",
      "  %tensor.57 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::zeros_like(%1326, %1494, %1495, %1496, %1497, %1498) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1500 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1501 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1502 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1503 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1504 : NoneType = prim::Constant()\n",
      "  %tensor.73 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.57, %1500, %1501, %1502, %1503, %1504) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1522 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1523 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1524 : NoneType = prim::Constant()\n",
      "  %1525 : NoneType = prim::Constant()\n",
      "  %1526 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1527 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1528 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1522, %1523, %1524, %1525, %1526, %1527) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1529 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1528, %tensor.69) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1538 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1539 : int[] = prim::ListConstruct(%1538)\n",
      "  %1540 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1529, %1539) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1541 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1542 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1540, %1541) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1543 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1544 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1542, %1177, %1543) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1545 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1546 : int[] = prim::ListConstruct(%1545)\n",
      "  %tensor.63 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::view(%1544, %1546) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1549 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1550 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1551 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1552 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1553 : NoneType = prim::Constant()\n",
      "  %tensor.67 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.63, %1549, %1550, %1551, %1552, %1553) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1561 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1562 : int[] = prim::ListConstruct(%1561)\n",
      "  %1563 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1326, %1562) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1564 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1565 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1566 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1567 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1568 : NoneType = prim::Constant()\n",
      "  %1569 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.67, %1564, %1565, %1566, %1567, %1568) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1578 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1579 : int[] = prim::ListConstruct(%1578)\n",
      "  %1580 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1581 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1569, %1579, %1580) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1582 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1583 : int[] = prim::ListConstruct(%1582)\n",
      "  %1584 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1585 : NoneType = prim::Constant()\n",
      "  %1586 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1587 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1588 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%1583, %1584, %1585, %1586, %1587) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1597 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1598 : int[] = prim::ListConstruct(%1597)\n",
      "  %1599 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1600 : NoneType = prim::Constant()\n",
      "  %1601 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1602 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1603 : Float(1536, strides=[1], requires_grad=0, device=cpu) = aten::ones(%1598, %1599, %1600, %1601, %1602) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1612 : int = prim::Constant[value=1536]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1613 : int[] = prim::ListConstruct(%1612)\n",
      "  %1614 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1615 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1569, %1613, %1614) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1616 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1617 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1618 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1619 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1620 : NoneType = prim::Constant()\n",
      "  %tensor.71 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.69, %1616, %1617, %1618, %1619, %1620) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1622 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1623 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1624 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1625 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1626 : NoneType = prim::Constant()\n",
      "  %tensor.83 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.71, %1622, %1623, %1624, %1625, %1626) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1628 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1629 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1630 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1631 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1632 : NoneType = prim::Constant()\n",
      "  %1633 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::to(%tensor.73, %1628, %1629, %1630, %1631, %1632) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1650 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1651 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1652 : NoneType = prim::Constant()\n",
      "  %1653 : NoneType = prim::Constant()\n",
      "  %1654 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1655 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1656 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1650, %1651, %1652, %1653, %1654, %1655) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1657 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1656, %tensor.83) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1666 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1667 : int[] = prim::ListConstruct(%1666)\n",
      "  %1668 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1657, %1667) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1669 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1670 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1668, %1669) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1671 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1672 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::add(%1670, %1177, %1671) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1673 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1674 : int[] = prim::ListConstruct(%1673)\n",
      "  %tensor.79 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::view(%1672, %1674) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1676 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1677 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1678 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1679 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1680 : NoneType = prim::Constant()\n",
      "  %tensor.81 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.79, %1676, %1677, %1678, %1679, %1680) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1682 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1683 : int[] = prim::ListConstruct(%1682)\n",
      "  %1684 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1633, %1683) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1685 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1686 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1687 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1688 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1689 : NoneType = prim::Constant()\n",
      "  %1690 : Long(1536, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.81, %1685, %1686, %1687, %1688, %1689) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1713 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1714 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1715 : NoneType = prim::Constant()\n",
      "  %1716 : NoneType = prim::Constant()\n",
      "  %1717 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1718 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1719 : Long(2048, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1713, %1714, %1715, %1716, %1717, %1718) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1720 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1721 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1722 : int[] = prim::ListConstruct(%1720, %1721)\n",
      "  %1723 : Long(1, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%1719, %1722) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1724 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1725 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1726 : int[] = prim::ListConstruct(%1724, %1725)\n",
      "  %tensor.89 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::repeat(%1723, %1726) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1728 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1729 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1730 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1731 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1732 : NoneType = prim::Constant()\n",
      "  %1733 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.89, %1728, %1729, %1730, %1731, %1732) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1734 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1735 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%1277, %1734, %1270, %1252) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.23 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#108)\n",
      "  %2384 : Tensor[] = prim::ListConstruct(%1735), scope: __module._NeuronGraph#108\n",
      "  %2385 : Float(6144, strides=[1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2384, %model.23), scope: __module._NeuronGraph#108 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %1738 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1739 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%2385, %1738, %1304, %1292) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1740 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1741 : Bool(6144, strides=[1], requires_grad=0, device=cpu) = aten::lt(%1739, %1740) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1742 : Tensor?[] = prim::ListConstruct(%1741)\n",
      "  %1743 : Float(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1744 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1745 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::index_put_(%1739, %1742, %1743, %1744) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1746 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1747 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%1417, %1746, %1410, %1392) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.25 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#114)\n",
      "  %2387 : Tensor[] = prim::ListConstruct(%1747), scope: __module._NeuronGraph#114\n",
      "  %2388 : Float(6144, strides=[1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2387, %model.25), scope: __module._NeuronGraph#114 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %1750 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1751 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%2388, %1750, %1444, %1432) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1752 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1753 : Bool(6144, strides=[1], requires_grad=0, device=cpu) = aten::lt(%1751, %1752) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1754 : Tensor?[] = prim::ListConstruct(%1753)\n",
      "  %1755 : Float(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1756 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1757 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::index_put_(%1751, %1754, %1755, %1756) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.91 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::fmod(%1487, %tensor.97) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1759 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1760 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%1588, %1759, %1581, %1563) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model.27 : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#121)\n",
      "  %2390 : Tensor[] = prim::ListConstruct(%1760), scope: __module._NeuronGraph#121\n",
      "  %2391 : Float(6144, strides=[1], requires_grad=0, device=cpu) = neuron::forward_v2_1(%2390, %model.27), scope: __module._NeuronGraph#121 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %1763 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1764 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%2391, %1763, %1615, %1603) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1765 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1766 : Bool(6144, strides=[1], requires_grad=0, device=cpu) = aten::lt(%1764, %1765) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1767 : Tensor?[] = prim::ListConstruct(%1766)\n",
      "  %1768 : Float(requires_grad=0, device=cpu) = prim::Constant[value={1}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1769 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1770 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::index_put_(%1764, %1767, %1768, %1769) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1771 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1772 : NoneType = prim::Constant()\n",
      "  %1773 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1774 : Long(6144, strides=[1], requires_grad=0, device=cpu), %1775 : Long(6144, strides=[1], requires_grad=0, device=cpu) = torch_scatter::scatter_max(%1684, %1690, %1771, %1772, %1773) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1784 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1785 : int[] = prim::ListConstruct(%1784)\n",
      "  %1786 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1787 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1745, %1785, %1786) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1788 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::div_(%1735, %1787) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1789 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1790 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1791 : int[] = prim::ListConstruct(%1789, %1790)\n",
      "  %1792 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%1788, %1791) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1801 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1802 : int[] = prim::ListConstruct(%1801)\n",
      "  %1803 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1804 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1757, %1802, %1803) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1805 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::div_(%1747, %1804) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1806 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1807 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1808 : int[] = prim::ListConstruct(%1806, %1807)\n",
      "  %1809 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%1805, %1808) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1810 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1811 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1812 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1813 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1814 : NoneType = prim::Constant()\n",
      "  %1815 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.91, %1810, %1811, %1812, %1813, %1814) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %tensor.93 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::floor(%1815) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1817 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1818 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1819 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1820 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1821 : NoneType = prim::Constant()\n",
      "  %tensor.95 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.93, %1817, %1818, %1819, %1820, %1821) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1823 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1824 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1825 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1826 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1827 : NoneType = prim::Constant()\n",
      "  %1828 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.95, %1823, %1824, %1825, %1826, %1827) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1829 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1830 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1831 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1832 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1833 : NoneType = prim::Constant()\n",
      "  %tensor.109 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.97, %1829, %1830, %1831, %1832, %1833) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1835 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::mul(%1809, %1792) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1852 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1853 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1854 : NoneType = prim::Constant()\n",
      "  %1855 : NoneType = prim::Constant()\n",
      "  %1856 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1857 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1858 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1852, %1853, %1854, %1855, %1856, %1857) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1859 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1858, %tensor.109) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1868 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1869 : int[] = prim::ListConstruct(%1868)\n",
      "  %1870 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1859, %1869) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1871 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1872 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1870, %1871) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1873 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1874 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::add(%1872, %1828, %1873) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1875 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1876 : int[] = prim::ListConstruct(%1875)\n",
      "  %tensor.103 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::view(%1874, %1876) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1879 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1880 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1881 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1882 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1883 : NoneType = prim::Constant()\n",
      "  %tensor.107 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.103, %1879, %1880, %1881, %1882, %1883) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1891 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1892 : int[] = prim::ListConstruct(%1891)\n",
      "  %1893 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1835, %1892) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1894 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1895 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1896 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1897 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1898 : NoneType = prim::Constant()\n",
      "  %1899 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.107, %1894, %1895, %1896, %1897, %1898) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1908 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1909 : int[] = prim::ListConstruct(%1908)\n",
      "  %1910 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1911 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1899, %1909, %1910) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1912 : int = prim::Constant[value=96]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1913 : int[] = prim::ListConstruct(%1912)\n",
      "  %1914 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1915 : NoneType = prim::Constant()\n",
      "  %1916 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1917 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1918 : Float(96, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%1913, %1914, %1915, %1916, %1917) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1919 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1920 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1921 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1922 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1923 : NoneType = prim::Constant()\n",
      "  %tensor.111 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.109, %1919, %1920, %1921, %1922, %1923) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1925 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1926 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1927 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1928 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1929 : NoneType = prim::Constant()\n",
      "  %tensor.123 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.111, %1925, %1926, %1927, %1928, %1929) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1947 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1948 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1949 : NoneType = prim::Constant()\n",
      "  %1950 : NoneType = prim::Constant()\n",
      "  %1951 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1952 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1953 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::arange(%1947, %1948, %1949, %1950, %1951, %1952) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1954 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::mul(%1953, %tensor.123) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1963 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1964 : int[] = prim::ListConstruct(%1963)\n",
      "  %1965 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::view(%1954, %1964) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1966 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1967 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%1965, %1966) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1968 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1969 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::add(%1967, %1828, %1968) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1970 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1971 : int[] = prim::ListConstruct(%1970)\n",
      "  %tensor.117 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::view(%1969, %1971) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1974 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1975 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1976 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1977 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1978 : NoneType = prim::Constant()\n",
      "  %tensor.121 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.117, %1974, %1975, %1976, %1977, %1978) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1986 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1987 : int[] = prim::ListConstruct(%1986)\n",
      "  %1988 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::reshape(%1792, %1987) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %1989 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1990 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1991 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1992 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %1993 : NoneType = prim::Constant()\n",
      "  %1994 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.121, %1989, %1990, %1991, %1992, %1993) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2003 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2004 : int[] = prim::ListConstruct(%2003)\n",
      "  %2005 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2006 : Long(6144, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1994, %2004, %2005) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2007 : int = prim::Constant[value=96]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2008 : int[] = prim::ListConstruct(%2007)\n",
      "  %2009 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2010 : NoneType = prim::Constant()\n",
      "  %2011 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2012 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2013 : Float(96, strides=[1], requires_grad=0, device=cpu) = aten::zeros(%2008, %2009, %2010, %2011, %2012) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2014 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2015 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2016 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2017 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2018 : NoneType = prim::Constant()\n",
      "  %tensor.125 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.123, %2014, %2015, %2016, %2017, %2018) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2020 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2021 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2022 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2023 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2024 : NoneType = prim::Constant()\n",
      "  %tensor.127 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.125, %2020, %2021, %2022, %2023, %2024) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2026 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2027 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2028 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2029 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2030 : NoneType = prim::Constant()\n",
      "  %tensor.129 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.127, %2026, %2027, %2028, %2029, %2030) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2032 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2033 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2034 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2035 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2036 : NoneType = prim::Constant()\n",
      "  %tensor.131 : Long(requires_grad=0, device=cpu) = aten::to(%tensor.129, %2032, %2033, %2034, %2035, %2036) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2038 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2039 : Float(96, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%1918, %2038, %1911, %1893) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2040 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2041 : Float(96, strides=[1], requires_grad=0, device=cpu) = aten::scatter_add_(%2013, %2040, %2006, %1988) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.141 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::fmod(%1733, %tensor.131) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2043 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2044 : int = prim::Constant[value=32]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2045 : int[] = prim::ListConstruct(%2043, %2044)\n",
      "  %2046 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::view(%2039, %2045) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2063 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2064 : int = prim::Constant[value=32]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2065 : NoneType = prim::Constant()\n",
      "  %2066 : NoneType = prim::Constant()\n",
      "  %2067 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2068 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2069 : Long(32, strides=[1], requires_grad=0, device=cpu) = aten::arange(%2063, %2064, %2065, %2066, %2067, %2068) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2070 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2071 : int = prim::Constant[value=32]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2072 : int[] = prim::ListConstruct(%2070, %2071)\n",
      "  %2073 : Long(1, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::view(%2069, %2072) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2074 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2075 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2076 : int[] = prim::ListConstruct(%2074, %2075)\n",
      "  %tensor.135 : Long(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::repeat(%2073, %2076) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2078 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2079 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2080 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2081 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2082 : NoneType = prim::Constant()\n",
      "  %2083 : Long(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::to(%tensor.135, %2078, %2079, %2080, %2081, %2082) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2084 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2085 : int = prim::Constant[value=32]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2086 : int[] = prim::ListConstruct(%2084, %2085)\n",
      "  %2087 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::view(%2041, %2086) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2088 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-10}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2089 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2090 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::add(%2087, %2088, %2089) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2091 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::div_(%2046, %2090) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2092 : float = prim::Constant[value=0.5]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2093 : Bool(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::lt(%2087, %2092) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2094 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2095 : Bool(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::eq(%2083, %2094) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2096 : Bool(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::bitwise_not(%2095) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.137 : Bool(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::logical_and(%2093, %2096) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2098 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2099 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2100 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2101 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2102 : NoneType = prim::Constant()\n",
      "  %2103 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::to(%tensor.137, %2098, %2099, %2100, %2101, %2102) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2104 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2105 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::mul(%2103, %2104) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2106 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2107 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::add_(%2091, %2105, %2106) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2108 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.139 : Bool(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::eq(%2083, %2108) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2110 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2111 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2112 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2113 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2114 : NoneType = prim::Constant()\n",
      "  %2115 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::to(%tensor.139, %2110, %2111, %2112, %2113, %2114) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2116 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2117 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::mul(%2115, %2116) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2118 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2119 : Float(3, 32, strides=[32, 1], requires_grad=0, device=cpu) = aten::add_(%2107, %2117, %2118) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2128 : int = prim::Constant[value=6144]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2129 : int[] = prim::ListConstruct(%2128)\n",
      "  %2130 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2131 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::expand(%1770, %2129, %2130) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2132 : Float(6144, strides=[1], requires_grad=0, device=cpu) = aten::div_(%1760, %2131) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2133 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2134 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2135 : int[] = prim::ListConstruct(%2133, %2134)\n",
      "  %2136 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%2132, %2135) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2137 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2138 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2139 : int[] = prim::ListConstruct(%2137, %2138)\n",
      "  %tensor.147 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%1774, %2139) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2141 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2142 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2143 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2144 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2145 : NoneType = prim::Constant()\n",
      "  %2146 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.141, %2141, %2142, %2143, %2144, %2145) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %tensor.143 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::floor(%2146) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2148 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2149 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2150 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2151 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2152 : NoneType = prim::Constant()\n",
      "  %tensor.145 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.143, %2148, %2149, %2150, %2151, %2152) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2154 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2155 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2156 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2157 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2158 : NoneType = prim::Constant()\n",
      "  %2159 : Long(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.145, %2154, %2155, %2156, %2157, %2158) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2160 : Tensor[] = prim::ListConstruct(%2136)\n",
      "  %2161 : Tensor[] = aten::broadcast_tensors(%2160) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2162 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%2161)\n",
      "  %2163 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2164 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2165 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2166 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2167 : NoneType = prim::Constant()\n",
      "  %2168 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor.147, %2163, %2164, %2165, %2166, %2167) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2169 : Tensor[] = prim::ListConstruct(%2162, %2168)\n",
      "  %2170 : Tensor[] = aten::broadcast_tensors(%2169) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2171 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu), %2172 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = prim::ListUnpack(%2170)\n",
      "  %2173 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2174 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor.149 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::argmax(%2119, %2173, %2174) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2176 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2177 : int = prim::Constant[value=4]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2178 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2179 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2180 : NoneType = prim::Constant()\n",
      "  %2181 : Long(3, strides=[1], requires_grad=0, device=cpu) = aten::to(%tensor.149, %2176, %2177, %2178, %2179, %2180) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2182 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2183 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = aten::unsqueeze(%2181, %2182) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %tensor : Bool(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::eq(%2159, %2183) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2185 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2186 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2187 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2188 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2189 : NoneType = prim::Constant()\n",
      "  %2190 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::to(%tensor, %2185, %2186, %2187, %2188, %2189) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/native_ops/aten.py:82:0\n",
      "  %2191 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2192 : Bool(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::eq(%2159, %2191) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2209 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2210 : int = prim::Constant[value=2048]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2211 : int[] = prim::ListConstruct(%2209, %2210)\n",
      "  %2212 : Bool(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::view(%2192, %2211) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2213 : int = prim::Constant[value=6]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2214 : int = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2215 : Device = prim::Constant[value=\"cpu\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2216 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2217 : NoneType = prim::Constant()\n",
      "  %2218 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::zeros_like(%2190, %2213, %2214, %2215, %2216, %2217) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2219 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::where(%2212, %2218, %2190) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2220 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::mul(%1792, %2219) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2221 : float = prim::Constant[value=1.]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2222 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2223 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::rsub(%2220, %2221, %2222) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2224 : Double(requires_grad=0, device=cpu) = prim::Constant[value={-10000}]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2225 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::mul(%2223, %2224) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2226 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2227 : Float(3, 2048, strides=[2048, 1], requires_grad=0, device=cpu) = aten::add(%2171, %2225, %2226) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2236 : int = prim::Constant[value=3]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2237 : int = prim::Constant[value=-1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2238 : int[] = prim::ListConstruct(%2236, %2237)\n",
      "  %2239 : Long(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::view(%1177, %2238) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2240 : int = prim::Constant[value=1]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2241 : bool = prim::Constant[value=0]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %2242 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu) = aten::gather(%2227, %2240, %2239, %2241) # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch_neuron/resolve_function.py:71:0\n",
      "  %model : __torch__.torch.classes.neuron.Model = prim::GetAttr[name=\"model\"](%_NeuronGraph#133)\n",
      "  %2393 : Tensor[] = prim::ListConstruct(%1020, %1177, %2242), scope: __module._NeuronGraph#133\n",
      "  %2394 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu), %2395 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = neuron::forward_v2_2(%2393, %model), scope: __module._NeuronGraph#133 # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_ops.py:442:0\n",
      "  %2396 : (Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)) = prim::TupleConstruct(%2394, %2395)\n",
      "  %2327 : Float(3, 512, strides=[512, 1], requires_grad=0, device=cpu), %2328 : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu) = prim::TupleUnpack(%2396)\n",
      "  %2246 : str = prim::Constant[value=\"logits\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/jit/_trace.py:983:0\n",
      "  %2247 : str = prim::Constant[value=\"logits_aggregation\"]() # /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/jit/_trace.py:983:0\n",
      "  %2248 : Dict(str, Tensor) = prim::DictConstruct(%2246, %2327, %2247, %2328)\n",
      "  return (%2248)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tapas_deployer.trace_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f6e52-ffdb-401c-92e7-f2bdf3d13f7f",
   "metadata": {},
   "source": [
    "### Upload the traced model into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e791eba9-c88f-4be9-a0fb-91b69228fe8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron_compiled_model.pt\n",
      "Uploaded model to S3: s3://sagemaker-eu-north-1-058095970122/inf1_compiled_model/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "tapas_deployer.upload_model_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee47f1a-1059-4392-a7c5-b8b325c7e7bf",
   "metadata": {},
   "source": [
    "### Build the docker image that will serve as the hosting environment of the deployed model\n",
    "To see all the instructions used to build the image, check the Dockerfile at ```./Dockerfile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6a4df2-8448-4e20-85c6-de3aa83a4267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  359.9MB\n",
      "Step 1/4 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference-neuron:1.7.1-neuron-py36-ubuntu18.04\n",
      " ---> 388bfe7d2429\n",
      "Step 2/4 : RUN pip install \"pandas==1.1.5\"\n",
      " ---> Using cache\n",
      " ---> b0e18d821bee\n",
      "Step 3/4 : RUN pip install --upgrade --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch torch-scatter --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
      " ---> Using cache\n",
      " ---> 1b39d27c2e1c\n",
      "Step 4/4 : RUN pip install --upgrade --no-cache-dir 'transformers==4.6.0'\n",
      " ---> Using cache\n",
      " ---> 09efc9662482\n",
      "[Warning] One or more build-args [REGION] were not consumed\n",
      "Successfully built 09efc9662482\n",
      "Successfully tagged inference-to-deploy:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [058095970122.dkr.ecr.eu-north-1.amazonaws.com/inference-to-deploy]\n",
      "abc090cd2ab4: Preparing\n",
      "46af0ecae94b: Preparing\n",
      "7e57f08b8a1d: Preparing\n",
      "5d32c72ad027: Preparing\n",
      "f4d9427d752b: Preparing\n",
      "62b8cb6215cb: Preparing\n",
      "877b36f2f41c: Preparing\n",
      "4beb4e23ce0b: Preparing\n",
      "629f76e0ebfa: Preparing\n",
      "55aafc4b4134: Preparing\n",
      "5b505b65f8e8: Preparing\n",
      "4383d9750962: Preparing\n",
      "120ef6a75dae: Preparing\n",
      "d1a63e051735: Preparing\n",
      "1353ff378dc3: Preparing\n",
      "3d7573db3c3f: Preparing\n",
      "2858c813c4e4: Preparing\n",
      "629f76e0ebfa: Waiting\n",
      "e8b427e8fb51: Preparing\n",
      "877b36f2f41c: Waiting\n",
      "6b9a1856b2e9: Preparing\n",
      "79ec63999885: Preparing\n",
      "4beb4e23ce0b: Waiting\n",
      "5dcdeb94f6a5: Preparing\n",
      "b8b74f1e44f0: Preparing\n",
      "bf9a431aeda6: Preparing\n",
      "5f08512fd434: Preparing\n",
      "c7bb31fc0e08: Preparing\n",
      "62b8cb6215cb: Waiting\n",
      "55aafc4b4134: Waiting\n",
      "50858308da3d: Preparing\n",
      "5b505b65f8e8: Waiting\n",
      "3d7573db3c3f: Waiting\n",
      "e8b427e8fb51: Waiting\n",
      "4383d9750962: Waiting\n",
      "bf9a431aeda6: Waiting\n",
      "79ec63999885: Waiting\n",
      "6b9a1856b2e9: Waiting\n",
      "5dcdeb94f6a5: Waiting\n",
      "2858c813c4e4: Waiting\n",
      "120ef6a75dae: Waiting\n",
      "b8b74f1e44f0: Waiting\n",
      "5f08512fd434: Waiting\n",
      "1353ff378dc3: Waiting\n",
      "c7bb31fc0e08: Waiting\n",
      "d1a63e051735: Waiting\n",
      "46af0ecae94b: Layer already exists\n",
      "f4d9427d752b: Layer already exists\n",
      "5d32c72ad027: Layer already exists\n",
      "abc090cd2ab4: Layer already exists\n",
      "7e57f08b8a1d: Layer already exists\n",
      "877b36f2f41c: Layer already exists\n",
      "629f76e0ebfa: Layer already exists\n",
      "62b8cb6215cb: Layer already exists\n",
      "55aafc4b4134: Layer already exists\n",
      "4beb4e23ce0b: Layer already exists\n",
      "5b505b65f8e8: Layer already exists\n",
      "4383d9750962: Layer already exists\n",
      "120ef6a75dae: Layer already exists\n",
      "1353ff378dc3: Layer already exists\n",
      "d1a63e051735: Layer already exists\n",
      "3d7573db3c3f: Layer already exists\n",
      "e8b427e8fb51: Layer already exists\n",
      "2858c813c4e4: Layer already exists\n",
      "79ec63999885: Layer already exists\n",
      "6b9a1856b2e9: Layer already exists\n",
      "5dcdeb94f6a5: Layer already exists\n",
      "b8b74f1e44f0: Layer already exists\n",
      "bf9a431aeda6: Layer already exists\n",
      "5f08512fd434: Layer already exists\n",
      "c7bb31fc0e08: Layer already exists\n",
      "50858308da3d: Layer already exists\n",
      "latest: digest: sha256:36fa3ff9fe86bc06ffdfa9cfd082d3598d210913ab04a4b8b191f5c1ab384dcc size: 5773\n"
     ]
    }
   ],
   "source": [
    "tapas_deployer.build_ecr_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee38c7-c765-4f9a-beed-9484c5508810",
   "metadata": {},
   "source": [
    "### Deploy the built environment using the entrypoint ```./entrypoint/inference.py``` to define how the image starts and how it reacts to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8832f6-1c0d-475d-9bb0-30ff88bca169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------"
     ]
    }
   ],
   "source": [
    "tapas_deployer.deploy_ecr_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eacee0-638a-450c-ac57-c430a883e918",
   "metadata": {},
   "source": [
    "### Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f0597-8960-4eda-89ff-277768bd82da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tapas_deployer.test_endpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519afa7-8a0d-4b99-b319-1b1d83d87743",
   "metadata": {},
   "source": [
    "### Delete the endpoint after testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cc127-6f0e-4a4e-b2ab-cb07468a56d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ede64-7127-48d4-9d93-89e46cfaf3d0",
   "metadata": {},
   "source": [
    "###  Final notes for Scrub ..\n",
    "- This deployer successfully builds and deploys CPU and Neuron instances.\n",
    "- If run on an ```inf1``` instance, the deployer will test entrypoints locally to make sure CPU and Neuron inference work as expected in the deployed endpoints.\n",
    "- The Neuron deployer works as expected when testing with classic BERT models.\n",
    "- Specifically for TAPAS, the tracing step always returns the following warning for TAPAS mini:\n",
    "```\n",
    "WARNING:Neuron:torch.neuron.trace was unable to compile > 50% of the operators in the compiled model!\n",
    "WARNING:Neuron:Please review the torch.neuron.analyze_model output and if you believe you are seeing a failure\n",
    "WARNING:Neuron:Lodge an issue on https://github.com/aws/aws-neuron-sdk/issues if you believe the model is not compiling as expected\n",
    "```\n",
    "- The warning above means that traced TAPAS models randomly crash with \"Unkown Reasons\" when used for inference.\n",
    "- Using the API included here, other BERT models work well during Neuron deployment and inference.\n",
    "- The neuron service will always try running predictions through Neuron models first, and will fall back on the CPU if the neuron model acts funny.\n",
    "- Seems like the randomness of TAPAS Neuron tracing would take a fair bit of time to resolve, so I am including a typical Neuron deployment build here with CPU fallback.\n",
    "\n",
    "Thanks for the clear test and please let me know if you have any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46b744-aebb-41bd-8774-cd5e81a3b5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ad1d-ebcf-4d68-b849-375602617789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c510c-2bfe-4479-b601-faafea9d2c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f808e5e-fd72-4216-8142-9e76700ea4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7f9ca-5782-4164-8854-050f9fc4fe23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
