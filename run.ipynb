{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4674f667",
   "metadata": {},
   "source": [
    "# TAPAS deployment via Sagemaker-Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e39838",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c454f",
   "metadata": {},
   "source": [
    "This notebook creates an instance of ```TAPAS_Deployer``` and calls all neccessary actions to build, deploy, and test a mini variant of TAPAS for tabular question answering. For details, please refer to the source files included in ```./source``` and ```./entrypoint``` which were refactored to be easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92460bb-f922-43f9-a435-8ddb062cbffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How to use this notebook..\n",
    "- Create an AWS account.\n",
    "- Create an IAM role with the following access permissions: ```AmazonSageMakerFullAccess, EC2InstanceProfileForImageBuilderECRContainerBuilds, AWSAppRunnerServicePolicyForECRAccess```\n",
    "- Start a new Notebook instance in Sagemaker using the role created above.\n",
    "- Clone this repository and run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae3092c",
   "metadata": {},
   "source": [
    "## Some notes for Scrub..\n",
    "- ```Deployer``` is a generic class template from which many models can be built and deployed directly.\n",
    "- ```TAPAS_Deployer``` inherits Deployer and any other model can be similarly created with minimum effort.\n",
    "- To avoid timeouts and and random kernel restarts, the running code is separated from the noteboook running it. \n",
    "- Everything in ```./source``` can be easily imported as an API.\n",
    "- Some integration pytest samples are included in ```./tests```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1f0bf-6516-420c-9193-bf6c6380dcf0",
   "metadata": {},
   "source": [
    "### Install local dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c3731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir torch-neuron neuron-cc[tensorflow] torchvision torch torch-scatter --extra-index-url=https://pip.repos.neuron.amazonaws.com\n",
    "!pip install --upgrade --no-cache-dir 'transformers==4.6.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4796d3a",
   "metadata": {},
   "source": [
    "### Prepare deployer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe85f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from source.tapas import TAPAS_Deployer\n",
    "tapas_deployer = TAPAS_Deployer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d9222-f669-4fed-aafe-8d5bb4170ad6",
   "metadata": {},
   "source": [
    "### Retrieve model from Huggingface Hub and prepare its respective tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b83ed-7abe-4219-bcc5-f70d38023d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.get_model_and_tokeniser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa89ef-fc6a-49c2-b923-a7a54c60ea33",
   "metadata": {},
   "source": [
    "### Trace the model to be deployed into a Neuron instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5a2f0-4af5-4c34-9e19-3a2390bb0c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.trace_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f6e52-ffdb-401c-92e7-f2bdf3d13f7f",
   "metadata": {},
   "source": [
    "### Upload the traced model into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791eba9-c88f-4be9-a0fb-91b69228fe8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.upload_model_to_s3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee47f1a-1059-4392-a7c5-b8b325c7e7bf",
   "metadata": {},
   "source": [
    "### Build the docker image that will serve as the hosting environment of the deployed model\n",
    "To see all the instructions used to build the image, check the Dockerfile at ```./Dockerfile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a4df2-8448-4e20-85c6-de3aa83a4267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.build_ecr_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee38c7-c765-4f9a-beed-9484c5508810",
   "metadata": {},
   "source": [
    "### Deploy the built environment using the entrypoint ```./entrypoint/inference.py``` to define how the image starts and how it reacts to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8832f6-1c0d-475d-9bb0-30ff88bca169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.deploy_ecr_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eacee0-638a-450c-ac57-c430a883e918",
   "metadata": {},
   "source": [
    "### Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f0597-8960-4eda-89ff-277768bd82da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tapas_deployer.test_endpoint())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519afa7-8a0d-4b99-b319-1b1d83d87743",
   "metadata": {},
   "source": [
    "### Delete the endpoint after testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cc127-6f0e-4a4e-b2ab-cb07468a56d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tapas_deployer.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ede64-7127-48d4-9d93-89e46cfaf3d0",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- This deployer successfully builds and deploys CPU and Neuron instances.\n",
    "- If run on an ```inf1``` instance, the deployer will test entrypoints locally to make sure CPU and Neuron inference work as expected in the deployed endpoints.\n",
    "- The Neuron deployer works as expected when testing with classic BERT models.\n",
    "- The warning above means that traced TAPAS models randomly crash with \"Unkown Reasons\" when used for inference.\n",
    "- Using the API included here, other BERT models work well during Neuron deployment and inference.\n",
    "- The neuron service will always try running predictions through Neuron models first, and will fall back on the CPU if the neuron model acts funny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46b744-aebb-41bd-8774-cd5e81a3b5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62ad1d-ebcf-4d68-b849-375602617789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c510c-2bfe-4479-b601-faafea9d2c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f808e5e-fd72-4216-8142-9e76700ea4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7f9ca-5782-4164-8854-050f9fc4fe23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
